/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
wandb: wandb version 0.12.16 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run brisk-grass-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rishigundakaram/CPINO
wandb: üöÄ View run at https://wandb.ai/rishigundakaram/CPINO/runs/ody4nhsg
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino/wandb/run-20220525_181309-ody4nhsg
wandb: Run `wandb offline` to turn off syncing.

  0% 0/50 [00:00<?, ?it/s]/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/CGDs/cgd_utils.py:201: UserWarning: CG iter num: 108
  warnings.warn('CG iter num: %d' % (i + 1))
Epoch: 0, train loss: 2.31881, f_loss_w: 0.00178, f_loss_uw: 2.31881, data loss: 0.21900:   0% 0/50 [09:24<?, ?it/s]Epoch: 0, train loss: 2.31881, f_loss_w: 0.00178, f_loss_uw: 2.31881, data loss: 0.21900:   2% 1/50 [09:24<7:41:04, 564.59s/it]Epoch: 1, train loss: 1.98214, f_loss_w: 0.00393, f_loss_uw: 1.98214, data loss: 0.09238:   2% 1/50 [15:27<7:41:04, 564.59s/it]Epoch: 1, train loss: 1.98214, f_loss_w: 0.00393, f_loss_uw: 1.98214, data loss: 0.09238:   4% 2/50 [15:27<6:06:42, 458.39s/it]Epoch: 2, train loss: 1.97546, f_loss_w: 0.00418, f_loss_uw: 1.97546, data loss: 0.09057:   4% 2/50 [20:44<6:06:42, 458.39s/it]Epoch: 2, train loss: 1.97546, f_loss_w: 0.00418, f_loss_uw: 1.97546, data loss: 0.09057:   6% 3/50 [20:44<5:18:10, 406.18s/it]Epoch: 3, train loss: 2.06767, f_loss_w: 0.00341, f_loss_uw: 2.06767, data loss: 0.08685:   6% 3/50 [26:50<5:18:10, 406.18s/it]Epoch: 3, train loss: 2.06767, f_loss_w: 0.00341, f_loss_uw: 2.06767, data loss: 0.08685:   8% 4/50 [26:50<5:02:27, 394.52s/it]Epoch: 4, train loss: 2.14626, f_loss_w: 0.00200, f_loss_uw: 2.14626, data loss: 0.08741:   8% 4/50 [31:13<5:02:27, 394.52s/it]Epoch: 4, train loss: 2.14626, f_loss_w: 0.00200, f_loss_uw: 2.14626, data loss: 0.08741:  10% 5/50 [31:13<4:31:53, 362.52s/it]Epoch: 5, train loss: 1.97010, f_loss_w: 0.00193, f_loss_uw: 1.97010, data loss: 0.07958:  10% 5/50 [35:48<4:31:53, 362.52s/it]Epoch: 5, train loss: 1.97010, f_loss_w: 0.00193, f_loss_uw: 1.97010, data loss: 0.07958:  12% 6/50 [35:48<4:12:07, 343.80s/it]Epoch: 6, train loss: 1.78841, f_loss_w: 0.00154, f_loss_uw: 1.78841, data loss: 0.07189:  12% 6/50 [40:32<4:12:07, 343.80s/it]Epoch: 6, train loss: 1.78841, f_loss_w: 0.00154, f_loss_uw: 1.78841, data loss: 0.07189:  14% 7/50 [40:32<3:58:08, 332.30s/it]Epoch: 7, train loss: 1.88498, f_loss_w: 0.00307, f_loss_uw: 1.88498, data loss: 0.08596:  14% 7/50 [45:05<3:58:08, 332.30s/it]Epoch: 7, train loss: 1.88498, f_loss_w: 0.00307, f_loss_uw: 1.88498, data loss: 0.08596:  16% 8/50 [45:05<3:45:19, 321.90s/it]Epoch: 8, train loss: 1.67997, f_loss_w: 0.00149, f_loss_uw: 1.67997, data loss: 0.06555:  16% 8/50 [49:59<3:45:19, 321.90s/it]Epoch: 8, train loss: 1.67997, f_loss_w: 0.00149, f_loss_uw: 1.67997, data loss: 0.06555:  18% 9/50 [49:59<3:36:52, 317.37s/it]Epoch: 9, train loss: 1.63475, f_loss_w: 0.00136, f_loss_uw: 1.63475, data loss: 0.06557:  18% 9/50 [54:46<3:36:52, 317.37s/it]Epoch: 9, train loss: 1.63475, f_loss_w: 0.00136, f_loss_uw: 1.63475, data loss: 0.06557:  20% 10/50 [54:46<3:28:24, 312.60s/it]Epoch: 10, train loss: 1.89748, f_loss_w: 0.00153, f_loss_uw: 1.89748, data loss: 0.08792:  20% 10/50 [59:28<3:28:24, 312.60s/it]Epoch: 10, train loss: 1.89748, f_loss_w: 0.00153, f_loss_uw: 1.89748, data loss: 0.08792:  22% 11/50 [59:28<3:20:22, 308.26s/it]Epoch: 11, train loss: 1.61900, f_loss_w: 0.00133, f_loss_uw: 1.61900, data loss: 0.06312:  22% 11/50 [1:04:07<3:20:22, 308.26s/it]Epoch: 11, train loss: 1.61900, f_loss_w: 0.00133, f_loss_uw: 1.61900, data loss: 0.06312:  24% 12/50 [1:04:07<3:12:34, 304.08s/it]Epoch: 12, train loss: 1.49810, f_loss_w: 0.00136, f_loss_uw: 1.49810, data loss: 0.05955:  24% 12/50 [1:09:45<3:12:34, 304.08s/it]Epoch: 12, train loss: 1.49810, f_loss_w: 0.00136, f_loss_uw: 1.49810, data loss: 0.05955:  26% 13/50 [1:09:45<3:10:22, 308.71s/it]Epoch: 13, train loss: 1.43262, f_loss_w: 0.00123, f_loss_uw: 1.43262, data loss: 0.05771:  26% 13/50 [1:14:44<3:10:22, 308.71s/it]Epoch: 13, train loss: 1.43262, f_loss_w: 0.00123, f_loss_uw: 1.43262, data loss: 0.05771:  28% 14/50 [1:14:44<3:04:25, 307.38s/it]Epoch: 14, train loss: 1.65755, f_loss_w: 0.00170, f_loss_uw: 1.65755, data loss: 0.07916:  28% 14/50 [1:19:55<3:04:25, 307.38s/it]Epoch: 14, train loss: 1.65755, f_loss_w: 0.00170, f_loss_uw: 1.65755, data loss: 0.07916:  30% 15/50 [1:19:55<2:59:38, 307.94s/it]Epoch: 15, train loss: 1.42788, f_loss_w: 0.00123, f_loss_uw: 1.42788, data loss: 0.05798:  30% 15/50 [1:25:01<2:59:38, 307.94s/it]Epoch: 15, train loss: 1.42788, f_loss_w: 0.00123, f_loss_uw: 1.42788, data loss: 0.05798:  32% 16/50 [1:25:01<2:54:20, 307.66s/it]Epoch: 16, train loss: 1.44850, f_loss_w: 0.00142, f_loss_uw: 1.44850, data loss: 0.07162:  32% 16/50 [1:30:14<2:54:20, 307.66s/it]Epoch: 16, train loss: 1.44850, f_loss_w: 0.00142, f_loss_uw: 1.44850, data loss: 0.07162:  34% 17/50 [1:30:14<2:49:34, 308.31s/it]Epoch: 17, train loss: 1.38223, f_loss_w: 0.00141, f_loss_uw: 1.38223, data loss: 0.05896:  34% 17/50 [1:35:27<2:49:34, 308.31s/it]Epoch: 17, train loss: 1.38223, f_loss_w: 0.00141, f_loss_uw: 1.38223, data loss: 0.05896:  36% 18/50 [1:35:27<2:44:42, 308.83s/it]Epoch: 18, train loss: 1.30103, f_loss_w: 0.00164, f_loss_uw: 1.30103, data loss: 0.05926:  36% 18/50 [1:41:07<2:44:42, 308.83s/it]Epoch: 18, train loss: 1.30103, f_loss_w: 0.00164, f_loss_uw: 1.30103, data loss: 0.05926:  38% 19/50 [1:41:07<2:41:25, 312.44s/it]Epoch: 19, train loss: 1.32709, f_loss_w: 0.00138, f_loss_uw: 1.32709, data loss: 0.06140:  38% 19/50 [1:46:19<2:41:25, 312.44s/it]Epoch: 19, train loss: 1.32709, f_loss_w: 0.00138, f_loss_uw: 1.32709, data loss: 0.06140:  40% 20/50 [1:46:19<2:36:10, 312.36s/it]Epoch: 20, train loss: 1.29647, f_loss_w: 0.00137, f_loss_uw: 1.29647, data loss: 0.05839:  40% 20/50 [1:51:41<2:36:10, 312.36s/it]Epoch: 20, train loss: 1.29647, f_loss_w: 0.00137, f_loss_uw: 1.29647, data loss: 0.05839:  42% 21/50 [1:51:41<2:31:29, 313.43s/it]Epoch: 21, train loss: 1.26543, f_loss_w: 0.00119, f_loss_uw: 1.26543, data loss: 0.05977:  42% 21/50 [1:56:34<2:31:29, 313.43s/it]Epoch: 21, train loss: 1.26543, f_loss_w: 0.00119, f_loss_uw: 1.26543, data loss: 0.05977:  44% 22/50 [1:56:34<2:25:13, 311.21s/it]Epoch: 22, train loss: 1.31544, f_loss_w: 0.00086, f_loss_uw: 1.31544, data loss: 0.05832:  44% 22/50 [2:01:03<2:25:13, 311.21s/it]Epoch: 22, train loss: 1.31544, f_loss_w: 0.00086, f_loss_uw: 1.31544, data loss: 0.05832:  46% 23/50 [2:01:03<2:17:56, 306.55s/it]Epoch: 23, train loss: 1.21718, f_loss_w: 0.00109, f_loss_uw: 1.21718, data loss: 0.05519:  46% 23/50 [2:05:55<2:17:56, 306.55s/it]Epoch: 23, train loss: 1.21718, f_loss_w: 0.00109, f_loss_uw: 1.21718, data loss: 0.05519:  48% 24/50 [2:05:55<2:12:10, 305.04s/it]Epoch: 24, train loss: 1.43275, f_loss_w: 0.00090, f_loss_uw: 1.43275, data loss: 0.07608:  48% 24/50 [2:10:45<2:12:10, 305.04s/it]Epoch: 24, train loss: 1.43275, f_loss_w: 0.00090, f_loss_uw: 1.43275, data loss: 0.07608:  50% 25/50 [2:10:45<2:06:25, 303.41s/it]Epoch: 25, train loss: 1.13597, f_loss_w: 0.00103, f_loss_uw: 1.13597, data loss: 0.04470:  50% 25/50 [2:16:21<2:06:25, 303.41s/it]Epoch: 25, train loss: 1.13597, f_loss_w: 0.00103, f_loss_uw: 1.13597, data loss: 0.04470:  52% 26/50 [2:16:21<2:02:43, 306.82s/it]Epoch: 26, train loss: 1.12884, f_loss_w: 0.00102, f_loss_uw: 1.12884, data loss: 0.04728:  52% 26/50 [2:21:39<2:02:43, 306.82s/it]Epoch: 26, train loss: 1.12884, f_loss_w: 0.00102, f_loss_uw: 1.12884, data loss: 0.04728:  54% 27/50 [2:21:39<1:58:05, 308.06s/it]Epoch: 27, train loss: 1.20034, f_loss_w: 0.00069, f_loss_uw: 1.20034, data loss: 0.05122:  54% 27/50 [2:26:23<1:58:05, 308.06s/it]Epoch: 27, train loss: 1.20034, f_loss_w: 0.00069, f_loss_uw: 1.20034, data loss: 0.05122:  56% 28/50 [2:26:23<1:52:00, 305.49s/it]Epoch: 28, train loss: 1.16298, f_loss_w: 0.00085, f_loss_uw: 1.16298, data loss: 0.05301:  56% 28/50 [2:31:09<1:52:00, 305.49s/it]Epoch: 28, train loss: 1.16298, f_loss_w: 0.00085, f_loss_uw: 1.16298, data loss: 0.05301:  58% 29/50 [2:31:09<1:46:13, 303.51s/it]Epoch: 29, train loss: 1.96954, f_loss_w: 0.00037, f_loss_uw: 1.96954, data loss: 0.11183:  58% 29/50 [2:34:45<1:46:13, 303.51s/it]Epoch: 29, train loss: 1.96954, f_loss_w: 0.00037, f_loss_uw: 1.96954, data loss: 0.11183:  60% 30/50 [2:34:45<1:38:05, 294.28s/it]Epoch: 30, train loss: 1.33071, f_loss_w: 0.00024, f_loss_uw: 1.33071, data loss: 0.05659:  60% 30/50 [2:38:53<1:38:05, 294.28s/it]Epoch: 30, train loss: 1.33071, f_loss_w: 0.00024, f_loss_uw: 1.33071, data loss: 0.05659:  62% 31/50 [2:38:53<1:31:41, 289.54s/it]Epoch: 31, train loss: 1.20451, f_loss_w: 0.00033, f_loss_uw: 1.20451, data loss: 0.05031:  62% 31/50 [2:43:32<1:31:41, 289.54s/it]Epoch: 31, train loss: 1.20451, f_loss_w: 0.00033, f_loss_uw: 1.20451, data loss: 0.05031:  64% 32/50 [2:43:32<1:26:31, 288.43s/it]Epoch: 32, train loss: 1.18697, f_loss_w: 0.00034, f_loss_uw: 1.18697, data loss: 0.04792:  64% 32/50 [2:47:51<1:26:31, 288.43s/it]Epoch: 32, train loss: 1.18697, f_loss_w: 0.00034, f_loss_uw: 1.18697, data loss: 0.04792:  66% 33/50 [2:47:51<1:20:51, 285.41s/it]Epoch: 33, train loss: 1.31333, f_loss_w: 0.00046, f_loss_uw: 1.31333, data loss: 0.06221:  66% 33/50 [2:52:03<1:20:51, 285.41s/it]Epoch: 33, train loss: 1.31333, f_loss_w: 0.00046, f_loss_uw: 1.31333, data loss: 0.06221:  68% 34/50 [2:52:03<1:15:11, 281.97s/it]Epoch: 34, train loss: 1.27093, f_loss_w: 0.00049, f_loss_uw: 1.27093, data loss: 0.05812:  68% 34/50 [2:55:59<1:15:11, 281.97s/it]Epoch: 34, train loss: 1.27093, f_loss_w: 0.00049, f_loss_uw: 1.27093, data loss: 0.05812:  70% 35/50 [2:55:59<1:09:18, 277.21s/it]Epoch: 35, train loss: 1.21732, f_loss_w: 0.00050, f_loss_uw: 1.21732, data loss: 0.06143:  70% 35/50 [2:59:37<1:09:18, 277.21s/it]Epoch: 35, train loss: 1.21732, f_loss_w: 0.00050, f_loss_uw: 1.21732, data loss: 0.06143:  72% 36/50 [2:59:37<1:03:16, 271.19s/it]Epoch: 36, train loss: 1.28961, f_loss_w: 0.00056, f_loss_uw: 1.28961, data loss: 0.06067:  72% 36/50 [3:03:01<1:03:16, 271.19s/it]Epoch: 36, train loss: 1.28961, f_loss_w: 0.00056, f_loss_uw: 1.28961, data loss: 0.06067:  74% 37/50 [3:03:01<57:15, 264.27s/it]  Epoch: 37, train loss: 1.18690, f_loss_w: 0.00057, f_loss_uw: 1.18690, data loss: 0.05666:  74% 37/50 [3:06:30<57:15, 264.27s/it]Epoch: 37, train loss: 1.18690, f_loss_w: 0.00057, f_loss_uw: 1.18690, data loss: 0.05666:  76% 38/50 [3:06:30<51:44, 258.70s/it]Epoch: 38, train loss: 1.31048, f_loss_w: 0.00049, f_loss_uw: 1.31048, data loss: 0.06318:  76% 38/50 [3:09:50<51:44, 258.70s/it]Epoch: 38, train loss: 1.31048, f_loss_w: 0.00049, f_loss_uw: 1.31048, data loss: 0.06318:  78% 39/50 [3:09:50<46:19, 252.69s/it]Epoch: 39, train loss: 1.20447, f_loss_w: 0.00053, f_loss_uw: 1.20447, data loss: 0.05572:  78% 39/50 [3:13:13<46:19, 252.69s/it]Epoch: 39, train loss: 1.20447, f_loss_w: 0.00053, f_loss_uw: 1.20447, data loss: 0.05572:  80% 40/50 [3:13:13<41:16, 247.70s/it]Epoch: 40, train loss: 1.30942, f_loss_w: 0.00047, f_loss_uw: 1.30942, data loss: 0.06419:  80% 40/50 [3:16:23<41:16, 247.70s/it]Epoch: 40, train loss: 1.30942, f_loss_w: 0.00047, f_loss_uw: 1.30942, data loss: 0.06419:  82% 41/50 [3:16:23<36:16, 241.79s/it]Epoch: 41, train loss: 1.26849, f_loss_w: 0.00038, f_loss_uw: 1.26849, data loss: 0.06309:  82% 41/50 [3:19:14<36:16, 241.79s/it]Epoch: 41, train loss: 1.26849, f_loss_w: 0.00038, f_loss_uw: 1.26849, data loss: 0.06309:  84% 42/50 [3:19:14<31:17, 234.71s/it]Epoch: 42, train loss: 1.12697, f_loss_w: 0.00050, f_loss_uw: 1.12697, data loss: 0.04957:  84% 42/50 [3:22:38<31:17, 234.71s/it]Epoch: 42, train loss: 1.12697, f_loss_w: 0.00050, f_loss_uw: 1.12697, data loss: 0.04957:  86% 43/50 [3:22:38<27:00, 231.57s/it]Epoch: 43, train loss: 1.35399, f_loss_w: 0.00044, f_loss_uw: 1.35399, data loss: 0.06743:  86% 43/50 [3:25:46<27:00, 231.57s/it]Epoch: 43, train loss: 1.35399, f_loss_w: 0.00044, f_loss_uw: 1.35399, data loss: 0.06743:  88% 44/50 [3:25:46<22:42, 227.14s/it]Epoch: 44, train loss: 1.15166, f_loss_w: 0.00042, f_loss_uw: 1.15166, data loss: 0.04582:  88% 44/50 [3:28:49<22:42, 227.14s/it]Epoch: 44, train loss: 1.15166, f_loss_w: 0.00042, f_loss_uw: 1.15166, data loss: 0.04582:  90% 45/50 [3:28:49<18:33, 222.71s/it]Epoch: 45, train loss: 1.12124, f_loss_w: 0.00059, f_loss_uw: 1.12124, data loss: 0.04929:  90% 45/50 [3:32:00<18:33, 222.71s/it]Epoch: 45, train loss: 1.12124, f_loss_w: 0.00059, f_loss_uw: 1.12124, data loss: 0.04929:  92% 46/50 [3:32:00<14:37, 219.46s/it]Epoch: 46, train loss: 1.27136, f_loss_w: 0.00052, f_loss_uw: 1.27136, data loss: 0.06518:  92% 46/50 [3:35:16<14:37, 219.46s/it]Epoch: 46, train loss: 1.27136, f_loss_w: 0.00052, f_loss_uw: 1.27136, data loss: 0.06518:  94% 47/50 [3:35:16<10:51, 217.14s/it]Epoch: 47, train loss: 1.43123, f_loss_w: 0.00005, f_loss_uw: 1.43123, data loss: 0.06864:  94% 47/50 [3:37:35<10:51, 217.14s/it]Epoch: 47, train loss: 1.43123, f_loss_w: 0.00005, f_loss_uw: 1.43123, data loss: 0.06864:  96% 48/50 [3:37:35<06:58, 209.26s/it]Epoch: 48, train loss: 1.29398, f_loss_w: 0.00001, f_loss_uw: 1.29398, data loss: 0.05877:  96% 48/50 [3:39:01<06:58, 209.26s/it]Epoch: 48, train loss: 1.29398, f_loss_w: 0.00001, f_loss_uw: 1.29398, data loss: 0.05877:  98% 49/50 [3:39:01<03:16, 196.87s/it]Epoch: 49, train loss: 1.25139, f_loss_w: 0.00001, f_loss_uw: 1.25139, data loss: 0.05210:  98% 49/50 [3:40:24<03:16, 196.87s/it]Epoch: 49, train loss: 1.25139, f_loss_w: 0.00001, f_loss_uw: 1.25139, data loss: 0.05210: 100% 50/50 [3:40:24<00:00, 185.46s/it]Epoch: 49, train loss: 1.25139, f_loss_w: 0.00001, f_loss_uw: 1.25139, data loss: 0.05210: 100% 50/50 [3:40:24<00:00, 264.49s/it]Checkpoint is saved at checkpoints//darcy-cpino.pt
Checkpoint is saved at checkpoints//darcy-cpino-weights.pt

wandb: Waiting for W&B process to finish, PID 404... (success).
wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:            f loss ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:   f loss weighted ‚ñÑ‚ñà‚ñà‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:        train loss ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb: 
wandb: Run summary:
wandb:         data loss 0.0521
wandb:            f loss 1.25139
wandb:   f loss weighted 1e-05
wandb:        train loss 1.25139
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced brisk-grass-27: https://wandb.ai/rishigundakaram/CPINO/runs/ody4nhsg
wandb: Find logs at: ./wandb/run-20220525_181309-ody4nhsg/logs/debug.log
wandb: 

Done!
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
0
Traceback (most recent call last):
  File "/groups/tensorlab/rgundaka/code/PINO/eval_operator.py", line 80, in <module>
    test_2d(config, args)
  File "/groups/tensorlab/rgundaka/code/PINO/eval_operator.py", line 64, in test_2d
    ckpt = torch.load(ckpt_path)
  File "/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/serialization.py", line 594, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/groups/tensorlab/rgundaka/code/PINO/CGD_PINO/experiments/Darcy_cpino/checkpoints/darcy-pino.pt'
