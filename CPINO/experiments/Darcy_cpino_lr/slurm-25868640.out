/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
loading data
loaded data
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
loading data
loaded data
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
loading data
loaded data
loading data
loaded data
loading data
loaded data
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
loading data
loaded data
loading data
loaded data
loading data
loaded data
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
loading data
loaded data
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
loading data
loaded data
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
loading data
loaded data
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
loading data
loaded data
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run fancy-fog-186
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/gq6jdt6k
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110422-gq6jdt6k
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run sage-thunder-187
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/1zzm1p0s
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110422-1zzm1p0s
wandb: Run `wandb offline` to turn off syncing.

wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run legendary-donkey-188
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/1nx69q86
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110423-1nx69q86
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run lilac-surf-189
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/35iohf7h
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110423-35iohf7h
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run blooming-microwave-190
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/709ifv8o
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110423-709ifv8o
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run morning-jazz-191
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/2c45n5xe
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110423-2c45n5xe
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run young-pyramid-192
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/1slq1jnq
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110423-1slq1jnq
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run usual-wind-193
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/3f2m2kz2
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110423-3f2m2kz2
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run balmy-hill-194
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/3k1b39hb
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-3k1b39hb
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run smooth-frost-195
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/35a5mqrl
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-35a5mqrl
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run bumbling-morning-196
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/22googc6
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-22googc6
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run tough-star-197
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/34dscilq
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-34dscilq
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run serene-blaze-198
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/kvniafs9
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-kvniafs9
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run solar-thunder-199
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/3p5tuq44
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-3p5tuq44
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run glad-pine-200
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/2qvvc0xm
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-2qvvc0xm
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run faithful-field-201
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/2uzmycsg
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-2uzmycsg
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run apricot-salad-202
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/3iyg8aqe
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110425-3iyg8aqe
wandb: Run `wandb offline` to turn off syncing.
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run daily-music-203
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/2n88fw1a
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110424-2n88fw1a
wandb: Run `wandb offline` to turn off syncing.


wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run efficient-smoke-204
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/345grtly
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110425-345grtly
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run devout-sponge-205
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/28256sve
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110425-28256sve
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run chocolate-thunder-206
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/3rlnwi0q
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110425-3rlnwi0q
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run worldly-tree-207
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/uxjhlxiq
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110425-uxjhlxiq
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run polished-music-208
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/w8sbpf65
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110428-w8sbpf65
wandb: Run `wandb offline` to turn off syncing.

wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run comfy-snowflake-209
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/1p45i0xb
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110428-1p45i0xb
wandb: Run `wandb offline` to turn off syncing.

/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
wandb: Currently logged in as: rishigundakaram (use `wandb login --relogin` to force relogin)
loading data
loaded data
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.10
wandb: Syncing run ethereal-feather-210
wandb: ⭐️ View project at https://wandb.ai/rishigundakaram/CPINO
wandb: 🚀 View run at https://wandb.ai/rishigundakaram/CPINO/runs/chg5pnpo
wandb: Run data is saved locally in /central/groups/tensorlab/rgundaka/code/PINO/CPINO/experiments/Darcy_cpino_lr/wandb/run-20220615_110441-chg5pnpo
wandb: Run `wandb offline` to turn off syncing.

  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.78892, f_loss_w: 0.01620, f_loss_uw: 3.78892, data loss: 0.56592:   0% 0/25 [01:26<?, ?it/s]Epoch: 0, train loss: 3.78892, f_loss_w: 0.01620, f_loss_uw: 3.78892, data loss: 0.56592:   4% 1/25 [01:26<34:27, 86.14s/it]Epoch: 1, train loss: 2.62420, f_loss_w: 0.00534, f_loss_uw: 2.62420, data loss: 0.35692:   4% 1/25 [03:41<34:27, 86.14s/it]Epoch: 1, train loss: 2.62420, f_loss_w: 0.00534, f_loss_uw: 2.62420, data loss: 0.35692:   8% 2/25 [03:41<43:01, 112.26s/it]Epoch: 2, train loss: 2.55253, f_loss_w: 0.00096, f_loss_uw: 2.55253, data loss: 0.30595:   8% 2/25 [05:38<43:01, 112.26s/it]Epoch: 2, train loss: 2.55253, f_loss_w: 0.00096, f_loss_uw: 2.55253, data loss: 0.30595:  12% 3/25 [05:38<41:42, 113.74s/it]Epoch: 3, train loss: 2.57469, f_loss_w: 0.00035, f_loss_uw: 2.57469, data loss: 0.18733:  12% 3/25 [07:44<41:42, 113.74s/it]Epoch: 3, train loss: 2.57469, f_loss_w: 0.00035, f_loss_uw: 2.57469, data loss: 0.18733:  16% 4/25 [07:44<41:08, 117.54s/it]  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 4.55535, f_loss_w: 0.01316, f_loss_uw: 4.55535, data loss: 0.59244:   0% 0/25 [02:23<?, ?it/s]Epoch: 0, train loss: 4.55535, f_loss_w: 0.01316, f_loss_uw: 4.55535, data loss: 0.59244:   4% 1/25 [02:23<57:15, 143.15s/it]Epoch: 1, train loss: 2.40106, f_loss_w: 0.00028, f_loss_uw: 2.40106, data loss: 0.17081:   4% 1/25 [04:49<57:15, 143.15s/it]Epoch: 1, train loss: 2.40106, f_loss_w: 0.00028, f_loss_uw: 2.40106, data loss: 0.17081:   8% 2/25 [04:49<55:36, 145.07s/it]Epoch: 2, train loss: 2.35494, f_loss_w: 0.00030, f_loss_uw: 2.35494, data loss: 0.20430:   8% 2/25 [06:39<55:36, 145.07s/it]Epoch: 2, train loss: 2.35494, f_loss_w: 0.00030, f_loss_uw: 2.35494, data loss: 0.20430:  12% 3/25 [06:39<48:22, 131.93s/it]Epoch: 3, train loss: 2.21334, f_loss_w: 0.00017, f_loss_uw: 2.21334, data loss: 0.18792:  12% 3/25 [07:56<48:22, 131.93s/it]Epoch: 3, train loss: 2.21334, f_loss_w: 0.00017, f_loss_uw: 2.21334, data loss: 0.18792:  16% 4/25 [07:56<40:36, 116.02s/i  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.67496, f_loss_w: 0.00655, f_loss_uw: 3.67496, data loss: 0.54151:   0% 0/25 [01:32<?, ?it/s]Epoch: 0, train loss: 3.67496, f_loss_w: 0.00655, f_loss_uw: 3.67496, data loss: 0.54151:   4% 1/25 [01:32<37:02, 92.59s/it]Epoch: 1, train loss: 3.09249, f_loss_w: 0.00127, f_loss_uw: 3.09249, data loss: 0.56505:   4% 1/25 [03:55<37:02, 92.59s/it]Epoch: 1, train loss: 3.09249, f_loss_w: 0.00127, f_loss_uw: 3.09249, data loss: 0.56505:   8% 2/25 [03:55<45:42, 119.22s/it]Epoch: 2, train loss: 2.99995, f_loss_w: 0.00033, f_loss_uw: 2.99995, data loss: 0.25550:   8% 2/25 [05:58<45:42, 119.22s/it]Epoch: 2, train loss: 2.99995, f_loss_w: 0.00033, f_loss_uw: 2.99995, data loss: 0.25550:  12% 3/25 [05:58<44:15, 120.69s/it]Epoch: 3, train loss: 2.68814, f_loss_w: 0.00015, f_loss_uw: 2.68814, data loss: 0.18008:  12% 3/25 [07:58<44:15, 120.69s/it]Epoch: 3, train loss: 2.68814, f_loss_w: 0.00015, f_loss_uw: 2.68814, data loss: 0.18008:  16% 4/25 [07:58<42:05, 120.28s/it]  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.48215, f_loss_w: -0.00291, f_loss_uw: 3.48215, data loss: 0.63709:   0% 0/25 [02:50<?, ?it/s]Epoch: 0, train loss: 3.48215, f_loss_w: -0.00291, f_loss_uw: 3.48215, data loss: 0.63709:   4% 1/25 [02:50<1:08:03, 170.13s/it]Epoch: 1, train loss: 2.47465, f_loss_w: 0.00008, f_loss_uw: 2.47465, data loss: 0.19763:   4% 1/25 [05:05<1:08:03, 170.13s/it] Epoch: 1, train loss: 2.47465, f_loss_w: 0.00008, f_loss_uw: 2.47465, data loss: 0.19763:   8% 2/25 [05:05<58:10, 151.75s/it]  Epoch: 2, train loss: 3.74914, f_loss_w: 0.00056, f_loss_uw: 3.74914, data loss: 0.33669:   8% 2/25 [07:11<58:10, 151.75s/it]Epoch: 2, train loss: 3.74914, f_loss_w: 0.00056, f_loss_uw: 3.74914, data loss: 0.33669:  12% 3/25 [07:12<52:14, 142.49s/it]Epoch: 3, train loss: 2.68067, f_loss_w: 0.00013, f_loss_uw: 2.68067, data loss: 0.24797:  12% 3/25 [08:46<52:14, 142.49s/it]Epoch: 3, train loss: 2.68067, f_loss_w: 0.00013, f_loss_uw: 2.68067, data loss: 0.24797:  16% 4/25 [08:46<44:58,   0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.45273, f_loss_w: 0.00225, f_loss_uw: 3.45273, data loss: 0.57687:   0% 0/25 [01:51<?, ?it/s]Epoch: 0, train loss: 3.45273, f_loss_w: 0.00225, f_loss_uw: 3.45273, data loss: 0.57687:   4% 1/25 [01:51<44:35, 111.46s/it]Epoch: 1, train loss: 3.31296, f_loss_w: 0.00023, f_loss_uw: 3.31296, data loss: 0.45395:   4% 1/25 [04:35<44:35, 111.46s/it]Epoch: 1, train loss: 3.31296, f_loss_w: 0.00023, f_loss_uw: 3.31296, data loss: 0.45395:   8% 2/25 [04:35<53:14, 138.91s/it]Epoch: 2, train loss: 2.85834, f_loss_w: 0.00005, f_loss_uw: 2.85834, data loss: 0.21767:   8% 2/25 [07:17<53:14, 138.91s/it]Epoch: 2, train loss: 2.85834, f_loss_w: 0.00005, f_loss_uw: 2.85834, data loss: 0.21767:  12% 3/25 [07:17<54:05, 147.52s/it]Epoch: 3, train loss: 2.99057, f_loss_w: 0.00006, f_loss_uw: 2.99057, data loss: 0.19110:  12% 3/25 [10:01<54:05, 147.52s/it]Epoch: 3, train loss: 2.99057, f_loss_w: 0.00006, f_loss_uw: 2.99057, data loss: 0.19110:  16% 4/25 [10:01<53:17, 152.24s/i  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.26869, f_loss_w: -0.00314, f_loss_uw: 3.26869, data loss: 0.63974:   0% 0/25 [02:05<?, ?it/s]Epoch: 0, train loss: 3.26869, f_loss_w: -0.00314, f_loss_uw: 3.26869, data loss: 0.63974:   4% 1/25 [02:05<50:06, 125.27s/it]Epoch: 1, train loss: 3.36953, f_loss_w: -0.00003, f_loss_uw: 3.36953, data loss: 0.44920:   4% 1/25 [04:54<50:06, 125.27s/it]Epoch: 1, train loss: 3.36953, f_loss_w: -0.00003, f_loss_uw: 3.36953, data loss: 0.44920:   8% 2/25 [04:54<56:50, 148.30s/it]Epoch: 2, train loss: 2.59974, f_loss_w: 0.00003, f_loss_uw: 2.59974, data loss: 0.24064:   8% 2/25 [07:57<56:50, 148.30s/it] Epoch: 2, train loss: 2.59974, f_loss_w: 0.00003, f_loss_uw: 2.59974, data loss: 0.24064:  12% 3/25 [07:57<59:09, 161.34s/it]Epoch: 3, train loss: 2.58380, f_loss_w: 0.00005, f_loss_uw: 2.58380, data loss: 0.20761:  12% 3/25 [10:48<59:09, 161.34s/it]Epoch: 3, train loss: 2.58380, f_loss_w: 0.00005, f_loss_uw: 2.58380, data loss: 0.20761:  16% 4/25 [10:48<57:25, 164.  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.77502, f_loss_w: -0.04006, f_loss_uw: 3.77502, data loss: 0.71145:   0% 0/25 [02:42<?, ?it/s]Epoch: 0, train loss: 3.77502, f_loss_w: -0.04006, f_loss_uw: 3.77502, data loss: 0.71145:   4% 1/25 [02:42<1:04:54, 162.26s/it]Epoch: 1, train loss: 2.25211, f_loss_w: 0.00044, f_loss_uw: 2.25211, data loss: 0.18473:   4% 1/25 [06:21<1:04:54, 162.26s/it] Epoch: 1, train loss: 2.25211, f_loss_w: 0.00044, f_loss_uw: 2.25211, data loss: 0.18473:   8% 2/25 [06:21<1:13:40, 192.19s/it]Epoch: 2, train loss: 2.25926, f_loss_w: 0.00009, f_loss_uw: 2.25926, data loss: 0.16994:   8% 2/25 [09:15<1:13:40, 192.19s/it]Epoch: 2, train loss: 2.25926, f_loss_w: 0.00009, f_loss_uw: 2.25926, data loss: 0.16994:  12% 3/25 [09:15<1:07:59, 185.42s/it]Epoch: 3, train loss: 2.45436, f_loss_w: 0.00011, f_loss_uw: 2.45436, data loss: 0.17174:  12% 3/25 [11:34<1:07:59, 185.42s/it]Epoch: 3, train loss: 2.45436, f_loss_w: 0.00011, f_loss_uw: 2.45436, data loss: 0.17174:  16% 4/25 [11:34<1  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.75346, f_loss_w: 0.33711, f_loss_uw: 3.75346, data loss: 0.59226:   0% 0/25 [01:12<?, ?it/s]Epoch: 0, train loss: 3.75346, f_loss_w: 0.33711, f_loss_uw: 3.75346, data loss: 0.59226:   4% 1/25 [01:12<29:10, 72.92s/it]Epoch: 1, train loss: 2.91087, f_loss_w: 0.36455, f_loss_uw: 2.91087, data loss: 0.28373:   4% 1/25 [03:17<29:10, 72.92s/it]Epoch: 1, train loss: 2.91087, f_loss_w: 0.36455, f_loss_uw: 2.91087, data loss: 0.28373:   8% 2/25 [03:17<38:23, 100.17s/it]Epoch: 2, train loss: 3.58087, f_loss_w: 0.14163, f_loss_uw: 3.58087, data loss: 0.26084:   8% 2/25 [07:33<38:23, 100.17s/it]Epoch: 2, train loss: 3.58087, f_loss_w: 0.14163, f_loss_uw: 3.58087, data loss: 0.26084:  12% 3/25 [07:33<57:46, 157.57s/it]Epoch: 3, train loss: 2.48071, f_loss_w: 0.06137, f_loss_uw: 2.48071, data loss: 0.18285:  12% 3/25 [11:53<57:46, 157.57s/it]Epoch: 3, train loss: 2.48071, f_loss_w: 0.06137, f_loss_uw: 2.48071, data loss: 0.18285:  16% 4/25 [11:53<1:05:37, 187.51s/i  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 4.12730, f_loss_w: 84.49557, f_loss_uw: 4.12730, data loss: 0.45789:   0% 0/25 [02:55<?, ?it/s]Epoch: 0, train loss: 4.12730, f_loss_w: 84.49557, f_loss_uw: 4.12730, data loss: 0.45789:   4% 1/25 [02:55<1:10:07, 175.31s/it]Epoch: 1, train loss: 3.79406, f_loss_w: 79.32133, f_loss_uw: 3.79406, data loss: 0.30316:   4% 1/25 [06:20<1:10:07, 175.31s/it]Epoch: 1, train loss: 3.79406, f_loss_w: 79.32133, f_loss_uw: 3.79406, data loss: 0.30316:   8% 2/25 [06:20<1:13:10, 190.87s/it]Epoch: 2, train loss: 2.86130, f_loss_w: 15.50690, f_loss_uw: 2.86130, data loss: 0.20727:   8% 2/25 [09:01<1:13:10, 190.87s/it]Epoch: 2, train loss: 2.86130, f_loss_w: 15.50690, f_loss_uw: 2.86130, data loss: 0.20727:  12% 3/25 [09:01<1:05:55, 179.78s/it]Epoch: 3, train loss: 2.65294, f_loss_w: 16.10469, f_loss_uw: 2.65294, data loss: 0.17485:  12% 3/25 [12:47<1:05:55, 179.78s/it]Epoch: 3, train loss: 2.65294, f_loss_w: 16.10469, f_loss_uw: 2.65294, data loss: 0.17485:  16% 4/25 [12  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.26335, f_loss_w: -0.01481, f_loss_uw: 3.26335, data loss: 0.56792:   0% 0/25 [02:51<?, ?it/s]Epoch: 0, train loss: 3.26335, f_loss_w: -0.01481, f_loss_uw: 3.26335, data loss: 0.56792:   4% 1/25 [02:51<1:08:31, 171.30s/it]Epoch: 1, train loss: 2.12633, f_loss_w: 0.00117, f_loss_uw: 2.12633, data loss: 0.16569:   4% 1/25 [07:02<1:08:31, 171.30s/it] Epoch: 1, train loss: 2.12633, f_loss_w: 0.00117, f_loss_uw: 2.12633, data loss: 0.16569:   8% 2/25 [07:02<1:21:51, 213.53s/it]Epoch: 2, train loss: 2.06581, f_loss_w: 0.00142, f_loss_uw: 2.06581, data loss: 0.17159:   8% 2/25 [10:00<1:21:51, 213.53s/it]Epoch: 2, train loss: 2.06581, f_loss_w: 0.00142, f_loss_uw: 2.06581, data loss: 0.17159:  12% 3/25 [10:00<1:13:30, 200.46s/it]Epoch: 3, train loss: 2.46067, f_loss_w: 0.00351, f_loss_uw: 2.46067, data loss: 0.20032:  12% 3/25 [13:29<1:13:30, 200.46s/it]Epoch: 3, train loss: 2.46067, f_loss_w: 0.00351, f_loss_uw: 2.46067, data loss: 0.20032:  16% 4/25 [13:29<1  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 10.87481, f_loss_w: 0.12552, f_loss_uw: 10.87481, data loss: 0.60176:   0% 0/25 [04:05<?, ?it/s]Epoch: 0, train loss: 10.87481, f_loss_w: 0.12552, f_loss_uw: 10.87481, data loss: 0.60176:   4% 1/25 [04:05<1:38:03, 245.16s/it]Epoch: 1, train loss: 2.86261, f_loss_w: 0.00233, f_loss_uw: 2.86261, data loss: 0.17055:   4% 1/25 [06:56<1:38:03, 245.16s/it]  Epoch: 1, train loss: 2.86261, f_loss_w: 0.00233, f_loss_uw: 2.86261, data loss: 0.17055:   8% 2/25 [06:56<1:19:03, 206.24s/it]Epoch: 2, train loss: 3.51136, f_loss_w: 0.00517, f_loss_uw: 3.51136, data loss: 0.21600:   8% 2/25 [10:44<1:19:03, 206.24s/it]Epoch: 2, train loss: 3.51136, f_loss_w: 0.00517, f_loss_uw: 3.51136, data loss: 0.21600:  12% 3/25 [10:44<1:18:32, 214.20s/it]Epoch: 3, train loss: 3.14890, f_loss_w: 0.00569, f_loss_uw: 3.14890, data loss: 0.18099:  12% 3/25 [13:51<1:18:32, 214.20s/it]Epoch: 3, train loss: 3.14890, f_loss_w: 0.00569, f_loss_uw: 3.14890, data loss: 0.18099:  16% 4/25 [13:5  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 2.85757, f_loss_w: -0.04691, f_loss_uw: 2.85757, data loss: 0.38800:   0% 0/25 [03:47<?, ?it/s]Epoch: 0, train loss: 2.85757, f_loss_w: -0.04691, f_loss_uw: 2.85757, data loss: 0.38800:   4% 1/25 [03:47<1:31:04, 227.67s/it]Epoch: 1, train loss: 2.27135, f_loss_w: 0.01645, f_loss_uw: 2.27135, data loss: 0.19077:   4% 1/25 [07:18<1:31:04, 227.67s/it] Epoch: 1, train loss: 2.27135, f_loss_w: 0.01645, f_loss_uw: 2.27135, data loss: 0.19077:   8% 2/25 [07:18<1:23:47, 218.58s/it]Epoch: 2, train loss: 2.24177, f_loss_w: 0.00409, f_loss_uw: 2.24177, data loss: 0.19620:   8% 2/25 [10:21<1:23:47, 218.58s/it]Epoch: 2, train loss: 2.24177, f_loss_w: 0.00409, f_loss_uw: 2.24177, data loss: 0.19620:  12% 3/25 [10:21<1:15:26, 205.76s/it]Epoch: 3, train loss: 2.36799, f_loss_w: 0.02361, f_loss_uw: 2.36799, data loss: 0.18320:  12% 3/25 [14:18<1:15:26, 205.76s/it]Epoch: 3, train loss: 2.36799, f_loss_w: 0.02361, f_loss_uw: 2.36799, data loss: 0.18320:  16% 4/25 [14:18<1t]Epoch: 4, train loss: 3.63818, f_loss_w: 0.00274, f_loss_uw: 3.63818, data loss: 0.43335:  16% 4/25 [09:20<40:36, 116.02s/it]Epoch: 4, train loss: 3.63818, f_loss_w: 0.00274, f_loss_uw: 3.63818, data loss: 0.43335:  20% 5/25 [09:20<36:01, 108.06s/it]Epoch: 5, train loss: 2.99451, f_loss_w: 0.00012, f_loss_uw: 2.99451, data loss: 0.22912:  20% 5/25 [11:55<36:01, 108.06s/it]Epoch: 5, train loss: 2.99451, f_loss_w: 0.00012, f_loss_uw: 2.99451, data loss: 0.22912:  24% 6/25 [11:55<37:26, 118.22s/it]Epoch: 6, train loss: 3.03080, f_loss_w: 0.00015, f_loss_uw: 3.03080, data loss: 0.24858:  24% 6/25 [13:15<37:26, 118.22s/it]Epoch: 6, train loss: 3.03080, f_loss_w: 0.00015, f_loss_uw: 3.03080, data loss: 0.24858:  28% 7/25 [13:15<33:15, 110.89s/it]Epoch: 7, train loss: 2.86181, f_loss_w: 0.00010, f_loss_uw: 2.86181, data loss: 0.22146:  28% 7/25 [14:25<33:15, 110.89s/it]Epoch: 7, train loss: 2.86181, f_loss_w: 0.00010, f_loss_uw: 2.86181, data loss: 0.22146:  32% 8/25 [14:25<29:23, 103.76s/it]Epoch: 8, tra  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 2.36697, f_loss_w: 0.05230, f_loss_uw: 2.36697, data loss: 0.35887:   0% 0/25 [03:25<?, ?it/s]Epoch: 0, train loss: 2.36697, f_loss_w: 0.05230, f_loss_uw: 2.36697, data loss: 0.35887:   4% 1/25 [03:25<1:22:14, 205.62s/it]Epoch: 1, train loss: 1.93737, f_loss_w: 0.02905, f_loss_uw: 1.93737, data loss: 0.16581:   4% 1/25 [09:31<1:22:14, 205.62s/it]Epoch: 1, train loss: 1.93737, f_loss_w: 0.02905, f_loss_uw: 1.93737, data loss: 0.16581:   8% 2/25 [09:31<1:51:12, 290.13s/it]Epoch: 2, train loss: 2.24400, f_loss_w: 0.02310, f_loss_uw: 2.24400, data loss: 0.13962:   8% 2/25 [13:50<1:51:12, 290.13s/it]Epoch: 2, train loss: 2.24400, f_loss_w: 0.02310, f_loss_uw: 2.24400, data loss: 0.13962:  12% 3/25 [13:50<1:42:09, 278.62s/it]Epoch: 3, train loss: 2.36856, f_loss_w: 0.00453, f_loss_uw: 2.36856, data loss: 0.16632:  12% 3/25 [15:49<1:42:09, 278.62s/it]Epoch: 3, train loss: 2.36856, f_loss_w: 0.00453, f_loss_uw: 2.36856, data loss: 0.16632:  16% 4/25 [15:49<1:21128.50s/it]Epoch: 4, train loss: 6.03899, f_loss_w: 0.00018, f_loss_uw: 6.03899, data loss: 0.74772:  16% 4/25 [10:25<44:58, 128.50s/it]Epoch: 4, train loss: 6.03899, f_loss_w: 0.00018, f_loss_uw: 6.03899, data loss: 0.74772:  20% 5/25 [10:25<40:26, 121.32s/it]Epoch: 5, train loss: 3.00025, f_loss_w: 0.00019, f_loss_uw: 3.00025, data loss: 0.30998:  20% 5/25 [12:25<40:26, 121.32s/it]Epoch: 5, train loss: 3.00025, f_loss_w: 0.00019, f_loss_uw: 3.00025, data loss: 0.30998:  24% 6/25 [12:25<38:18, 120.98s/it]Epoch: 6, train loss: 2.69002, f_loss_w: 0.00003, f_loss_uw: 2.69002, data loss: 0.24703:  24% 6/25 [14:02<38:18, 120.98s/it]Epoch: 6, train loss: 2.69002, f_loss_w: 0.00003, f_loss_uw: 2.69002, data loss: 0.24703:  28% 7/25 [14:02<34:55, 116.40s/it]Epoch: 7, train loss: 2.79601, f_loss_w: 0.00008, f_loss_uw: 2.79601, data loss: 0.23159:  28% 7/25 [15:35<34:55, 116.40s/it]Epoch: 7, train loss: 2.79601, f_loss_w: 0.00008, f_loss_uw: 2.79601, data loss: 0.23159:  32% 8/25 [15:35<31:48, 112.29s/it]EpocEpoch: 4, train loss: 2.70657, f_loss_w: 0.00018, f_loss_uw: 2.70657, data loss: 0.18684:  16% 4/25 [10:23<42:05, 120.28s/it]Epoch: 4, train loss: 2.70657, f_loss_w: 0.00018, f_loss_uw: 2.70657, data loss: 0.18684:  20% 5/25 [10:23<42:07, 126.38s/it]Epoch: 5, train loss: 2.34545, f_loss_w: 0.00015, f_loss_uw: 2.34545, data loss: 0.16842:  20% 5/25 [12:36<42:07, 126.38s/it]Epoch: 5, train loss: 2.34545, f_loss_w: 0.00015, f_loss_uw: 2.34545, data loss: 0.16842:  24% 6/25 [12:36<40:28, 127.83s/it]Epoch: 6, train loss: 2.29688, f_loss_w: 0.00015, f_loss_uw: 2.29688, data loss: 0.16967:  24% 6/25 [14:34<40:28, 127.83s/it]Epoch: 6, train loss: 2.29688, f_loss_w: 0.00015, f_loss_uw: 2.29688, data loss: 0.16967:  28% 7/25 [14:34<37:46, 125.89s/it]Epoch: 7, train loss: 3.22888, f_loss_w: 0.00040, f_loss_uw: 3.22888, data loss: 0.25616:  28% 7/25 [16:07<37:46, 125.89s/it]Epoch: 7, train loss: 3.22888, f_loss_w: 0.00040, f_loss_uw: 3.22888, data loss: 0.25616:  32% 8/25 [16:07<34:03, 120.20s/it]Epoch: 8, train  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 2.69525, f_loss_w: 0.05106, f_loss_uw: 2.69525, data loss: 0.30732:   0% 0/25 [04:43<?, ?it/s]Epoch: 0, train loss: 2.69525, f_loss_w: 0.05106, f_loss_uw: 2.69525, data loss: 0.30732:   4% 1/25 [04:43<1:53:24, 283.52s/it]Epoch: 1, train loss: 5.49615, f_loss_w: 0.03737, f_loss_uw: 5.49615, data loss: 0.25566:   4% 1/25 [08:49<1:53:24, 283.52s/it]Epoch: 1, train loss: 5.49615, f_loss_w: 0.03737, f_loss_uw: 5.49615, data loss: 0.25566:   8% 2/25 [08:49<1:41:01, 263.56s/it]Epoch: 2, train loss: 2.75984, f_loss_w: 0.01921, f_loss_uw: 2.75984, data loss: 0.16573:   8% 2/25 [13:57<1:41:01, 263.56s/it]Epoch: 2, train loss: 2.75984, f_loss_w: 0.01921, f_loss_uw: 2.75984, data loss: 0.16573:  12% 3/25 [13:57<1:42:43, 280.14s/it]Epoch: 3, train loss: 12.26613, f_loss_w: -0.01134, f_loss_uw: 12.26613, data loss: 0.48329:  12% 3/25 [17:42<1:42:43, 280.14s/it]Epoch: 3, train loss: 12.26613, f_loss_w: -0.01134, f_loss_uw: 12.26613, data loss: 0.48329:  16% 4/25 [17:4  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 6.76615, f_loss_w: 0.26864, f_loss_uw: 6.76615, data loss: 0.32081:   0% 0/25 [04:39<?, ?it/s]Epoch: 0, train loss: 6.76615, f_loss_w: 0.26864, f_loss_uw: 6.76615, data loss: 0.32081:   4% 1/25 [04:39<1:51:45, 279.41s/it]Epoch: 1, train loss: 2.42795, f_loss_w: 0.04743, f_loss_uw: 2.42795, data loss: 0.13408:   4% 1/25 [09:43<1:51:45, 279.41s/it]Epoch: 1, train loss: 2.42795, f_loss_w: 0.04743, f_loss_uw: 2.42795, data loss: 0.13408:   8% 2/25 [09:43<1:52:08, 292.53s/it]Epoch: 2, train loss: 4.67653, f_loss_w: 0.03842, f_loss_uw: 4.67653, data loss: 0.17112:   8% 2/25 [13:51<1:52:08, 292.53s/it]Epoch: 2, train loss: 4.67653, f_loss_w: 0.03842, f_loss_uw: 4.67653, data loss: 0.17112:  12% 3/25 [13:51<1:41:14, 276.12s/it]Epoch: 3, train loss: 3.10774, f_loss_w: 0.03011, f_loss_uw: 3.10774, data loss: 0.13877:  12% 3/25 [17:56<1:41:14, 276.12s/it]Epoch: 3, train loss: 3.10774, f_loss_w: 0.03011, f_loss_uw: 3.10774, data loss: 0.13877:  16% 4/25 [17:56<1:33  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 15.84130, f_loss_w: 0.10564, f_loss_uw: 15.84130, data loss: 0.44386:   0% 0/25 [04:36<?, ?it/s]Epoch: 0, train loss: 15.84130, f_loss_w: 0.10564, f_loss_uw: 15.84130, data loss: 0.44386:   4% 1/25 [04:36<1:50:24, 276.03s/it]Epoch: 1, train loss: 15.25982, f_loss_w: 0.03638, f_loss_uw: 15.25982, data loss: 0.43122:   4% 1/25 [08:22<1:50:24, 276.03s/it]Epoch: 1, train loss: 15.25982, f_loss_w: 0.03638, f_loss_uw: 15.25982, data loss: 0.43122:   8% 2/25 [08:22<1:35:46, 249.83s/it]Epoch: 2, train loss: 3.80082, f_loss_w: 0.00371, f_loss_uw: 3.80082, data loss: 0.16871:   8% 2/25 [11:51<1:35:46, 249.83s/it]  Epoch: 2, train loss: 3.80082, f_loss_w: 0.00371, f_loss_uw: 3.80082, data loss: 0.16871:  12% 3/25 [11:51<1:26:02, 234.68s/it]Epoch: 3, train loss: 2.90334, f_loss_w: 0.01100, f_loss_uw: 2.90334, data loss: 0.14366:  12% 3/25 [18:00<1:26:02, 234.68s/it]Epoch: 3, train loss: 2.90334, f_loss_w: 0.01100, f_loss_uw: 2.90334, data loss: 0.14366:  16% 4/25 [t]Epoch: 4, train loss: 2.95104, f_loss_w: 0.00007, f_loss_uw: 2.95104, data loss: 0.20065:  16% 4/25 [12:10<53:17, 152.24s/it]Epoch: 4, train loss: 2.95104, f_loss_w: 0.00007, f_loss_uw: 2.95104, data loss: 0.20065:  20% 5/25 [12:10<48:54, 146.72s/it]Epoch: 5, train loss: 4.86677, f_loss_w: 0.00021, f_loss_uw: 4.86677, data loss: 0.41678:  20% 5/25 [13:41<48:54, 146.72s/it]Epoch: 5, train loss: 4.86677, f_loss_w: 0.00021, f_loss_uw: 4.86677, data loss: 0.41678:  24% 6/25 [13:41<42:42, 134.88s/it]Epoch: 6, train loss: 3.19058, f_loss_w: 0.00010, f_loss_uw: 3.19058, data loss: 0.45393:  24% 6/25 [15:33<42:42, 134.88s/it]Epoch: 6, train loss: 3.19058, f_loss_w: 0.00010, f_loss_uw: 3.19058, data loss: 0.45393:  28% 7/25 [15:33<39:07, 130.42s/it]Epoch: 7, train loss: 2.87404, f_loss_w: 0.00011, f_loss_uw: 2.87404, data loss: 0.24443:  28% 7/25 [16:52<39:07, 130.42s/it]Epoch: 7, train loss: 2.87404, f_loss_w: 0.00011, f_loss_uw: 2.87404, data loss: 0.24443:  32% 8/25 [16:52<34:24, 121.45s/it]Epoch: 8, train loss: 2.89703, f_loss_w: 0.00004, f_loss_uw: 2.89703, data loss: 0.22301:  32% 8/25 [15:25<29:23, 103.76s/it]Epoch: 8, train loss: 2.89703, f_loss_w: 0.00004, f_loss_uw: 2.89703, data loss: 0.22301:  36% 9/25 [15:25<25:44, 96.50s/it] Epoch: 9, train loss: 3.02465, f_loss_w: 0.00002, f_loss_uw: 3.02465, data loss: 0.19864:  36% 9/25 [16:22<25:44, 96.50s/it]Epoch: 9, train loss: 3.02465, f_loss_w: 0.00002, f_loss_uw: 3.02465, data loss: 0.19864:  40% 10/25 [16:22<22:36, 90.46s/it]Epoch: 10, train loss: 3.27393, f_loss_w: 0.00031, f_loss_uw: 3.27393, data loss: 0.28862:  40% 10/25 [17:36<22:36, 90.46s/it]Epoch: 10, train loss: 3.27393, f_loss_w: 0.00031, f_loss_uw: 3.27393, data loss: 0.28862:  44% 11/25 [17:36<20:33, 88.08s/it]Epoch: 11, train loss: 2.51957, f_loss_w: 0.00004, f_loss_uw: 2.51957, data loss: 0.19429:  44% 11/25 [18:32<20:33, 88.08s/it]Epoch: 11, train loss: 2.51957, f_loss_w: 0.00004, f_loss_uw: 2.51957, data loss: 0.19429:  48% 12/25 [18:32<18:07, 83.66s/it]Epoch: 12, train loss: 2.5  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 2.71118, f_loss_w: 0.14538, f_loss_uw: 2.71118, data loss: 0.37208:   0% 0/25 [03:19<?, ?it/s]Epoch: 0, train loss: 2.71118, f_loss_w: 0.14538, f_loss_uw: 2.71118, data loss: 0.37208:   4% 1/25 [03:19<1:19:46, 199.43s/it]Epoch: 1, train loss: 2.10671, f_loss_w: 0.06476, f_loss_uw: 2.10671, data loss: 0.16451:   4% 1/25 [10:10<1:19:46, 199.43s/it]Epoch: 1, train loss: 2.10671, f_loss_w: 0.06476, f_loss_uw: 2.10671, data loss: 0.16451:   8% 2/25 [10:10<1:59:04, 310.65s/it]Epoch: 2, train loss: 2.43868, f_loss_w: 0.05215, f_loss_uw: 2.43868, data loss: 0.13588:   8% 2/25 [15:57<1:59:04, 310.65s/it]Epoch: 2, train loss: 2.43868, f_loss_w: 0.05215, f_loss_uw: 2.43868, data loss: 0.13588:  12% 3/25 [15:57<1:58:51, 324.15s/it]Epoch: 3, train loss: 2.27854, f_loss_w: 0.03614, f_loss_uw: 2.27854, data loss: 0.12040:  12% 3/25 [19:32<1:58:51, 324.15s/it]Epoch: 3, train loss: 2.27854, f_loss_w: 0.03614, f_loss_uw: 2.27854, data loss: 0.12040:  16% 4/25 [19:32<1:42Epoch: 4, train loss: 2.32186, f_loss_w: 0.00037, f_loss_uw: 2.32186, data loss: 0.17222:  16% 4/25 [10:10<41:08, 117.54s/it]Epoch: 4, train loss: 2.32186, f_loss_w: 0.00037, f_loss_uw: 2.32186, data loss: 0.17222:  20% 5/25 [10:10<41:29, 124.45s/it]Epoch: 5, train loss: 2.13832, f_loss_w: 0.00041, f_loss_uw: 2.13832, data loss: 0.16809:  20% 5/25 [12:53<41:29, 124.45s/it]Epoch: 5, train loss: 2.13832, f_loss_w: 0.00041, f_loss_uw: 2.13832, data loss: 0.16809:  24% 6/25 [12:53<42:00, 132.64s/it]Epoch: 6, train loss: 2.22272, f_loss_w: 0.00042, f_loss_uw: 2.22272, data loss: 0.15967:  24% 6/25 [15:34<42:00, 132.64s/it]Epoch: 6, train loss: 2.22272, f_loss_w: 0.00042, f_loss_uw: 2.22272, data loss: 0.15967:  28% 7/25 [15:34<41:25, 138.09s/it]Epoch: 7, train loss: 2.64371, f_loss_w: 0.00048, f_loss_uw: 2.64371, data loss: 0.17860:  28% 7/25 [17:49<41:25, 138.09s/it]Epoch: 7, train loss: 2.64371, f_loss_w: 0.00048, f_loss_uw: 2.64371, data loss: 0.17860:  32% 8/25 [17:49<38:57, 137.51s/it]Epoch: 8, train06s/it]Epoch: 4, train loss: 2.74508, f_loss_w: 0.00005, f_loss_uw: 2.74508, data loss: 0.20165:  16% 4/25 [13:26<57:25, 164.06s/it]Epoch: 4, train loss: 2.74508, f_loss_w: 0.00005, f_loss_uw: 2.74508, data loss: 0.20165:  20% 5/25 [13:26<54:10, 162.53s/it]Epoch: 5, train loss: 3.88123, f_loss_w: 0.00014, f_loss_uw: 3.88123, data loss: 0.37539:  20% 5/25 [15:24<54:10, 162.53s/it]Epoch: 5, train loss: 3.88123, f_loss_w: 0.00014, f_loss_uw: 3.88123, data loss: 0.37539:  24% 6/25 [15:24<48:27, 153.04s/it]Epoch: 6, train loss: 2.84694, f_loss_w: 0.00026, f_loss_uw: 2.84694, data loss: 0.34410:  24% 6/25 [16:56<48:27, 153.04s/it]Epoch: 6, train loss: 2.84694, f_loss_w: 0.00026, f_loss_uw: 2.84694, data loss: 0.34410:  28% 7/25 [16:56<42:24, 141.38s/it]Epoch: 7, train loss: 4.07695, f_loss_w: 0.00011, f_loss_uw: 4.07695, data loss: 0.47017:  28% 7/25 [18:46<42:24, 141.38s/it]Epoch: 7, train loss: 4.07695, f_loss_w: 0.00011, f_loss_uw: 4.07695, data loss: 0.47017:  32% 8/25 [18:46<38:29, 135.84s/it]Epoch: 8  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 4.46617, f_loss_w: 305.64970, f_loss_uw: 4.46617, data loss: 0.41113:   0% 0/25 [04:04<?, ?it/s]Epoch: 0, train loss: 4.46617, f_loss_w: 305.64970, f_loss_uw: 4.46617, data loss: 0.41113:   4% 1/25 [04:04<1:37:37, 244.08s/it]Epoch: 1, train loss: 2.89296, f_loss_w: 234.60272, f_loss_uw: 2.89296, data loss: 0.20210:   4% 1/25 [08:29<1:37:37, 244.08s/it]Epoch: 1, train loss: 2.89296, f_loss_w: 234.60272, f_loss_uw: 2.89296, data loss: 0.20210:   8% 2/25 [08:29<1:37:48, 255.17s/it]Epoch: 2, train loss: 2.55215, f_loss_w: 375.10461, f_loss_uw: 2.55215, data loss: 0.16256:   8% 2/25 [14:41<1:37:48, 255.17s/it]Epoch: 2, train loss: 2.55215, f_loss_w: 375.10461, f_loss_uw: 2.55215, data loss: 0.16256:  12% 3/25 [14:41<1:49:25, 298.45s/it]Epoch: 3, train loss: 2.58560, f_loss_w: 349.46711, f_loss_uw: 2.58560, data loss: 0.14092:  12% 3/25 [20:32<1:49:25, 298.45s/it]Epoch: 3, train loss: 2.58560, f_loss_w: 349.46711, f_loss_uw: 2.58560, data loss: 0.14092:  16%   0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 6.10673, f_loss_w: 612923.14029, f_loss_uw: 6.10673, data loss: 1.77628:   0% 0/25 [10:25<?, ?it/s]Epoch: 0, train loss: 6.10673, f_loss_w: 612923.14029, f_loss_uw: 6.10673, data loss: 1.77628:   4% 1/25 [10:25<4:10:22, 625.94s/it]/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/CGDs/cgd_utils.py:201: UserWarning: CG iter num: 143
  warnings.warn('CG iter num: %d' % (i + 1))
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/CGDs/cgd_utils.py:201: UserWarning: CG iter num: 114
  warnings.warn('CG iter num: %d' % (i + 1))
 loss: 2.68050, f_loss_w: 0.00006, f_loss_uw: 2.68050, data loss: 0.20730:  32% 8/25 [17:19<34:03, 120.20s/it]Epoch: 8, train loss: 2.68050, f_loss_w: 0.00006, f_loss_uw: 2.68050, data loss: 0.20730:  36% 9/25 [17:19<29:57, 112.33s/it]Epoch: 9, train loss: 2.69328, f_loss_w: 0.00006, f_loss_uw: 2.69328, data loss: 0.17779:  36% 9/25 [18:29<29:57, 112.33s/it]Epoch: 9, train loss: 2.69328, f_loss_w: 0.00006, f_loss_uw: 2.69328, data loss: 0.17779:  40% 10/25 [18:29<26:26, 105.77s/it]Epoch: 10, train loss: 2.14265, f_loss_w: 0.00007, f_loss_uw: 2.14265, data loss: 0.14967:  40% 10/25 [19:38<26:26, 105.77s/it]Epoch: 10, train loss: 2.14265, f_loss_w: 0.00007, f_loss_uw: 2.14265, data loss: 0.14967:  44% 11/25 [19:38<23:25, 100.38s/it]Epoch: 11, train loss: 2.09372, f_loss_w: 0.00006, f_loss_uw: 2.09372, data loss: 0.18490:  44% 11/25 [20:53<23:25, 100.38s/it]Epoch: 11, train loss: 2.09372, f_loss_w: 0.00006, f_loss_uw: 2.09372, data loss: 0.18490:  48% 12/25 [20:53<20:58, 96.81s/it] Epoch: 12, train loss::10:56, 202.67s/it]Epoch: 4, train loss: 2.95709, f_loss_w: 0.00196, f_loss_uw: 2.95709, data loss: 0.17120:  16% 4/25 [16:31<1:10:56, 202.67s/it]Epoch: 4, train loss: 2.95709, f_loss_w: 0.00196, f_loss_uw: 2.95709, data loss: 0.17120:  20% 5/25 [16:31<1:05:53, 197.65s/it]Epoch: 5, train loss: 3.28410, f_loss_w: 0.00109, f_loss_uw: 3.28410, data loss: 0.15028:  20% 5/25 [18:52<1:05:53, 197.65s/it]Epoch: 5, train loss: 3.28410, f_loss_w: 0.00109, f_loss_uw: 3.28410, data loss: 0.15028:  24% 6/25 [18:52<58:49, 185.74s/it]  Epoch: 6, train loss: 3.02939, f_loss_w: 0.00034, f_loss_uw: 3.02939, data loss: 0.13909:  24% 6/25 [20:40<58:49, 185.74s/it]Epoch: 6, train loss: 3.02939, f_loss_w: 0.00034, f_loss_uw: 3.02939, data loss: 0.13909:  28% 7/25 [20:40<51:13, 170.73s/it]Epoch: 7, train loss: 2.79279, f_loss_w: 0.00025, f_loss_uw: 2.79279, data loss: 0.12516:  28% 7/25 [22:24<51:13, 170.73s/it]Epoch: 7, train loss: 2.79279, f_loss_w: 0.00025, f_loss_uw: 2.79279, data loss: 0.12516:  32% 8/25 [22:24<45:02,   0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.69895, f_loss_w: 0.19059, f_loss_uw: 3.69895, data loss: 0.40165:   0% 0/25 [05:31<?, ?it/s]Epoch: 0, train loss: 3.69895, f_loss_w: 0.19059, f_loss_uw: 3.69895, data loss: 0.40165:   4% 1/25 [05:31<2:12:36, 331.54s/it]Epoch: 1, train loss: 2.56415, f_loss_w: 0.21237, f_loss_uw: 2.56415, data loss: 0.13912:   4% 1/25 [12:46<2:12:36, 331.54s/it]Epoch: 1, train loss: 2.56415, f_loss_w: 0.21237, f_loss_uw: 2.56415, data loss: 0.13912:   8% 2/25 [12:46<2:27:52, 385.74s/it]Epoch: 2, train loss: 2.73734, f_loss_w: 0.07477, f_loss_uw: 2.73734, data loss: 0.12640:   8% 2/25 [17:43<2:27:52, 385.74s/it]Epoch: 2, train loss: 2.73734, f_loss_w: 0.07477, f_loss_uw: 2.73734, data loss: 0.12640:  12% 3/25 [17:43<2:09:27, 353.06s/it]Epoch: 3, train loss: 7.74864, f_loss_w: 0.13658, f_loss_uw: 7.74864, data loss: 0.20922:  12% 3/25 [22:51<2:09:27, 353.06s/it]Epoch: 3, train loss: 7.74864, f_loss_w: 0.13658, f_loss_uw: 7.74864, data loss: 0.20922:  16% 4/25 [22:51<1:598743, f_loss_w: 0.00001, f_loss_uw: 2.58743, data loss: 0.23190:  48% 12/25 [19:26<18:07, 83.66s/it]Epoch: 12, train loss: 2.58743, f_loss_w: 0.00001, f_loss_uw: 2.58743, data loss: 0.23190:  52% 13/25 [19:26<15:55, 79.66s/it]Epoch: 13, train loss: 2.64027, f_loss_w: 0.00001, f_loss_uw: 2.64027, data loss: 0.19098:  52% 13/25 [20:21<15:55, 79.66s/it]Epoch: 13, train loss: 2.64027, f_loss_w: 0.00001, f_loss_uw: 2.64027, data loss: 0.19098:  56% 14/25 [20:21<14:00, 76.44s/it]Epoch: 14, train loss: 2.42984, f_loss_w: 0.00002, f_loss_uw: 2.42984, data loss: 0.18120:  56% 14/25 [21:14<14:00, 76.44s/it]Epoch: 14, train loss: 2.42984, f_loss_w: 0.00002, f_loss_uw: 2.42984, data loss: 0.18120:  60% 15/25 [21:14<12:15, 73.50s/it]Epoch: 15, train loss: 2.16541, f_loss_w: 0.00001, f_loss_uw: 2.16541, data loss: 0.18901:  60% 15/25 [22:06<12:15, 73.50s/it]Epoch: 15, train loss: 2.16541, f_loss_w: 0.00001, f_loss_uw: 2.16541, data loss: 0.18901:  64% 16/25 [22:06<10:37, 70.86s/it]Epoch: 16, train loss: 2.64624, f_  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 4.22243, f_loss_w: 0.08822, f_loss_uw: 4.22243, data loss: 0.43153:   0% 0/25 [06:38<?, ?it/s]Epoch: 0, train loss: 4.22243, f_loss_w: 0.08822, f_loss_uw: 4.22243, data loss: 0.43153:   4% 1/25 [06:38<2:39:15, 398.13s/it]Epoch: 1, train loss: 3.93876, f_loss_w: 2.99832, f_loss_uw: 3.93876, data loss: 0.15303:   4% 1/25 [14:08<2:39:15, 398.13s/it]Epoch: 1, train loss: 3.93876, f_loss_w: 2.99832, f_loss_uw: 3.93876, data loss: 0.15303:   8% 2/25 [14:08<2:43:12, 425.76s/it]Epoch: 2, train loss: 4.02523, f_loss_w: 1.64975, f_loss_uw: 4.02523, data loss: 0.14816:   8% 2/25 [19:19<2:43:12, 425.76s/it]Epoch: 2, train loss: 4.02523, f_loss_w: 1.64975, f_loss_uw: 4.02523, data loss: 0.14816:  12% 3/25 [19:19<2:20:31, 383.24s/it]Epoch: 3, train loss: 7.16761, f_loss_w: 2.38391, f_loss_uw: 7.16761, data loss: 0.19741:  12% 3/25 [23:06<2:20:31, 383.24s/it]Epoch: 3, train loss: 7.16761, f_loss_w: 2.38391, f_loss_uw: 7.16761, data loss: 0.19741:  16% 4/25 [23:06<1:58  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.33056, f_loss_w: 3.23105, f_loss_uw: 3.33056, data loss: 0.34797:   0% 0/25 [07:51<?, ?it/s]Epoch: 0, train loss: 3.33056, f_loss_w: 3.23105, f_loss_uw: 3.33056, data loss: 0.34797:   4% 1/25 [07:51<3:08:43, 471.82s/it]Epoch: 1, train loss: 2.49784, f_loss_w: 1.25775, f_loss_uw: 2.49784, data loss: 0.12415:   4% 1/25 [13:38<3:08:43, 471.82s/it]Epoch: 1, train loss: 2.49784, f_loss_w: 1.25775, f_loss_uw: 2.49784, data loss: 0.12415:   8% 2/25 [13:38<2:35:32, 405.76s/it]Epoch: 2, train loss: 3.74077, f_loss_w: 2.94450, f_loss_uw: 3.74077, data loss: 0.14237:   8% 2/25 [18:19<2:35:32, 405.76s/it]Epoch: 2, train loss: 3.74077, f_loss_w: 2.94450, f_loss_uw: 3.74077, data loss: 0.14237:  12% 3/25 [18:19<2:12:00, 360.01s/it]Epoch: 3, train loss: 2.13080, f_loss_w: 1.87735, f_loss_uw: 2.13080, data loss: 0.09876:  12% 3/25 [23:20<2:12:00, 360.01s/it]Epoch: 3, train loss: 2.13080, f_loss_w: 1.87735, f_loss_uw: 2.13080, data loss: 0.09876:  16% 4/25 [23:20<1:59  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 2.36677, f_loss_w: 0.26729, f_loss_uw: 2.36677, data loss: 0.33963:   0% 0/25 [05:42<?, ?it/s]Epoch: 0, train loss: 2.36677, f_loss_w: 0.26729, f_loss_uw: 2.36677, data loss: 0.33963:   4% 1/25 [05:42<2:16:56, 342.35s/it]Epoch: 1, train loss: 2.36532, f_loss_w: 1.20484, f_loss_uw: 2.36532, data loss: 0.14551:   4% 1/25 [14:22<2:16:56, 342.35s/it]Epoch: 1, train loss: 2.36532, f_loss_w: 1.20484, f_loss_uw: 2.36532, data loss: 0.14551:   8% 2/25 [14:22<2:47:01, 435.73s/it]Epoch: 2, train loss: 2.97190, f_loss_w: 0.61426, f_loss_uw: 2.97190, data loss: 0.14102:   8% 2/25 [19:41<2:47:01, 435.73s/it]Epoch: 2, train loss: 2.97190, f_loss_w: 0.61426, f_loss_uw: 2.97190, data loss: 0.14102:  12% 3/25 [19:41<2:24:01, 392.79s/it]Epoch: 3, train loss: 2.51870, f_loss_w: 0.41178, f_loss_uw: 2.51870, data loss: 0.10185:  12% 3/25 [23:30<2:24:01, 392.79s/it]Epoch: 3, train loss: 2.51870, f_loss_w: 0.41178, f_loss_uw: 2.51870, data loss: 0.10185:  16% 4/25 [23:30<2:00in loss: 2.97434, f_loss_w: 0.00016, f_loss_uw: 2.97434, data loss: 0.23793:  32% 8/25 [18:11<34:24, 121.45s/it]Epoch: 8, train loss: 2.97434, f_loss_w: 0.00016, f_loss_uw: 2.97434, data loss: 0.23793:  36% 9/25 [18:11<30:30, 114.40s/it]Epoch: 9, train loss: 3.34202, f_loss_w: 0.00003, f_loss_uw: 3.34202, data loss: 0.40150:  36% 9/25 [19:29<30:30, 114.40s/it]Epoch: 9, train loss: 3.34202, f_loss_w: 0.00003, f_loss_uw: 3.34202, data loss: 0.40150:  40% 10/25 [19:29<27:12, 108.82s/it]Epoch: 10, train loss: 2.89095, f_loss_w: 0.00026, f_loss_uw: 2.89095, data loss: 0.31664:  40% 10/25 [20:44<27:12, 108.82s/it]Epoch: 10, train loss: 2.89095, f_loss_w: 0.00026, f_loss_uw: 2.89095, data loss: 0.31664:  44% 11/25 [20:44<24:15, 103.94s/it]Epoch: 11, train loss: 2.16698, f_loss_w: 0.00003, f_loss_uw: 2.16698, data loss: 0.32780:  44% 11/25 [22:28<24:15, 103.94s/it]Epoch: 11, train loss: 2.16698, f_loss_w: 0.00003, f_loss_uw: 2.16698, data loss: 0.32780:  48% 12/25 [22:28<22:32, 104.01s/it]Epoch: 12, train los1<1:12:14, 206.42s/it]Epoch: 4, train loss: 2.69238, f_loss_w: 0.00221, f_loss_uw: 2.69238, data loss: 0.13007:  16% 4/25 [17:05<1:12:14, 206.42s/it]Epoch: 4, train loss: 2.69238, f_loss_w: 0.00221, f_loss_uw: 2.69238, data loss: 0.13007:  20% 5/25 [17:05<1:07:44, 203.24s/it]Epoch: 5, train loss: 2.57556, f_loss_w: 0.00167, f_loss_uw: 2.57556, data loss: 0.12147:  20% 5/25 [20:21<1:07:44, 203.24s/it]Epoch: 5, train loss: 2.57556, f_loss_w: 0.00167, f_loss_uw: 2.57556, data loss: 0.12147:  24% 6/25 [20:21<1:03:53, 201.76s/it]Epoch: 6, train loss: 2.99336, f_loss_w: 0.00072, f_loss_uw: 2.99336, data loss: 0.15421:  24% 6/25 [22:37<1:03:53, 201.76s/it]Epoch: 6, train loss: 2.99336, f_loss_w: 0.00072, f_loss_uw: 2.99336, data loss: 0.15421:  28% 7/25 [22:37<56:45, 189.18s/it]  Epoch: 7, train loss: 2.96020, f_loss_w: 0.00027, f_loss_uw: 2.96020, data loss: 0.17267:  28% 7/25 [24:16<56:45, 189.18s/it]Epoch: 7, train loss: 2.96020, f_loss_w: 0.00027, f_loss_uw: 2.96020, data loss: 0.17267:  32% 8/25 [24:16<:00:12, 172.01s/it]Epoch: 4, train loss: 1.98629, f_loss_w: 0.00023, f_loss_uw: 1.98629, data loss: 0.15690:  16% 4/25 [14:17<1:00:12, 172.01s/it]Epoch: 4, train loss: 1.98629, f_loss_w: 0.00023, f_loss_uw: 1.98629, data loss: 0.15690:  20% 5/25 [14:17<56:37, 169.87s/it]  Epoch: 5, train loss: 2.01948, f_loss_w: 0.00073, f_loss_uw: 2.01948, data loss: 0.15478:  20% 5/25 [17:59<56:37, 169.87s/it]Epoch: 5, train loss: 2.01948, f_loss_w: 0.00073, f_loss_uw: 2.01948, data loss: 0.15478:  24% 6/25 [17:59<57:19, 181.04s/it]Epoch: 6, train loss: 2.74161, f_loss_w: 0.00132, f_loss_uw: 2.74161, data loss: 0.19104:  24% 6/25 [21:12<57:19, 181.04s/it]Epoch: 6, train loss: 2.74161, f_loss_w: 0.00132, f_loss_uw: 2.74161, data loss: 0.19104:  28% 7/25 [21:12<54:58, 183.23s/it]Epoch: 7, train loss: 3.24857, f_loss_w: 0.00046, f_loss_uw: 3.24857, data loss: 0.18089:  28% 7/25 [24:28<54:58, 183.23s/it]Epoch: 7, train loss: 3.24857, f_loss_w: 0.00046, f_loss_uw: 3.24857, data loss: 0.18089:  32% 8/25 [24:28<52:34, 185., train loss: 2.79941, f_loss_w: 0.00017, f_loss_uw: 2.79941, data loss: 0.24598:  32% 8/25 [20:06<38:29, 135.84s/it]Epoch: 8, train loss: 2.79941, f_loss_w: 0.00017, f_loss_uw: 2.79941, data loss: 0.24598:  36% 9/25 [20:06<33:47, 126.69s/it]Epoch: 9, train loss: 4.14217, f_loss_w: 0.00039, f_loss_uw: 4.14217, data loss: 0.53306:  36% 9/25 [21:35<33:47, 126.69s/it]Epoch: 9, train loss: 4.14217, f_loss_w: 0.00039, f_loss_uw: 4.14217, data loss: 0.53306:  40% 10/25 [21:35<30:14, 120.95s/it]Epoch: 10, train loss: 3.95899, f_loss_w: 0.00002, f_loss_uw: 3.95899, data loss: 0.46386:  40% 10/25 [23:09<30:14, 120.95s/it]Epoch: 10, train loss: 3.95899, f_loss_w: 0.00002, f_loss_uw: 3.95899, data loss: 0.46386:  44% 11/25 [23:09<27:18, 117.05s/it]Epoch: 11, train loss: 3.53449, f_loss_w: 0.00002, f_loss_uw: 3.53449, data loss: 0.37567:  44% 11/25 [24:21<27:18, 117.05s/it]Epoch: 11, train loss: 3.53449, f_loss_w: 0.00002, f_loss_uw: 3.53449, data loss: 0.37567:  48% 12/25 [24:21<24:00, 110.79s/it]Epoch: 12, traiEpoch: 1, train loss: 124.41685, f_loss_w: 4337819052.54000, f_loss_uw: 124.41685, data loss: 4.40145:   4% 1/25 [20:48<4:10:22, 625.94s/it]Epoch: 1, train loss: 124.41685, f_loss_w: 4337819052.54000, f_loss_uw: 124.41685, data loss: 4.40145:   8% 2/25 [20:48<3:59:20, 624.37s/it]Epoch: 2, train loss: 67.05063, f_loss_w: 90029876.49000, f_loss_uw: 67.05063, data loss: 1.01965:   8% 2/25 [22:27<3:59:20, 624.37s/it]    Epoch: 2, train loss: 67.05063, f_loss_w: 90029876.49000, f_loss_uw: 67.05063, data loss: 1.01965:  12% 3/25 [22:27<2:37:51, 430.54s/it]Epoch: 3, train loss: 42.22185, f_loss_w: 109986307.20000, f_loss_uw: 42.22185, data loss: 0.72493:  12% 3/25 [24:21<2:37:51, 430.54s/it]Epoch: 3, train loss: 42.22185, f_loss_w: 109986307.20000, f_loss_uw: 42.22185, data loss: 0.72493:  16% 4/25 [24:21<1:58:22, 338.23s/it]Epoch: 4, train loss: 29.47683, f_loss_w: 120023226.40000, f_loss_uw: 29.47683, data loss: 0.56011:  16% 4/25 [26:20<1:58:22, 338.23s/it]Epoch: 4, train loss: 29.47683, f_loss_w: 1200232loss_w: 0.00001, f_loss_uw: 2.64624, data loss: 0.18812:  64% 16/25 [22:59<10:37, 70.86s/it]Epoch: 16, train loss: 2.64624, f_loss_w: 0.00001, f_loss_uw: 2.64624, data loss: 0.18812:  68% 17/25 [22:59<09:09, 68.64s/it]Epoch: 17, train loss: 2.24829, f_loss_w: 0.00001, f_loss_uw: 2.24829, data loss: 0.15634:  68% 17/25 [23:53<09:09, 68.64s/it]Epoch: 17, train loss: 2.24829, f_loss_w: 0.00001, f_loss_uw: 2.24829, data loss: 0.15634:  72% 18/25 [23:53<07:48, 66.94s/it]Epoch: 18, train loss: 2.22003, f_loss_w: 0.00000, f_loss_uw: 2.22003, data loss: 0.17870:  72% 18/25 [24:47<07:48, 66.94s/it]Epoch: 18, train loss: 2.22003, f_loss_w: 0.00000, f_loss_uw: 2.22003, data loss: 0.17870:  76% 19/25 [24:47<06:32, 65.43s/it]Epoch: 19, train loss: 2.23650, f_loss_w: 0.00001, f_loss_uw: 2.23650, data loss: 0.16150:  76% 19/25 [25:39<06:32, 65.43s/it]Epoch: 19, train loss: 2.23650, f_loss_w: 0.00001, f_loss_uw: 2.23650, data loss: 0.16150:  80% 20/25 [25:39<05:19, 63.98s/it]Epoch: 20, train loss: 2.13382, f_loss_w: :16, 232.23s/it]Epoch: 4, train loss: 2.24759, f_loss_w: 0.00625, f_loss_uw: 2.24759, data loss: 0.10747:  16% 4/25 [19:40<1:21:16, 232.23s/it]Epoch: 4, train loss: 2.24759, f_loss_w: 0.00625, f_loss_uw: 2.24759, data loss: 0.10747:  20% 5/25 [19:40<1:17:17, 231.86s/it]Epoch: 5, train loss: 2.13880, f_loss_w: 0.00090, f_loss_uw: 2.13880, data loss: 0.09271:  20% 5/25 [22:32<1:17:17, 231.86s/it]Epoch: 5, train loss: 2.13880, f_loss_w: 0.00090, f_loss_uw: 2.13880, data loss: 0.09271:  24% 6/25 [22:32<1:09:20, 218.97s/it]Epoch: 6, train loss: 1.98174, f_loss_w: 0.00085, f_loss_uw: 1.98174, data loss: 0.09463:  24% 6/25 [24:51<1:09:20, 218.97s/it]Epoch: 6, train loss: 1.98174, f_loss_w: 0.00085, f_loss_uw: 1.98174, data loss: 0.09463:  28% 7/25 [24:51<1:01:06, 203.68s/it]Epoch: 7, train loss: 2.35139, f_loss_w: 0.00383, f_loss_uw: 2.35139, data loss: 0.21426:  28% 7/25 [26:45<1:01:06, 203.68s/it]Epoch: 7, train loss: 2.35139, f_loss_w: 0.00383, f_loss_uw: 2.35139, data loss: 0.21426:  32% 8/25 [26:45<53:1 2.45033, f_loss_w: 0.00005, f_loss_uw: 2.45033, data loss: 0.15024:  48% 12/25 [22:09<20:58, 96.81s/it]Epoch: 12, train loss: 2.45033, f_loss_w: 0.00005, f_loss_uw: 2.45033, data loss: 0.15024:  52% 13/25 [22:09<18:49, 94.13s/it]Epoch: 13, train loss: 2.38576, f_loss_w: 0.00007, f_loss_uw: 2.38576, data loss: 0.16846:  52% 13/25 [23:20<18:49, 94.13s/it]Epoch: 13, train loss: 2.38576, f_loss_w: 0.00007, f_loss_uw: 2.38576, data loss: 0.16846:  56% 14/25 [23:20<16:41, 91.04s/it]Epoch: 14, train loss: 2.26316, f_loss_w: 0.00011, f_loss_uw: 2.26316, data loss: 0.15293:  56% 14/25 [24:33<16:41, 91.04s/it]Epoch: 14, train loss: 2.26316, f_loss_w: 0.00011, f_loss_uw: 2.26316, data loss: 0.15293:  60% 15/25 [24:33<14:48, 88.87s/it]Epoch: 15, train loss: 2.69812, f_loss_w: 0.00018, f_loss_uw: 2.69812, data loss: 0.22850:  60% 15/25 [25:40<14:48, 88.87s/it]Epoch: 15, train loss: 2.69812, f_loss_w: 0.00018, f_loss_uw: 2.69812, data loss: 0.22850:  64% 16/25 [25:40<12:55, 86.14s/it]Epoch: 16, train loss: 2.05457h: 8, train loss: 2.40651, f_loss_w: 0.00010, f_loss_uw: 2.40651, data loss: 0.22223:  32% 8/25 [16:54<31:48, 112.29s/it]Epoch: 8, train loss: 2.40651, f_loss_w: 0.00010, f_loss_uw: 2.40651, data loss: 0.22223:  36% 9/25 [16:54<28:28, 106.81s/it]Epoch: 9, train loss: 2.71806, f_loss_w: 0.00019, f_loss_uw: 2.71806, data loss: 0.25695:  36% 9/25 [18:20<28:28, 106.81s/it]Epoch: 9, train loss: 2.71806, f_loss_w: 0.00019, f_loss_uw: 2.71806, data loss: 0.25695:  40% 10/25 [18:21<25:56, 103.77s/it]Epoch: 10, train loss: 3.84866, f_loss_w: 0.00242, f_loss_uw: 3.84866, data loss: 0.48073:  40% 10/25 [20:00<25:56, 103.77s/it]Epoch: 10, train loss: 3.84866, f_loss_w: 0.00242, f_loss_uw: 3.84866, data loss: 0.48073:  44% 11/25 [20:00<24:04, 103.17s/it]Epoch: 11, train loss: 597.86509, f_loss_w: 9.98006, f_loss_uw: 597.86509, data loss: 13.42527:  44% 11/25 [24:13<24:04, 103.17s/it]Epoch: 11, train loss: 597.86509, f_loss_w: 9.98006, f_loss_uw: 597.86509, data loss: 13.42527:  48% 12/25 [24:13<26:52, 124.07s/it]E158.97s/it]Epoch: 8, train loss: 3.26015, f_loss_w: 0.00062, f_loss_uw: 3.26015, data loss: 0.19590:  32% 8/25 [24:06<45:02, 158.97s/it]Epoch: 8, train loss: 3.26015, f_loss_w: 0.00062, f_loss_uw: 3.26015, data loss: 0.19590:  36% 9/25 [24:06<39:55, 149.74s/it]Epoch: 9, train loss: 2.65769, f_loss_w: 0.00038, f_loss_uw: 2.65769, data loss: 0.15079:  36% 9/25 [25:43<39:55, 149.74s/it]Epoch: 9, train loss: 2.65769, f_loss_w: 0.00038, f_loss_uw: 2.65769, data loss: 0.15079:  40% 10/25 [25:43<35:23, 141.57s/it]Epoch: 10, train loss: 3.40135, f_loss_w: 0.00007, f_loss_uw: 3.40135, data loss: 0.20977:  40% 10/25 [26:45<35:23, 141.57s/it]Epoch: 10, train loss: 3.40135, f_loss_w: 0.00007, f_loss_uw: 3.40135, data loss: 0.20977:  44% 11/25 [26:45<30:19, 130.00s/it]Epoch: 11, train loss: 2.72949, f_loss_w: 0.00011, f_loss_uw: 2.72949, data loss: 0.16868:  44% 11/25 [27:45<30:19, 130.00s/it]Epoch: 11, train loss: 2.72949, f_loss_w: 0.00011, f_loss_uw: 2.72949, data loss: 0.16868:  48% 12/25 [27:45<26:03, 120.27s  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 3.26328, f_loss_w: 5219.06205, f_loss_uw: 3.26328, data loss: 0.34315:   0% 0/25 [07:30<?, ?it/s]Epoch: 0, train loss: 3.26328, f_loss_w: 5219.06205, f_loss_uw: 3.26328, data loss: 0.34315:   4% 1/25 [07:30<3:00:15, 450.63s/it]Epoch: 1, train loss: 2.33249, f_loss_w: 20615.29967, f_loss_uw: 2.33249, data loss: 0.15400:   4% 1/25 [16:01<3:00:15, 450.63s/it]Epoch: 1, train loss: 2.33249, f_loss_w: 20615.29967, f_loss_uw: 2.33249, data loss: 0.15400:   8% 2/25 [16:01<3:04:52, 482.28s/it]Epoch: 2, train loss: 2.28944, f_loss_w: 28921.58406, f_loss_uw: 2.28944, data loss: 0.13679:   8% 2/25 [22:14<3:04:52, 482.28s/it]Epoch: 2, train loss: 2.28944, f_loss_w: 28921.58406, f_loss_uw: 2.28944, data loss: 0.13679:  12% 3/25 [22:14<2:41:59, 441.82s/it]Epoch: 3, train loss: 2.13981, f_loss_w: 31699.69771, f_loss_uw: 2.13981, data loss: 0.12741:  12% 3/25 [28:58<2:41:59, 441.82s/it]Epoch: 3, train loss: 2.13981, f_loss_w: 31699.69771, f_loss_uw: 2.13981, data loss: s: 2.75583, f_loss_w: 0.00001, f_loss_uw: 2.75583, data loss: 0.18931:  48% 12/25 [24:15<22:32, 104.01s/it]Epoch: 12, train loss: 2.75583, f_loss_w: 0.00001, f_loss_uw: 2.75583, data loss: 0.18931:  52% 13/25 [24:15<20:52, 104.35s/it]Epoch: 13, train loss: 3.07601, f_loss_w: 0.00012, f_loss_uw: 3.07601, data loss: 0.23804:  52% 13/25 [25:43<20:52, 104.35s/it]Epoch: 13, train loss: 3.07601, f_loss_w: 0.00012, f_loss_uw: 3.07601, data loss: 0.23804:  56% 14/25 [25:43<18:43, 102.17s/it]Epoch: 14, train loss: 2.58427, f_loss_w: 0.00003, f_loss_uw: 2.58427, data loss: 0.32721:  56% 14/25 [27:03<18:43, 102.17s/it]Epoch: 14, train loss: 2.58427, f_loss_w: 0.00003, f_loss_uw: 2.58427, data loss: 0.32721:  60% 15/25 [27:03<16:34, 99.45s/it] Epoch: 15, train loss: 2.70172, f_loss_w: 0.00001, f_loss_uw: 2.70172, data loss: 0.22638:  60% 15/25 [28:19<16:34, 99.45s/it]Epoch: 15, train loss: 2.70172, f_loss_w: 0.00001, f_loss_uw: 2.70172, data loss: 0.22638:  64% 16/25 [28:19<14:29, 96.61s/it]Epoch: 16, train loss:2<1:32:25, 264.08s/it]Epoch: 4, train loss: 3.73829, f_loss_w: 0.00524, f_loss_uw: 3.73829, data loss: 0.21517:  16% 4/25 [20:33<1:32:25, 264.08s/it]   Epoch: 4, train loss: 3.73829, f_loss_w: 0.00524, f_loss_uw: 3.73829, data loss: 0.21517:  20% 5/25 [20:33<1:20:28, 241.40s/it]Epoch: 5, train loss: 3.04456, f_loss_w: 0.00561, f_loss_uw: 3.04456, data loss: 0.19037:  20% 5/25 [22:47<1:20:28, 241.40s/it]Epoch: 5, train loss: 3.04456, f_loss_w: 0.00561, f_loss_uw: 3.04456, data loss: 0.19037:  24% 6/25 [22:47<1:09:10, 218.47s/it]Epoch: 6, train loss: 2.69370, f_loss_w: 0.00714, f_loss_uw: 2.69370, data loss: 0.14887:  24% 6/25 [26:46<1:09:10, 218.47s/it]Epoch: 6, train loss: 2.69370, f_loss_w: 0.00714, f_loss_uw: 2.69370, data loss: 0.14887:  28% 7/25 [26:46<1:06:44, 222.47s/it]Epoch: 7, train loss: 3.12422, f_loss_w: 0.00448, f_loss_uw: 3.12422, data loss: 0.14564:  28% 7/25 [29:54<1:06:44, 222.47s/it]Epoch: 7, train loss: 3.12422, f_loss_w: 0.00448, f_loss_uw: 3.12422, data loss: 0.14564:  32% 8/25 [2:18, 292.30s/it]Epoch: 4, train loss: 2.03659, f_loss_w: 0.00797, f_loss_uw: 2.03659, data loss: 0.12065:  16% 4/25 [21:16<1:42:18, 292.30s/it]Epoch: 4, train loss: 2.03659, f_loss_w: 0.00797, f_loss_uw: 2.03659, data loss: 0.12065:  20% 5/25 [21:16<1:22:06, 246.35s/it]Epoch: 5, train loss: 2.28158, f_loss_w: 0.01032, f_loss_uw: 2.28158, data loss: 0.09747:  20% 5/25 [23:57<1:22:06, 246.35s/it]Epoch: 5, train loss: 2.28158, f_loss_w: 0.01032, f_loss_uw: 2.28158, data loss: 0.09747:  24% 6/25 [23:57<1:12:14, 228.15s/it]Epoch: 6, train loss: 2.25586, f_loss_w: 0.01820, f_loss_uw: 2.25586, data loss: 0.08993:  24% 6/25 [26:57<1:12:14, 228.15s/it]Epoch: 6, train loss: 2.25586, f_loss_w: 0.01820, f_loss_uw: 2.25586, data loss: 0.08993:  28% 7/25 [26:57<1:05:39, 218.88s/it]Epoch: 7, train loss: 2.32614, f_loss_w: 0.01138, f_loss_uw: 2.32614, data loss: 0.07858:  28% 7/25 [30:46<1:05:39, 218.88s/it]Epoch: 7, train loss: 2.32614, f_loss_w: 0.01138, f_loss_uw: 2.32614, data loss: 0.07858:  32% 8/25 [30:46<1:02n loss: 4.56193, f_loss_w: 0.00019, f_loss_uw: 4.56193, data loss: 0.37326:  48% 12/25 [26:12<24:00, 110.79s/it]Epoch: 12, train loss: 4.56193, f_loss_w: 0.00019, f_loss_uw: 4.56193, data loss: 0.37326:  52% 13/25 [26:12<22:09, 110.80s/it]Epoch: 13, train loss: 5.15128, f_loss_w: 0.00005, f_loss_uw: 5.15128, data loss: 0.59708:  52% 13/25 [27:49<22:09, 110.80s/it]Epoch: 13, train loss: 5.15128, f_loss_w: 0.00005, f_loss_uw: 5.15128, data loss: 0.59708:  56% 14/25 [27:49<19:58, 108.98s/it]Epoch: 14, train loss: 3.45823, f_loss_w: 0.00010, f_loss_uw: 3.45823, data loss: 0.29935:  56% 14/25 [28:57<19:58, 108.98s/it]Epoch: 14, train loss: 3.45823, f_loss_w: 0.00010, f_loss_uw: 3.45823, data loss: 0.29935:  60% 15/25 [28:57<17:17, 103.79s/it]Epoch: 15, train loss: 3.69087, f_loss_w: 0.00008, f_loss_uw: 3.69087, data loss: 0.37300:  60% 15/25 [30:02<17:17, 103.79s/it]Epoch: 15, train loss: 3.69087, f_loss_w: 0.00008, f_loss_uw: 3.69087, data loss: 0.37300:  64% 16/25 [30:02<14:51, 99.05s/it] Epoch: 16, trai:15:08, 214.67s/it]Epoch: 4, train loss: 2.87165, f_loss_w: 0.00654, f_loss_uw: 2.87165, data loss: 0.19655:  16% 4/25 [17:22<1:15:08, 214.67s/it]Epoch: 4, train loss: 2.87165, f_loss_w: 0.00654, f_loss_uw: 2.87165, data loss: 0.19655:  20% 5/25 [17:22<1:09:06, 207.34s/it]Epoch: 5, train loss: 2.54838, f_loss_w: 0.01590, f_loss_uw: 2.54838, data loss: 0.13509:  20% 5/25 [21:50<1:09:06, 207.34s/it]Epoch: 5, train loss: 2.54838, f_loss_w: 0.01590, f_loss_uw: 2.54838, data loss: 0.13509:  24% 6/25 [21:50<1:09:42, 220.11s/it]Epoch: 6, train loss: 2.96073, f_loss_w: 0.04332, f_loss_uw: 2.96073, data loss: 0.17099:  24% 6/25 [25:39<1:09:42, 220.11s/it]Epoch: 6, train loss: 2.96073, f_loss_w: 0.04332, f_loss_uw: 2.96073, data loss: 0.17099:  28% 7/25 [25:39<1:06:35, 221.95s/it]Epoch: 7, train loss: 2.55805, f_loss_w: 0.01943, f_loss_uw: 2.55805, data loss: 0.09505:  28% 7/25 [31:30<1:06:35, 221.95s/it]Epoch: 7, train loss: 2.55805, f_loss_w: 0.01943, f_loss_uw: 2.55805, data loss: 0.09505:  32% 8/25 [31:30<118:00<1:35:49, 273.79s/it]Epoch: 4, train loss: 15.20903, f_loss_w: -0.00390, f_loss_uw: 15.20903, data loss: 0.38370:  16% 4/25 [22:06<1:35:49, 273.79s/it]Epoch: 4, train loss: 15.20903, f_loss_w: -0.00390, f_loss_uw: 15.20903, data loss: 0.38370:  20% 5/25 [22:06<1:28:59, 266.98s/it]Epoch: 5, train loss: 4.61807, f_loss_w: 0.00082, f_loss_uw: 4.61807, data loss: 0.20274:  20% 5/25 [25:01<1:28:59, 266.98s/it]   Epoch: 5, train loss: 4.61807, f_loss_w: 0.00082, f_loss_uw: 4.61807, data loss: 0.20274:  24% 6/25 [25:01<1:18:20, 247.39s/it]Epoch: 6, train loss: 3.47752, f_loss_w: 0.00123, f_loss_uw: 3.47752, data loss: 0.16567:  24% 6/25 [28:01<1:18:20, 247.39s/it]Epoch: 6, train loss: 3.47752, f_loss_w: 0.00123, f_loss_uw: 3.47752, data loss: 0.16567:  28% 7/25 [28:01<1:10:22, 234.59s/it]Epoch: 7, train loss: 3.29256, f_loss_w: 0.00644, f_loss_uw: 3.29256, data loss: 0.16337:  28% 7/25 [31:42<1:10:22, 234.59s/it]Epoch: 7, train loss: 3.29256, f_loss_w: 0.00644, f_loss_uw: 3.29256, data loss: 0.16337:  3:27, 267.03s/it]Epoch: 4, train loss: 3.21116, f_loss_w: 0.00984, f_loss_uw: 3.21116, data loss: 0.13085:  16% 4/25 [21:34<1:33:27, 267.03s/it]Epoch: 4, train loss: 3.21116, f_loss_w: 0.00984, f_loss_uw: 3.21116, data loss: 0.13085:  20% 5/25 [21:34<1:25:00, 255.01s/it]Epoch: 5, train loss: 3.58286, f_loss_w: 0.00668, f_loss_uw: 3.58286, data loss: 0.12860:  20% 5/25 [24:48<1:25:00, 255.01s/it]Epoch: 5, train loss: 3.58286, f_loss_w: 0.00668, f_loss_uw: 3.58286, data loss: 0.12860:  24% 6/25 [24:48<1:16:36, 241.91s/it]Epoch: 6, train loss: 11.16359, f_loss_w: 0.04725, f_loss_uw: 11.16359, data loss: 0.23064:  24% 6/25 [28:06<1:16:36, 241.91s/it]Epoch: 6, train loss: 11.16359, f_loss_w: 0.04725, f_loss_uw: 11.16359, data loss: 0.23064:  28% 7/25 [28:06<1:10:04, 233.60s/it]Epoch: 7, train loss: 10.19485, f_loss_w: 0.07496, f_loss_uw: 10.19485, data loss: 0.26067:  28% 7/25 [31:45<1:10:04, 233.60s/it]Epoch: 7, train loss: 10.19485, f_loss_w: 0.07496, f_loss_uw: 10.19485, data loss: 0.26067:  32% 8/25 [31  0% 0/25 [00:00<?, ?it/s]Epoch: 0, train loss: 4.47856, f_loss_w: 23.55277, f_loss_uw: 4.47856, data loss: 0.31747:   0% 0/25 [09:21<?, ?it/s]Epoch: 0, train loss: 4.47856, f_loss_w: 23.55277, f_loss_uw: 4.47856, data loss: 0.31747:   4% 1/25 [09:21<3:44:37, 561.56s/it]Epoch: 1, train loss: 2.00123, f_loss_w: 28.85248, f_loss_uw: 2.00123, data loss: 0.11517:   4% 1/25 [18:59<3:44:37, 561.56s/it]Epoch: 1, train loss: 2.00123, f_loss_w: 28.85248, f_loss_uw: 2.00123, data loss: 0.11517:   8% 2/25 [18:59<3:38:32, 570.12s/it]Epoch: 2, train loss: 3.74093, f_loss_w: 379.90590, f_loss_uw: 3.74093, data loss: 0.13535:   8% 2/25 [27:03<3:38:32, 570.12s/it]Epoch: 2, train loss: 3.74093, f_loss_w: 379.90590, f_loss_uw: 3.74093, data loss: 0.13535:  12% 3/25 [27:03<3:17:24, 538.40s/it]Epoch: 3, train loss: 3.47841, f_loss_w: 287.22751, f_loss_uw: 3.47841, data loss: 0.12036:  12% 3/25 [31:40<3:17:24, 538.40s/it]Epoch: 3, train loss: 3.47841, f_loss_w: 287.22751, f_loss_uw: 3.47841, data loss: 0.12036:  16% 4/25/it]Epoch: 12, train loss: 2.74552, f_loss_w: 0.00011, f_loss_uw: 2.74552, data loss: 0.13107:  48% 12/25 [28:53<26:03, 120.27s/it]Epoch: 12, train loss: 2.74552, f_loss_w: 0.00011, f_loss_uw: 2.74552, data loss: 0.13107:  52% 13/25 [28:53<22:38, 113.25s/it]Epoch: 13, train loss: 2.60840, f_loss_w: 0.00015, f_loss_uw: 2.60840, data loss: 0.12506:  52% 13/25 [30:06<22:38, 113.25s/it]Epoch: 13, train loss: 2.60840, f_loss_w: 0.00015, f_loss_uw: 2.60840, data loss: 0.12506:  56% 14/25 [30:06<19:48, 108.02s/it]Epoch: 14, train loss: 2.61403, f_loss_w: 0.00011, f_loss_uw: 2.61403, data loss: 0.13176:  56% 14/25 [31:13<19:48, 108.02s/it]Epoch: 14, train loss: 2.61403, f_loss_w: 0.00011, f_loss_uw: 2.61403, data loss: 0.13176:  60% 15/25 [31:13<17:08, 102.84s/it]Epoch: 15, train loss: 3.22933, f_loss_w: 0.00014, f_loss_uw: 3.22933, data loss: 0.17218:  60% 15/25 [32:27<17:08, 102.84s/it]Epoch: 15, train loss: 3.22933, f_loss_w: 0.00014, f_loss_uw: 3.22933, data loss: 0.17218:  64% 16/25 [32:27<14:53, 99.29s/ loss: 2.43843, f_loss_w: 0.00014, f_loss_uw: 2.43843, data loss: 0.13985:  32% 8/25 [19:49<38:57, 137.51s/it]Epoch: 8, train loss: 2.43843, f_loss_w: 0.00014, f_loss_uw: 2.43843, data loss: 0.13985:  36% 9/25 [19:49<35:54, 134.67s/it]Epoch: 9, train loss: 2.42587, f_loss_w: 0.00029, f_loss_uw: 2.42587, data loss: 0.15587:  36% 9/25 [22:07<35:54, 134.67s/it]Epoch: 9, train loss: 2.42587, f_loss_w: 0.00029, f_loss_uw: 2.42587, data loss: 0.15587:  40% 10/25 [22:07<33:47, 135.14s/it]Epoch: 10, train loss: 2.25377, f_loss_w: 0.00090, f_loss_uw: 2.25377, data loss: 0.14817:  40% 10/25 [24:57<33:47, 135.14s/it]Epoch: 10, train loss: 2.25377, f_loss_w: 0.00090, f_loss_uw: 2.25377, data loss: 0.14817:  44% 11/25 [24:57<32:42, 140.19s/it]Epoch: 11, train loss: 2.38288, f_loss_w: 0.00200, f_loss_uw: 2.38288, data loss: 0.15095:  44% 11/25 [28:22<32:42, 140.19s/it]Epoch: 11, train loss: 2.38288, f_loss_w: 0.00200, f_loss_uw: 2.38288, data loss: 0.15095:  48% 12/25 [28:22<32:21, 149.33s/it]Epoch: 12, train loss::47<1:07:41, 193.39s/it]Epoch: 4, train loss: 2.54527, f_loss_w: 25.40330, f_loss_uw: 2.54527, data loss: 0.16333:  16% 4/25 [18:09<1:07:41, 193.39s/it]Epoch: 4, train loss: 2.54527, f_loss_w: 25.40330, f_loss_uw: 2.54527, data loss: 0.16333:  20% 5/25 [18:09<1:14:53, 224.67s/it]Epoch: 5, train loss: 2.50074, f_loss_w: 26.88011, f_loss_uw: 2.50074, data loss: 0.14891:  20% 5/25 [23:31<1:14:53, 224.67s/it]Epoch: 5, train loss: 2.50074, f_loss_w: 26.88011, f_loss_uw: 2.50074, data loss: 0.14891:  24% 6/25 [23:31<1:17:44, 245.52s/it]Epoch: 6, train loss: 2.45984, f_loss_w: 17.20423, f_loss_uw: 2.45984, data loss: 0.13935:  24% 6/25 [28:18<1:17:44, 245.52s/it]Epoch: 6, train loss: 2.45984, f_loss_w: 17.20423, f_loss_uw: 2.45984, data loss: 0.13935:  28% 7/25 [28:18<1:16:02, 253.45s/it]Epoch: 7, train loss: 2.24377, f_loss_w: 22.82477, f_loss_uw: 2.24377, data loss: 0.13388:  28% 7/25 [32:50<1:16:02, 253.45s/it]Epoch: 7, train loss: 2.24377, f_loss_w: 22.82477, f_loss_uw: 2.24377, data loss: 0.13388:  32% 26.40000, f_loss_uw: 29.47683, data loss: 0.56011:  20% 5/25 [26:20<1:34:57, 284.88s/it]Epoch: 5, train loss: 22.21638, f_loss_w: 46446664.88000, f_loss_uw: 22.21638, data loss: 0.44155:  20% 5/25 [28:19<1:34:57, 284.88s/it] Epoch: 5, train loss: 22.21638, f_loss_w: 46446664.88000, f_loss_uw: 22.21638, data loss: 0.44155:  24% 6/25 [28:19<1:19:00, 249.49s/it]Epoch: 6, train loss: 17.79042, f_loss_w: 44303960.08000, f_loss_uw: 17.79042, data loss: 0.35180:  24% 6/25 [30:16<1:19:00, 249.49s/it]Epoch: 6, train loss: 17.79042, f_loss_w: 44303960.08000, f_loss_uw: 17.79042, data loss: 0.35180:  28% 7/25 [30:16<1:07:12, 224.04s/it]Epoch: 7, train loss: 14.65486, f_loss_w: 39485348.32000, f_loss_uw: 14.65486, data loss: 0.28743:  28% 7/25 [32:13<1:07:12, 224.04s/it]Epoch: 7, train loss: 14.65486, f_loss_w: 39485348.32000, f_loss_uw: 14.65486, data loss: 0.28743:  32% 8/25 [32:13<58:07, 205.17s/it]  Epoch: 8, train loss: 12.47602, f_loss_w: 34186036.28000, f_loss_uw: 12.47602, data loss: 0.24234:  32% 8/25 [34 3.28089, f_loss_w: 0.00002, f_loss_uw: 3.28089, data loss: 0.18055:  64% 16/25 [29:34<14:29, 96.61s/it]Epoch: 16, train loss: 3.28089, f_loss_w: 0.00002, f_loss_uw: 3.28089, data loss: 0.18055:  68% 17/25 [29:34<12:31, 93.97s/it]Epoch: 17, train loss: 2.35671, f_loss_w: 0.00001, f_loss_uw: 2.35671, data loss: 0.18759:  68% 17/25 [30:48<12:31, 93.97s/it]Epoch: 17, train loss: 2.35671, f_loss_w: 0.00001, f_loss_uw: 2.35671, data loss: 0.18759:  72% 18/25 [30:48<10:41, 91.64s/it]Epoch: 18, train loss: 2.51435, f_loss_w: 0.00001, f_loss_uw: 2.51435, data loss: 0.15145:  72% 18/25 [31:55<10:41, 91.64s/it]Epoch: 18, train loss: 2.51435, f_loss_w: 0.00001, f_loss_uw: 2.51435, data loss: 0.15145:  76% 19/25 [31:55<08:52, 88.80s/it]Epoch: 19, train loss: 3.20913, f_loss_w: 0.00001, f_loss_uw: 3.20913, data loss: 0.16820:  76% 19/25 [33:14<08:52, 88.80s/it]Epoch: 19, train loss: 3.20913, f_loss_w: 0.00001, f_loss_uw: 3.20913, data loss: 0.16820:  80% 20/25 [33:14<07:18, 87.63s/it]Epoch: 20, train loss: 2.88178, f_loss_w: 0.00013, f_loss_uw: 2.05457, data loss: 0.18766:  64% 16/25 [26:53<12:55, 86.14s/it]Epoch: 16, train loss: 2.05457, f_loss_w: 0.00013, f_loss_uw: 2.05457, data loss: 0.18766:  68% 17/25 [26:53<11:16, 84.56s/it]Epoch: 17, train loss: 2.15122, f_loss_w: 0.00018, f_loss_uw: 2.15122, data loss: 0.15994:  68% 17/25 [28:11<11:16, 84.56s/it]Epoch: 17, train loss: 2.15122, f_loss_w: 0.00018, f_loss_uw: 2.15122, data loss: 0.15994:  72% 18/25 [28:11<09:46, 83.74s/it]Epoch: 18, train loss: 2.31738, f_loss_w: 0.00042, f_loss_uw: 2.31738, data loss: 0.15413:  72% 18/25 [29:59<09:46, 83.74s/it]Epoch: 18, train loss: 2.31738, f_loss_w: 0.00042, f_loss_uw: 2.31738, data loss: 0.15413:  76% 19/25 [29:59<08:39, 86.53s/it]Epoch: 19, train loss: 2.61342, f_loss_w: 0.00143, f_loss_uw: 2.61342, data loss: 0.18272:  76% 19/25 [32:33<08:39, 86.53s/it]Epoch: 19, train loss: 2.61342, f_loss_w: 0.00143, f_loss_uw: 2.61342, data loss: 0.18272:  80% 20/25 [32:33<07:51, 94.31s/it]Epoch: 20, train loss: 3.28255, f_lossn loss: 3.33283, f_loss_w: 0.00003, f_loss_uw: 3.33283, data loss: 0.28637:  64% 16/25 [31:03<14:51, 99.05s/it]Epoch: 16, train loss: 3.33283, f_loss_w: 0.00003, f_loss_uw: 3.33283, data loss: 0.28637:  68% 17/25 [31:03<12:35, 94.43s/it]Epoch: 17, train loss: 4.22952, f_loss_w: 0.00001, f_loss_uw: 4.22952, data loss: 0.29875:  68% 17/25 [32:07<12:35, 94.43s/it]Epoch: 17, train loss: 4.22952, f_loss_w: 0.00001, f_loss_uw: 4.22952, data loss: 0.29875:  72% 18/25 [32:07<10:36, 90.93s/it]Epoch: 18, train loss: 4.33875, f_loss_w: 0.00004, f_loss_uw: 4.33875, data loss: 0.38107:  72% 18/25 [33:11<10:36, 90.93s/it]Epoch: 18, train loss: 4.33875, f_loss_w: 0.00004, f_loss_uw: 4.33875, data loss: 0.38107:  76% 19/25 [33:11<08:46, 87.80s/it]Epoch: 19, train loss: 2.87261, f_loss_w: 0.00001, f_loss_uw: 2.87261, data loss: 0.32975:  76% 19/25 [34:16<08:46, 87.80s/it]Epoch: 19, train loss: 2.87261, f_loss_w: 0.00001, f_loss_uw: 2.87261, data loss: 0.32975:  80% 20/25 [34:16<07:06, 85.22s/it]Epoch: 20, train loss: 0.00001, f_loss_uw: 2.13382, data loss: 0.14834:  80% 20/25 [26:31<05:19, 63.98s/it]Epoch: 20, train loss: 2.13382, f_loss_w: 0.00001, f_loss_uw: 2.13382, data loss: 0.14834:  84% 21/25 [26:31<04:10, 62.59s/it]Epoch: 21, train loss: 2.34350, f_loss_w: 0.00001, f_loss_uw: 2.34350, data loss: 0.18347:  84% 21/25 [27:25<04:10, 62.59s/it]Epoch: 21, train loss: 2.34350, f_loss_w: 0.00001, f_loss_uw: 2.34350, data loss: 0.18347:  88% 22/25 [27:25<03:04, 61.66s/it]Epoch: 22, train loss: 4.69816, f_loss_w: 0.00319, f_loss_uw: 4.69816, data loss: 0.58653:  88% 22/25 [28:29<03:04, 61.66s/it]Epoch: 22, train loss: 4.69816, f_loss_w: 0.00319, f_loss_uw: 4.69816, data loss: 0.58653:  92% 23/25 [28:29<02:03, 61.93s/it]Epoch: 23, train loss: 2381.90528, f_loss_w: 36.87063, f_loss_uw: 2381.90528, data loss: 23.64717:  92% 23/25 [33:46<02:03, 61.93s/it]Epoch: 23, train loss: 2381.90528, f_loss_w: 36.87063, f_loss_uw: 2381.90528, data loss: 23.64717:  96% 24/25 [33:46<01:29, 89.64s/it]Epoch: 24, train loss: 330.44068, Checkpoint is saved at checkpoints//darcy-cpino-2.pt
Checkpoint is saved at checkpoints//darcy-cpino-2-weights.pt
f_loss_w: -0.13029, f_loss_uw: 330.44068, data loss: 4.76255:  96% 24/25 [36:04<01:29, 89.64s/it]   Epoch: 24, train loss: 330.44068, f_loss_w: -0.13029, f_loss_uw: 330.44068, data loss: 4.76255: 100% 25/25 [36:04<00:00, 94.79s/it]Epoch: 24, train loss: 330.44068, f_loss_w: -0.13029, f_loss_uw: 330.44068, data loss: 4.76255: 100% 25/25 [36:04<00:00, 86.56s/it]
wandb: Waiting for W&B process to finish, PID 21159... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▂
wandb:            f loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▂
wandb:   f loss weighted ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:        train loss ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▂
wandb: 
wandb: Run summary:
wandb:         data loss 4.76255
wandb:            f loss 330.44068
wandb:   f loss weighted -0.13029
wandb:        train loss 330.44068
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced young-pyramid-192: https://wandb.ai/rishigundakaram/CPINO/runs/1slq1jnq
wandb: Find logs at: ./wandb/run-20220615_110423-1slq1jnq/logs/debug.log
wandb: 

Done!
poch: 12, train loss: 104.68907, f_loss_w: -0.02962, f_loss_uw: 104.68907, data loss: 1.51572:  48% 12/25 [27:11<26:52, 124.07s/it]Epoch: 12, train loss: 104.68907, f_loss_w: -0.02962, f_loss_uw: 104.68907, data loss: 1.51572:  52% 13/25 [27:11<26:15, 131.30s/it]Epoch: 13, train loss: 117.18558, f_loss_w: -0.02420, f_loss_uw: 117.18558, data loss: 1.92708:  52% 13/25 [30:19<26:15, 131.30s/it]Epoch: 13, train loss: 117.18558, f_loss_w: -0.02420, f_loss_uw: 117.18558, data loss: 1.92708:  56% 14/25 [30:19<25:24, 138.56s/it]Epoch: 14, train loss: 138.90765, f_loss_w: -0.01580, f_loss_uw: 138.90765, data loss: 2.20794:  56% 14/25 [33:17<25:24, 138.56s/it]Epoch: 14, train loss: 138.90765, f_loss_w: -0.01580, f_loss_uw: 138.90765, data loss: 2.20794:  60% 15/25 [33:17<23:56, 143.62s/it]Epoch: 15, train loss: 150.09012, f_loss_w: -0.01033, f_loss_uw: 150.09012, data loss: 2.27794:  60% 15/25 [36:13<23:56, 143.62s/it]Epoch: 15, train loss: 150.09012, f_loss_w: -0.01033, f_loss_uw: 150.09012, data loss: 2.277944/25 [20:32<1:49:47, 313.68s/it]Epoch: 4, train loss: 2.44763, f_loss_w: 234.34092, f_loss_uw: 2.44763, data loss: 0.12530:  16% 4/25 [25:43<1:49:47, 313.68s/it]Epoch: 4, train loss: 2.44763, f_loss_w: 234.34092, f_loss_uw: 2.44763, data loss: 0.12530:  20% 5/25 [25:43<1:44:19, 313.00s/it]Epoch: 5, train loss: 2.47067, f_loss_w: 180.76333, f_loss_uw: 2.47067, data loss: 0.11287:  20% 5/25 [29:47<1:44:19, 313.00s/it]Epoch: 5, train loss: 2.47067, f_loss_w: 180.76333, f_loss_uw: 2.47067, data loss: 0.11287:  24% 6/25 [29:47<1:34:26, 298.24s/it]Epoch: 6, train loss: 2.41908, f_loss_w: 131.21489, f_loss_uw: 2.41908, data loss: 0.08937:  24% 6/25 [33:32<1:34:26, 298.24s/it]Epoch: 6, train loss: 2.41908, f_loss_w: 131.21489, f_loss_uw: 2.41908, data loss: 0.08937:  28% 7/25 [33:32<1:25:17, 284.29s/it]Epoch: 7, train loss: 2.38911, f_loss_w: 78.01574, f_loss_uw: 2.38911, data loss: 0.07622:  28% 7/25 [37:39<1:25:17, 284.29s/it] Epoch: 7, train loss: 2.38911, f_loss_w: 78.01574, f_loss_uw: 2.38911, data loss:49:07, 173.37s/it]Epoch: 8, train loss: 3.77199, f_loss_w: 0.00956, f_loss_uw: 3.77199, data loss: 0.23887:  32% 8/25 [26:41<49:07, 173.37s/it]Epoch: 8, train loss: 3.77199, f_loss_w: 0.00956, f_loss_uw: 3.77199, data loss: 0.23887:  36% 9/25 [26:41<44:59, 168.74s/it]Epoch: 9, train loss: 3.12782, f_loss_w: 0.00636, f_loss_uw: 3.12782, data loss: 0.16940:  36% 9/25 [31:31<44:59, 168.74s/it]Epoch: 9, train loss: 3.12782, f_loss_w: 0.00636, f_loss_uw: 3.12782, data loss: 0.16940:  40% 10/25 [31:31<46:49, 187.30s/it]Epoch: 10, train loss: 30.97887, f_loss_w: 0.03190, f_loss_uw: 30.97887, data loss: 0.69452:  40% 10/25 [35:00<46:49, 187.30s/it]Epoch: 10, train loss: 30.97887, f_loss_w: 0.03190, f_loss_uw: 30.97887, data loss: 0.69452:  44% 11/25 [35:00<44:26, 190.48s/it]Epoch: 11, train loss: 4.18264, f_loss_w: 0.00225, f_loss_uw: 4.18264, data loss: 0.19891:  44% 11/25 [37:39<44:26, 190.48s/it]  Epoch: 11, train loss: 4.18264, f_loss_w: 0.00225, f_loss_uw: 4.18264, data loss: 0.19891:  48% 12/25 [37:39<455s/it]Epoch: 8, train loss: 3.04418, f_loss_w: 0.00067, f_loss_uw: 3.04418, data loss: 0.16121:  32% 8/25 [28:19<52:34, 185.55s/it]Epoch: 8, train loss: 3.04418, f_loss_w: 0.00067, f_loss_uw: 3.04418, data loss: 0.16121:  36% 9/25 [28:19<51:27, 192.96s/it]Epoch: 9, train loss: 3.44280, f_loss_w: 0.00018, f_loss_uw: 3.44280, data loss: 0.14530:  36% 9/25 [32:05<51:27, 192.96s/it]Epoch: 9, train loss: 3.44280, f_loss_w: 0.00018, f_loss_uw: 3.44280, data loss: 0.14530:  40% 10/25 [32:05<49:28, 197.92s/it]Epoch: 10, train loss: 3.01844, f_loss_w: 0.00011, f_loss_uw: 3.01844, data loss: 0.13369:  40% 10/25 [35:22<49:28, 197.92s/it]Epoch: 10, train loss: 3.01844, f_loss_w: 0.00011, f_loss_uw: 3.01844, data loss: 0.13369:  44% 11/25 [35:22<46:09, 197.80s/it]Epoch: 11, train loss: 2.76979, f_loss_w: 0.00009, f_loss_uw: 2.76979, data loss: 0.12332:  44% 11/25 [38:00<46:09, 197.80s/it]Epoch: 11, train loss: 2.76979, f_loss_w: 0.00009, f_loss_uw: 2.76979, data loss: 0.12332:  48% 12/25 [38:00<41:40, 192.34s/it]5, 187.95s/it]  Epoch: 8, train loss: 2.21265, f_loss_w: 0.00548, f_loss_uw: 2.21265, data loss: 0.11431:  32% 8/25 [29:50<53:15, 187.95s/it]Epoch: 8, train loss: 2.21265, f_loss_w: 0.00548, f_loss_uw: 2.21265, data loss: 0.11431:  36% 9/25 [29:50<50:01, 187.57s/it]Epoch: 9, train loss: 2.24276, f_loss_w: 0.00083, f_loss_uw: 2.24276, data loss: 0.09414:  36% 9/25 [32:29<50:01, 187.57s/it]Epoch: 9, train loss: 2.24276, f_loss_w: 0.00083, f_loss_uw: 2.24276, data loss: 0.09414:  40% 10/25 [32:29<45:47, 183.15s/it]Epoch: 10, train loss: 2.06825, f_loss_w: 0.00070, f_loss_uw: 2.06825, data loss: 0.09204:  40% 10/25 [35:02<45:47, 183.15s/it]Epoch: 10, train loss: 2.06825, f_loss_w: 0.00070, f_loss_uw: 2.06825, data loss: 0.09204:  44% 11/25 [35:02<41:41, 178.68s/it]Epoch: 11, train loss: 1.97957, f_loss_w: 0.00068, f_loss_uw: 1.97957, data loss: 0.08344:  44% 11/25 [38:09<41:41, 178.68s/it]Epoch: 11, train loss: 1.97957, f_loss_w: 0.00068, f_loss_uw: 1.97957, data loss: 0.08344:  48% 12/25 [38:09<38:58, 179:54<1:01:16, 216.26s/it]Epoch: 8, train loss: 3.10925, f_loss_w: 0.00476, f_loss_uw: 3.10925, data loss: 0.14709:  32% 8/25 [32:39<1:01:16, 216.26s/it]Epoch: 8, train loss: 3.10925, f_loss_w: 0.00476, f_loss_uw: 3.10925, data loss: 0.14709:  36% 9/25 [32:39<55:27, 207.96s/it]  Epoch: 9, train loss: 3.28126, f_loss_w: 0.00205, f_loss_uw: 3.28126, data loss: 0.18235:  36% 9/25 [34:47<55:27, 207.96s/it]Epoch: 9, train loss: 3.28126, f_loss_w: 0.00205, f_loss_uw: 3.28126, data loss: 0.18235:  40% 10/25 [34:47<48:54, 195.67s/it]Epoch: 10, train loss: 2.92434, f_loss_w: 0.00128, f_loss_uw: 2.92434, data loss: 0.12788:  40% 10/25 [36:38<48:54, 195.67s/it]Epoch: 10, train loss: 2.92434, f_loss_w: 0.00128, f_loss_uw: 2.92434, data loss: 0.12788:  44% 11/25 [36:38<42:46, 183.30s/it]Epoch: 11, train loss: 2.93725, f_loss_w: -0.00053, f_loss_uw: 2.93725, data loss: 0.18470:  44% 11/25 [38:37<42:46, 183.30s/it]Epoch: 11, train loss: 2.93725, f_loss_w: -0.00053, f_loss_uw: 2.93725, data loss: 0.18470:  48% 12/25 [t]Epoch: 4, train loss: 2.16933, f_loss_w: 0.15035, f_loss_uw: 2.16933, data loss: 0.16496:  16% 4/25 [17:27<1:05:37, 187.51s/it]Epoch: 4, train loss: 2.16933, f_loss_w: 0.15035, f_loss_uw: 2.16933, data loss: 0.16496:  20% 5/25 [17:27<1:14:21, 223.07s/it]Epoch: 5, train loss: 2.39367, f_loss_w: 0.14577, f_loss_uw: 2.39367, data loss: 0.15361:  20% 5/25 [24:11<1:14:21, 223.07s/it]Epoch: 5, train loss: 2.39367, f_loss_w: 0.14577, f_loss_uw: 2.39367, data loss: 0.15361:  24% 6/25 [24:11<1:22:55, 261.87s/it]Epoch: 6, train loss: 2.60828, f_loss_w: 0.14904, f_loss_uw: 2.60828, data loss: 0.13659:  24% 6/25 [32:04<1:22:55, 261.87s/it]Epoch: 6, train loss: 2.60828, f_loss_w: 0.14904, f_loss_uw: 2.60828, data loss: 0.13659:  28% 7/25 [32:04<1:30:42, 302.34s/it]Epoch: 7, train loss: 2.56572, f_loss_w: 0.11677, f_loss_uw: 2.56572, data loss: 0.12019:  28% 7/25 [38:28<1:30:42, 302.34s/it]Epoch: 7, train loss: 2.56572, f_loss_w: 0.11677, f_loss_uw: 2.56572, data loss: 0.12019:  32% 8/25 [38:28<1:29:43, 316.68s/i4.16446, f_loss_w: 0.00001, f_loss_uw: 4.16446, data loss: 0.39837:  80% 20/25 [35:14<07:06, 85.22s/it]Epoch: 20, train loss: 4.16446, f_loss_w: 0.00001, f_loss_uw: 4.16446, data loss: 0.39837:  84% 21/25 [35:14<05:28, 82.12s/it]Epoch: 21, train loss: 3.33475, f_loss_w: 0.00001, f_loss_uw: 3.33475, data loss: 0.26044:  84% 21/25 [36:09<05:28, 82.12s/it]Epoch: 21, train loss: 3.33475, f_loss_w: 0.00001, f_loss_uw: 3.33475, data loss: 0.26044:  88% 22/25 [36:09<03:57, 79.16s/it]Epoch: 22, train loss: 3.02681, f_loss_w: 0.00001, f_loss_uw: 3.02681, data loss: 0.19740:  88% 22/25 [37:06<03:57, 79.16s/it]Epoch: 22, train loss: 3.02681, f_loss_w: 0.00001, f_loss_uw: 3.02681, data loss: 0.19740:  92% 23/25 [37:06<02:33, 76.72s/it]Epoch: 23, train loss: 2.27489, f_loss_w: 0.00001, f_loss_uw: 2.27489, data loss: 0.21411:  92% 23/25 [38:06<02:33, 76.72s/it]Epoch: 23, train loss: 2.27489, f_loss_w: 0.00001, f_loss_uw: 2.27489, data loss: 0.21411:  96% 24/25 [38:06<01:14, 74.84s/it]Epoch: 24, train loss: 2.24806,Checkpoint is saved at checkpoints//darcy-cpino-4.pt
Checkpoint is saved at checkpoints//darcy-cpino-4-weights.pt
 f_loss_w: 0.00001, f_loss_uw: 2.24806, data loss: 0.16074:  96% 24/25 [39:06<01:14, 74.84s/it]Epoch: 24, train loss: 2.24806, f_loss_w: 0.00001, f_loss_uw: 2.24806, data loss: 0.16074: 100% 25/25 [39:06<00:00, 73.33s/it]Epoch: 24, train loss: 2.24806, f_loss_w: 0.00001, f_loss_uw: 2.24806, data loss: 0.16074: 100% 25/25 [39:06<00:00, 93.88s/it]
wandb: Waiting for W&B process to finish, PID 21317... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
, f_loss_w: 0.00002, f_loss_uw: 2.88178, data loss: 0.18396:  80% 20/25 [34:29<07:18, 87.63s/it]Epoch: 20, train loss: 2.88178, f_loss_w: 0.00002, f_loss_uw: 2.88178, data loss: 0.18396:  84% 21/25 [34:29<05:44, 86.19s/it]Epoch: 21, train loss: 2.42367, f_loss_w: 0.00002, f_loss_uw: 2.42367, data loss: 0.17012:  84% 21/25 [35:33<05:44, 86.19s/it]Epoch: 21, train loss: 2.42367, f_loss_w: 0.00002, f_loss_uw: 2.42367, data loss: 0.17012:  88% 22/25 [35:33<04:11, 83.77s/it]Epoch: 22, train loss: 2.28502, f_loss_w: 0.00002, f_loss_uw: 2.28502, data loss: 0.15153:  88% 22/25 [36:41<04:11, 83.77s/it]Epoch: 22, train loss: 2.28502, f_loss_w: 0.00002, f_loss_uw: 2.28502, data loss: 0.15153:  92% 23/25 [36:41<02:44, 82.02s/it]Epoch: 23, train loss: 2.33884, f_loss_w: 0.00002, f_loss_uw: 2.33884, data loss: 0.14776:  92% 23/25 [37:49<02:44, 82.02s/it]Epoch: 23, train loss: 2.33884, f_loss_w: 0.00002, f_loss_uw: 2.33884, data loss: 0.14776:  96% 24/25 [37:49<01:20, 80.49s/it]Epoch: 24, train loss: 2.23913, f_losswandb: Run history:
wandb:         data loss █▅▂▂▂▄▄▆▂▆▅▄▄▇▃▄▃▃▄▃▄▂▂▂▁
wandb:            f loss ▃▄▂▂▂▅▂▅▂▆▅▄▇█▄▄▄▆▆▃▆▄▃▁▁
wandb:   f loss weighted ▁▇▇▇▇██▇██▇▇█▇▇▇▇▇▇▇▇▇▇▇▇
wandb:        train loss ▃▄▂▂▂▅▂▅▂▆▅▄▇█▄▄▄▆▆▃▆▄▃▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.16074
wandb:            f loss 2.24806
wandb:   f loss weighted 1e-05
wandb:        train loss 2.24806
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced chocolate-thunder-206: https://wandb.ai/rishigundakaram/CPINO/runs/3rlnwi0q
wandb: Find logs at: ./wandb/run-20220615_110425-3rlnwi0q/logs/debug.log
wandb: 

Done!
Checkpoint is saved at checkpoints//darcy-cpino-9.pt
Checkpoint is saved at checkpoints//darcy-cpino-9-weights.pt
_w: 0.00003, f_loss_uw: 2.23913, data loss: 0.14955:  96% 24/25 [39:13<01:20, 80.49s/it]Epoch: 24, train loss: 2.23913, f_loss_w: 0.00003, f_loss_uw: 2.23913, data loss: 0.14955: 100% 25/25 [39:13<00:00, 80.91s/it]Epoch: 24, train loss: 2.23913, f_loss_w: 0.00003, f_loss_uw: 2.23913, data loss: 0.14955: 100% 25/25 [39:13<00:00, 94.15s/it]
wandb: Waiting for W&B process to finish, PID 9458... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▆▂▂▂▅▆▃▂▅▄▄▂▂▄▂▂▂▁▁▂▁▁▁▁
wandb:            f loss ▄▄▃▃▃█▄▃▃▄▃▁▃▃▂▂▄▁▂▄▃▂▁▁▁
wandb:   f loss weighted █▂▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▄▄▃▃▃█▄▃▃▄▃▁▃▃▂▂▄▁▂▄▃▂▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.14955
wandb:            f loss 2.23913
wandb:   f loss weighted 3e-05
wandb:        train loss 2.23913
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced morning-jazz-191: https://wandb.ai/rishigundakaram/CPINO/runs/2c45n5xe
wandb: Find logs at: ./wandb/run-20220615_110423-2c45n5xe/logs/debug.log
wandb: 

Done!
:56, 342.69s/it]Epoch: 4, train loss: 2.13517, f_loss_w: 0.33147, f_loss_uw: 2.13517, data loss: 0.07050:  16% 4/25 [27:16<1:59:56, 342.69s/it]Epoch: 4, train loss: 2.13517, f_loss_w: 0.33147, f_loss_uw: 2.13517, data loss: 0.07050:  20% 5/25 [27:16<1:45:35, 316.79s/it]Epoch: 5, train loss: 2.14074, f_loss_w: 0.09582, f_loss_uw: 2.14074, data loss: 0.06066:  20% 5/25 [31:16<1:45:35, 316.79s/it]Epoch: 5, train loss: 2.14074, f_loss_w: 0.09582, f_loss_uw: 2.14074, data loss: 0.06066:  24% 6/25 [31:16<1:35:06, 300.33s/it]Epoch: 6, train loss: 2.07074, f_loss_w: 0.05988, f_loss_uw: 2.07074, data loss: 0.06233:  24% 6/25 [35:16<1:35:06, 300.33s/it]Epoch: 6, train loss: 2.07074, f_loss_w: 0.05988, f_loss_uw: 2.07074, data loss: 0.06233:  28% 7/25 [35:16<1:26:36, 288.70s/it]Epoch: 7, train loss: 1.88666, f_loss_w: 0.06241, f_loss_uw: 1.88666, data loss: 0.05727:  28% 7/25 [39:35<1:26:36, 288.70s/it]Epoch: 7, train loss: 1.88666, f_loss_w: 0.06241, f_loss_uw: 1.88666, data loss: 0.05727:  32% 8/25 [39:35<1:20_w: 0.00211, f_loss_uw: 3.28255, data loss: 0.21206:  80% 20/25 [34:43<07:51, 94.31s/it]Epoch: 20, train loss: 3.28255, f_loss_w: 0.00211, f_loss_uw: 3.28255, data loss: 0.21206:  84% 21/25 [34:43<06:33, 98.31s/it]Epoch: 21, train loss: 5.23591, f_loss_w: 0.00040, f_loss_uw: 5.23591, data loss: 0.20293:  84% 21/25 [37:00<06:33, 98.31s/it]Epoch: 21, train loss: 5.23591, f_loss_w: 0.00040, f_loss_uw: 5.23591, data loss: 0.20293:  88% 22/25 [37:00<05:07, 102.58s/it]Epoch: 22, train loss: 5.36820, f_loss_w: 0.00008, f_loss_uw: 5.36820, data loss: 0.21613:  88% 22/25 [38:32<05:07, 102.58s/it]Epoch: 22, train loss: 5.36820, f_loss_w: 0.00008, f_loss_uw: 5.36820, data loss: 0.21613:  92% 23/25 [38:32<03:22, 101.41s/it]Epoch: 23, train loss: 5.11493, f_loss_w: 0.00001, f_loss_uw: 5.11493, data loss: 0.17212:  92% 23/25 [39:52<03:22, 101.41s/it]Epoch: 23, train loss: 5.11493, f_loss_w: 0.00001, f_loss_uw: 5.11493, data loss: 0.17212:  96% 24/25 [39:52<01:39, 99.12s/it] Epoch: 24, train loss: 3.61079, f_loss_w:Checkpoint is saved at checkpoints//darcy-cpino-14.pt
Checkpoint is saved at checkpoints//darcy-cpino-14-weights.pt
 0.00004, f_loss_uw: 3.61079, data loss: 0.15956:  96% 24/25 [41:11<01:39, 99.12s/it]Epoch: 24, train loss: 3.61079, f_loss_w: 0.00004, f_loss_uw: 3.61079, data loss: 0.15956: 100% 25/25 [41:11<00:00, 96.87s/it]Epoch: 24, train loss: 3.61079, f_loss_w: 0.00004, f_loss_uw: 3.61079, data loss: 0.15956: 100% 25/25 [41:11<00:00, 98.84s/it]
wandb: Waiting for W&B process to finish, PID 10588... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss ██▃▂▂▁▁▃▂▁▁▂▁▁▁▂▂▁▁▂▂▂▂▁▁
wandb:            f loss ▄▃▃▂▂▂▂▃▂▂▁▁▂▂▁▂▁▁▂▂▄██▇▄
wandb:   f loss weighted █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▃▁▁▁▁
wandb:        train loss ▄▃▃▂▂▂▂▃▂▂▁▁▂▂▁▂▁▁▂▂▄██▇▄
wandb: 
wandb: Run summary:
wandb:         data loss 0.15956
wandb:            f loss 3.61079
wandb:   f loss weighted 4e-05
wandb:        train loss 3.61079
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced solar-thunder-199: https://wandb.ai/rishigundakaram/CPINO/runs/3p5tuq44
wandb: Find logs at: ./wandb/run-20220615_110424-3p5tuq44/logs/debug.log
wandb: 

Done!
:31, 220.66s/it]Epoch: 8, train loss: 2.23519, f_loss_w: 0.01171, f_loss_uw: 2.23519, data loss: 0.07304:  32% 8/25 [34:32<1:02:31, 220.66s/it]Epoch: 8, train loss: 2.23519, f_loss_w: 0.01171, f_loss_uw: 2.23519, data loss: 0.07304:  36% 9/25 [34:32<59:04, 221.53s/it]  Epoch: 9, train loss: 2.29712, f_loss_w: 0.00560, f_loss_uw: 2.29712, data loss: 0.06589:  36% 9/25 [37:58<59:04, 221.53s/it]Epoch: 9, train loss: 2.29712, f_loss_w: 0.00560, f_loss_uw: 2.29712, data loss: 0.06589:  40% 10/25 [37:58<54:47, 219.20s/it]Epoch: 10, train loss: 2.24228, f_loss_w: 0.00443, f_loss_uw: 2.24228, data loss: 0.07263:  40% 10/25 [40:34<54:47, 219.20s/it]Epoch: 10, train loss: 2.24228, f_loss_w: 0.00443, f_loss_uw: 2.24228, data loss: 0.07263:  44% 11/25 [40:34<48:59, 209.95s/it]Epoch: 11, train loss: 2.25641, f_loss_w: 0.00346, f_loss_uw: 2.25641, data loss: 0.06720:  44% 11/25 [43:21<48:59, 209.95s/it]Epoch: 11, train loss: 2.25641, f_loss_w: 0.00346, f_loss_uw: 2.25641, data loss: 0.06720:  48% 12/25 [43:21<44:13:16, 337.91s/it]Epoch: 4, train loss: 5.60368, f_loss_w: 8.78113, f_loss_uw: 5.60368, data loss: 0.15244:  16% 4/25 [28:51<1:58:16, 337.91s/it]Epoch: 4, train loss: 5.60368, f_loss_w: 8.78113, f_loss_uw: 5.60368, data loss: 0.15244:  20% 5/25 [28:51<1:53:13, 339.65s/it]Epoch: 5, train loss: 2.88714, f_loss_w: 1.17934, f_loss_uw: 2.88714, data loss: 0.08831:  20% 5/25 [33:27<1:53:13, 339.65s/it]Epoch: 5, train loss: 2.88714, f_loss_w: 1.17934, f_loss_uw: 2.88714, data loss: 0.08831:  24% 6/25 [33:27<1:43:13, 326.00s/it]Epoch: 6, train loss: 2.48742, f_loss_w: 0.79522, f_loss_uw: 2.48742, data loss: 0.08899:  24% 6/25 [38:34<1:43:13, 326.00s/it]Epoch: 6, train loss: 2.48742, f_loss_w: 0.79522, f_loss_uw: 2.48742, data loss: 0.08899:  28% 7/25 [38:34<1:36:41, 322.32s/it]Epoch: 7, train loss: 2.17125, f_loss_w: 0.71828, f_loss_uw: 2.17125, data loss: 0.07947:  28% 7/25 [44:08<1:36:41, 322.32s/it]Epoch: 7, train loss: 2.17125, f_loss_w: 0.71828, f_loss_uw: 2.17125, data loss: 0.07947:  32% 8/25 [44:08<1:31:02, 340.11s/it]Epoch: 4, train loss: 2.52782, f_loss_w: 0.12085, f_loss_uw: 2.52782, data loss: 0.11223:  16% 4/25 [30:04<1:59:02, 340.11s/it]Epoch: 4, train loss: 2.52782, f_loss_w: 0.12085, f_loss_uw: 2.52782, data loss: 0.11223:  20% 5/25 [30:04<2:00:52, 362.63s/it]Epoch: 5, train loss: 2.51320, f_loss_w: 0.03574, f_loss_uw: 2.51320, data loss: 0.08246:  20% 5/25 [34:36<2:00:52, 362.63s/it]Epoch: 5, train loss: 2.51320, f_loss_w: 0.03574, f_loss_uw: 2.51320, data loss: 0.08246:  24% 6/25 [34:36<1:48:45, 343.46s/it]Epoch: 6, train loss: 2.26775, f_loss_w: 0.01785, f_loss_uw: 2.26775, data loss: 0.06430:  24% 6/25 [39:33<1:48:45, 343.46s/it]Epoch: 6, train loss: 2.26775, f_loss_w: 0.01785, f_loss_uw: 2.26775, data loss: 0.06430:  28% 7/25 [39:33<1:40:19, 334.44s/it]Epoch: 7, train loss: 2.13307, f_loss_w: 0.01296, f_loss_uw: 2.13307, data loss: 0.05880:  28% 7/25 [44:42<1:40:19, 334.44s/it]Epoch: 7, train loss: 2.13307, f_loss_w: 0.01296, f_loss_uw: 2.13307, data loss: 0.05880:  32% 8/25 [44:42<1:33:46, 345.08s/it]Epoch: 4, train loss: 2.31566, f_loss_w: 0.08320, f_loss_uw: 2.31566, data loss: 0.08431:  16% 4/25 [28:12<2:00:46, 345.08s/it]Epoch: 4, train loss: 2.31566, f_loss_w: 0.08320, f_loss_uw: 2.31566, data loss: 0.08431:  20% 5/25 [28:12<1:49:56, 329.84s/it]Epoch: 5, train loss: 2.07542, f_loss_w: 0.05990, f_loss_uw: 2.07542, data loss: 0.07060:  20% 5/25 [34:05<1:49:56, 329.84s/it]Epoch: 5, train loss: 2.07542, f_loss_w: 0.05990, f_loss_uw: 2.07542, data loss: 0.07060:  24% 6/25 [34:05<1:45:59, 334.72s/it]Epoch: 6, train loss: 1.95270, f_loss_w: 0.03223, f_loss_uw: 1.95270, data loss: 0.06371:  24% 6/25 [39:37<1:45:59, 334.72s/it]Epoch: 6, train loss: 1.95270, f_loss_w: 0.03223, f_loss_uw: 1.95270, data loss: 0.06371:  28% 7/25 [39:37<1:40:15, 334.17s/it]Epoch: 7, train loss: 1.86312, f_loss_w: 0.02201, f_loss_uw: 1.86312, data loss: 0.05923:  28% 7/25 [44:52<1:40:15, 334.17s/it]Epoch: 7, train loss: 1.86312, f_loss_w: 0.02201, f_loss_uw: 1.86312, data loss: 0.05923:  32% 8/25 [44:52<1:33:15<58:07, 205.17s/it]Epoch: 8, train loss: 12.47602, f_loss_w: 34186036.28000, f_loss_uw: 12.47602, data loss: 0.24234:  36% 9/25 [34:15<51:06, 191.67s/it]Epoch: 9, train loss: 10.88350, f_loss_w: 33931047.56000, f_loss_uw: 10.88350, data loss: 0.21649:  36% 9/25 [36:32<51:06, 191.67s/it]Epoch: 9, train loss: 10.88350, f_loss_w: 33931047.56000, f_loss_uw: 10.88350, data loss: 0.21649:  40% 10/25 [36:32<45:47, 183.20s/it]Epoch: 10, train loss: 9.44069, f_loss_w: 38260531.48000, f_loss_uw: 9.44069, data loss: 0.19867:  40% 10/25 [39:06<45:47, 183.20s/it] Epoch: 10, train loss: 9.44069, f_loss_w: 38260531.48000, f_loss_uw: 9.44069, data loss: 0.19867:  44% 11/25 [39:06<41:45, 178.95s/it]Epoch: 11, train loss: 8.44311, f_loss_w: 38097734.92000, f_loss_uw: 8.44311, data loss: 0.18835:  44% 11/25 [41:56<41:45, 178.95s/it]Epoch: 11, train loss: 8.44311, f_loss_w: 38097734.92000, f_loss_uw: 8.44311, data loss: 0.18835:  48% 12/25 [41:56<38:31, 177.81s/it]Epoch: 12, train loss: 7.47524, f_loss_w: 45603722.560 3.24868, f_loss_w: 0.00151, f_loss_uw: 3.24868, data loss: 0.13898:  48% 12/25 [32:40<32:21, 149.33s/it]Epoch: 12, train loss: 3.24868, f_loss_w: 0.00151, f_loss_uw: 3.24868, data loss: 0.13898:  52% 13/25 [32:40<32:45, 163.81s/it]Epoch: 13, train loss: 5.19012, f_loss_w: -0.00024, f_loss_uw: 5.19012, data loss: 0.14691:  52% 13/25 [36:57<32:45, 163.81s/it]Epoch: 13, train loss: 5.19012, f_loss_w: -0.00024, f_loss_uw: 5.19012, data loss: 0.14691:  56% 14/25 [36:57<32:14, 175.90s/it]Epoch: 14, train loss: 4.87649, f_loss_w: 0.00001, f_loss_uw: 4.87649, data loss: 0.14127:  56% 14/25 [40:11<32:14, 175.90s/it] Epoch: 14, train loss: 4.87649, f_loss_w: 0.00001, f_loss_uw: 4.87649, data loss: 0.14127:  60% 15/25 [40:11<29:42, 178.22s/it]Epoch: 15, train loss: 3.40275, f_loss_w: 0.00007, f_loss_uw: 3.40275, data loss: 0.12591:  60% 15/25 [42:52<29:42, 178.22s/it]Epoch: 15, train loss: 3.40275, f_loss_w: 0.00007, f_loss_uw: 3.40275, data loss: 0.12591:  64% 16/25 [42:52<26:24, 176.05s/it]Epoch: 16, train lo0.12741:  16% 4/25 [28:58<2:30:47, 430.84s/it]Epoch: 4, train loss: 2.22319, f_loss_w: 82736.83502, f_loss_uw: 2.22319, data loss: 0.11076:  16% 4/25 [33:48<2:30:47, 430.84s/it]Epoch: 4, train loss: 2.22319, f_loss_w: 82736.83502, f_loss_uw: 2.22319, data loss: 0.11076:  20% 5/25 [33:48<2:12:08, 396.43s/it]Epoch: 5, train loss: 2.03802, f_loss_w: 45262.19680, f_loss_uw: 2.03802, data loss: 0.07965:  20% 5/25 [38:17<2:12:08, 396.43s/it]Epoch: 5, train loss: 2.03802, f_loss_w: 45262.19680, f_loss_uw: 2.03802, data loss: 0.07965:  24% 6/25 [38:17<1:56:56, 369.28s/it]Epoch: 6, train loss: 2.09480, f_loss_w: 13519.41342, f_loss_uw: 2.09480, data loss: 0.08025:  24% 6/25 [41:52<1:56:56, 369.28s/it]Epoch: 6, train loss: 2.09480, f_loss_w: 13519.41342, f_loss_uw: 2.09480, data loss: 0.08025:  28% 7/25 [41:52<1:41:54, 339.71s/it]Epoch: 7, train loss: 2.07835, f_loss_w: 15452.76320, f_loss_uw: 2.07835, data loss: 0.08242:  28% 7/25 [45:42<1:41:54, 339.71s/it]Epoch: 7, train loss: 2.07835, f_loss_w: 15452.76320,Epoch: 12, train loss: 2.77402, f_loss_w: 0.00031, f_loss_uw: 2.77402, data loss: 0.16692:  48% 12/25 [39:57<41:40, 192.34s/it]Epoch: 12, train loss: 2.77402, f_loss_w: 0.00031, f_loss_uw: 2.77402, data loss: 0.16692:  52% 13/25 [39:57<36:26, 182.18s/it]Epoch: 13, train loss: 2.43607, f_loss_w: 0.00019, f_loss_uw: 2.43607, data loss: 0.19128:  52% 13/25 [41:37<36:26, 182.18s/it]Epoch: 13, train loss: 2.43607, f_loss_w: 0.00019, f_loss_uw: 2.43607, data loss: 0.19128:  56% 14/25 [41:37<31:26, 171.52s/it]Epoch: 14, train loss: 3.35944, f_loss_w: 0.00059, f_loss_uw: 3.35944, data loss: 0.25298:  56% 14/25 [43:30<31:26, 171.52s/it]Epoch: 14, train loss: 3.35944, f_loss_w: 0.00059, f_loss_uw: 3.35944, data loss: 0.25298:  60% 15/25 [43:30<27:21, 164.11s/it]Epoch: 15, train loss: 1.93101, f_loss_w: 0.00016, f_loss_uw: 1.93101, data loss: 0.16166:  60% 15/25 [46:08<27:21, 164.11s/it]Epoch: 15, train loss: 1.93101, f_loss_w: 0.00016, f_loss_uw: 1.93101, data loss: 0.16166:  64% 16/25 [46:08<24:31, 163.47s/it]2% 8/25 [31:42<1:05:47, 232.19s/it]Epoch: 8, train loss: 3.63193, f_loss_w: 0.00557, f_loss_uw: 3.63193, data loss: 0.15548:  32% 8/25 [35:38<1:05:47, 232.19s/it]Epoch: 8, train loss: 3.63193, f_loss_w: 0.00557, f_loss_uw: 3.63193, data loss: 0.15548:  36% 9/25 [35:38<1:02:03, 232.70s/it]Epoch: 9, train loss: 4.82794, f_loss_w: 0.00735, f_loss_uw: 4.82794, data loss: 0.21003:  36% 9/25 [38:55<1:02:03, 232.70s/it]Epoch: 9, train loss: 4.82794, f_loss_w: 0.00735, f_loss_uw: 4.82794, data loss: 0.21003:  40% 10/25 [38:55<56:48, 227.26s/it] Epoch: 10, train loss: 3.87869, f_loss_w: 0.00941, f_loss_uw: 3.87869, data loss: 0.15641:  40% 10/25 [43:14<56:48, 227.26s/it]Epoch: 10, train loss: 3.87869, f_loss_w: 0.00941, f_loss_uw: 3.87869, data loss: 0.15641:  44% 11/25 [43:14<54:06, 231.91s/it]Epoch: 11, train loss: 3.94354, f_loss_w: 0.00397, f_loss_uw: 3.94354, data loss: 0.14649:  44% 11/25 [46:49<54:06, 231.91s/it]Epoch: 11, train loss: 3.94354, f_loss_w: 0.00397, f_loss_uw: 3.94354, data loss: 0.14649:  8/25 [32:50<1:12:44, 256.71s/it]Epoch: 8, train loss: 2.11842, f_loss_w: 22.96781, f_loss_uw: 2.11842, data loss: 0.12876:  32% 8/25 [36:54<1:12:44, 256.71s/it]Epoch: 8, train loss: 2.11842, f_loss_w: 22.96781, f_loss_uw: 2.11842, data loss: 0.12876:  36% 9/25 [36:54<1:07:53, 254.62s/it]Epoch: 9, train loss: 2.08670, f_loss_w: 27.15257, f_loss_uw: 2.08670, data loss: 0.11896:  36% 9/25 [41:19<1:07:53, 254.62s/it]Epoch: 9, train loss: 2.08670, f_loss_w: 27.15257, f_loss_uw: 2.08670, data loss: 0.11896:  40% 10/25 [41:19<1:04:03, 256.25s/it]Epoch: 10, train loss: 2.13563, f_loss_w: 18.99782, f_loss_uw: 2.13563, data loss: 0.10973:  40% 10/25 [44:17<1:04:03, 256.25s/it]Epoch: 10, train loss: 2.13563, f_loss_w: 18.99782, f_loss_uw: 2.13563, data loss: 0.10973:  44% 11/25 [44:17<57:07, 244.85s/it]  Epoch: 11, train loss: 2.04147, f_loss_w: 11.17805, f_loss_uw: 2.04147, data loss: 0.08826:  44% 11/25 [47:16<57:07, 244.85s/it]Epoch: 11, train loss: 2.04147, f_loss_w: 11.17805, f_loss_uw: 2.04147, data loss: :  64% 16/25 [36:13<22:07, 147.55s/it]Epoch: 16, train loss: 157.24692, f_loss_w: -0.00732, f_loss_uw: 157.24692, data loss: 2.35753:  64% 16/25 [38:56<22:07, 147.55s/it]Epoch: 16, train loss: 157.24692, f_loss_w: -0.00732, f_loss_uw: 157.24692, data loss: 2.35753:  68% 17/25 [38:56<19:55, 149.45s/it]Epoch: 17, train loss: 153.83786, f_loss_w: -0.00530, f_loss_uw: 153.83786, data loss: 2.21801:  68% 17/25 [41:43<19:55, 149.45s/it]Epoch: 17, train loss: 153.83786, f_loss_w: -0.00530, f_loss_uw: 153.83786, data loss: 2.21801:  72% 18/25 [41:43<17:40, 151.50s/it]Epoch: 18, train loss: 152.24355, f_loss_w: -0.00435, f_loss_uw: 152.24355, data loss: 2.13808:  72% 18/25 [44:39<17:40, 151.50s/it]Epoch: 18, train loss: 152.24355, f_loss_w: -0.00435, f_loss_uw: 152.24355, data loss: 2.13808:  76% 19/25 [44:39<15:25, 154.25s/it]Epoch: 19, train loss: 150.98212, f_loss_w: -0.00332, f_loss_uw: 150.98212, data loss: 2.07338:  76% 19/25 [47:23<15:25, 154.25s/it]Epoch: 19, train loss: 150.98212, f_loss_w: -0.00332, 9.87s/it]Epoch: 12, train loss: 1.94681, f_loss_w: 0.00073, f_loss_uw: 1.94681, data loss: 0.08377:  48% 12/25 [40:51<38:58, 179.87s/it]Epoch: 12, train loss: 1.94681, f_loss_w: 0.00073, f_loss_uw: 1.94681, data loss: 0.08377:  52% 13/25 [40:51<35:29, 177.45s/it]Epoch: 13, train loss: 1.97638, f_loss_w: 0.00042, f_loss_uw: 1.97638, data loss: 0.07816:  52% 13/25 [43:37<35:29, 177.45s/it]Epoch: 13, train loss: 1.97638, f_loss_w: 0.00042, f_loss_uw: 1.97638, data loss: 0.07816:  56% 14/25 [43:37<32:16, 176.06s/it]Epoch: 14, train loss: 1.97730, f_loss_w: 0.00042, f_loss_uw: 1.97730, data loss: 0.07388:  56% 14/25 [46:38<32:16, 176.06s/it]Epoch: 14, train loss: 1.97730, f_loss_w: 0.00042, f_loss_uw: 1.97730, data loss: 0.07388:  60% 15/25 [46:38<29:26, 176.63s/it]Epoch: 15, train loss: 3.08981, f_loss_w: 0.00527, f_loss_uw: 3.08981, data loss: 0.41722:  60% 15/25 [48:22<29:26, 176.63s/it]Epoch: 15, train loss: 3.08981, f_loss_w: 0.00527, f_loss_uw: 3.08981, data loss: 0.41722:  64% 16/25 [48:22<25:09, 160:20, 186.17s/it]Epoch: 12, train loss: 3.28680, f_loss_w: 0.00011, f_loss_uw: 3.28680, data loss: 0.16939:  48% 12/25 [40:21<40:20, 186.17s/it]Epoch: 12, train loss: 3.28680, f_loss_w: 0.00011, f_loss_uw: 3.28680, data loss: 0.16939:  52% 13/25 [40:21<36:33, 182.83s/it]Epoch: 13, train loss: 3.22813, f_loss_w: 0.00015, f_loss_uw: 3.22813, data loss: 0.15461:  52% 13/25 [43:08<36:33, 182.83s/it]Epoch: 13, train loss: 3.22813, f_loss_w: 0.00015, f_loss_uw: 3.22813, data loss: 0.15461:  56% 14/25 [43:08<33:08, 180.79s/it]Epoch: 14, train loss: 3.19131, f_loss_w: 0.00029, f_loss_uw: 3.19131, data loss: 0.15381:  56% 14/25 [45:36<33:08, 180.79s/it]Epoch: 14, train loss: 3.19131, f_loss_w: 0.00029, f_loss_uw: 3.19131, data loss: 0.15381:  60% 15/25 [45:36<29:26, 176.67s/it]Epoch: 15, train loss: 4.46467, f_loss_w: -0.00010, f_loss_uw: 4.46467, data loss: 0.20070:  60% 15/25 [48:23<29:26, 176.67s/it]Epoch: 15, train loss: 4.46467, f_loss_w: -0.00010, f_loss_uw: 4.46467, data loss: 0.20070:  64% 16/25 [48:23it] Epoch: 16, train loss: 3.21161, f_loss_w: 0.00185, f_loss_uw: 3.21161, data loss: 0.29451:  64% 16/25 [34:14<14:53, 99.29s/it]Epoch: 16, train loss: 3.21161, f_loss_w: 0.00185, f_loss_uw: 3.21161, data loss: 0.29451:  68% 17/25 [34:14<13:22, 100.30s/it]Epoch: 17, train loss: 5.50852, f_loss_w: 0.00065, f_loss_uw: 5.50852, data loss: 0.38792:  68% 17/25 [38:06<13:22, 100.30s/it]Epoch: 17, train loss: 5.50852, f_loss_w: 0.00065, f_loss_uw: 5.50852, data loss: 0.38792:  72% 18/25 [38:06<13:30, 115.74s/it]Epoch: 18, train loss: 2.80692, f_loss_w: 0.00762, f_loss_uw: 2.80692, data loss: 0.15630:  72% 18/25 [43:34<13:30, 115.74s/it]Epoch: 18, train loss: 2.80692, f_loss_w: 0.00762, f_loss_uw: 2.80692, data loss: 0.15630:  76% 19/25 [43:34<14:01, 140.26s/it]Epoch: 19, train loss: 2.84116, f_loss_w: 0.00111, f_loss_uw: 2.84116, data loss: 0.11873:  76% 19/25 [48:30<14:01, 140.26s/it]Epoch: 19, train loss: 2.84116, f_loss_w: 0.00111, f_loss_uw: 2.84116, data loss: 0.11873:  80% 20/25 [48:30<13:10, 158.00s/:09:16, 244.52s/it]Epoch: 8, train loss: 2.61998, f_loss_w: 0.01355, f_loss_uw: 2.61998, data loss: 0.09300:  32% 8/25 [37:36<1:09:16, 244.52s/it]Epoch: 8, train loss: 2.61998, f_loss_w: 0.01355, f_loss_uw: 2.61998, data loss: 0.09300:  36% 9/25 [37:36<1:10:29, 264.33s/it]Epoch: 9, train loss: 2.52219, f_loss_w: 0.00953, f_loss_uw: 2.52219, data loss: 0.08696:  36% 9/25 [42:43<1:10:29, 264.33s/it]Epoch: 9, train loss: 2.52219, f_loss_w: 0.00953, f_loss_uw: 2.52219, data loss: 0.08696:  40% 10/25 [42:43<1:07:43, 270.93s/it]Epoch: 10, train loss: 2.58087, f_loss_w: 0.00483, f_loss_uw: 2.58087, data loss: 0.08823:  40% 10/25 [46:41<1:07:43, 270.93s/it]Epoch: 10, train loss: 2.58087, f_loss_w: 0.00483, f_loss_uw: 2.58087, data loss: 0.08823:  44% 11/25 [46:41<1:02:06, 266.15s/it]Epoch: 11, train loss: 2.38383, f_loss_w: 0.00470, f_loss_uw: 2.38383, data loss: 0.08143:  44% 11/25 [50:05<1:02:06, 266.15s/it]Epoch: 11, train loss: 2.38383, f_loss_w: 0.00470, f_loss_uw: 2.38383, data loss: 0.08143:  48% 12/25, 204.08s/it]Epoch: 12, train loss: 2.33714, f_loss_w: 0.00149, f_loss_uw: 2.33714, data loss: 0.09076:  48% 12/25 [45:20<44:13, 204.08s/it]Epoch: 12, train loss: 2.33714, f_loss_w: 0.00149, f_loss_uw: 2.33714, data loss: 0.09076:  52% 13/25 [45:20<38:31, 192.61s/it]Epoch: 13, train loss: 2.22276, f_loss_w: 0.00249, f_loss_uw: 2.22276, data loss: 0.06777:  52% 13/25 [47:37<38:31, 192.61s/it]Epoch: 13, train loss: 2.22276, f_loss_w: 0.00249, f_loss_uw: 2.22276, data loss: 0.06777:  56% 14/25 [47:37<33:59, 185.42s/it]Epoch: 14, train loss: 2.21244, f_loss_w: 0.00288, f_loss_uw: 2.21244, data loss: 0.06925:  56% 14/25 [49:43<33:59, 185.42s/it]Epoch: 14, train loss: 2.21244, f_loss_w: 0.00288, f_loss_uw: 2.21244, data loss: 0.06925:  60% 15/25 [49:43<29:38, 177.86s/it]Epoch: 15, train loss: 2.27914, f_loss_w: 0.00205, f_loss_uw: 2.27914, data loss: 0.08413:  60% 15/25 [51:24<29:38, 177.86s/it]Epoch: 15, train loss: 2.27914, f_loss_w: 0.00205, f_loss_uw: 2.27914, data loss: 0.08413:  64% 16/25 [51:24<25:16:45<1:05:26, 230.95s/it]Epoch: 8, train loss: 5.62361, f_loss_w: 0.06513, f_loss_uw: 5.62361, data loss: 0.18316:  32% 8/25 [36:18<1:05:26, 230.95s/it]  Epoch: 8, train loss: 5.62361, f_loss_w: 0.06513, f_loss_uw: 5.62361, data loss: 0.18316:  36% 9/25 [36:18<1:03:26, 237.89s/it]Epoch: 9, train loss: 28.09968, f_loss_w: 0.38713, f_loss_uw: 28.09968, data loss: 0.41127:  36% 9/25 [40:22<1:03:26, 237.89s/it]Epoch: 9, train loss: 28.09968, f_loss_w: 0.38713, f_loss_uw: 28.09968, data loss: 0.41127:  40% 10/25 [40:22<59:42, 238.81s/it] Epoch: 10, train loss: 3.53711, f_loss_w: 0.07220, f_loss_uw: 3.53711, data loss: 0.15587:  40% 10/25 [45:34<59:42, 238.81s/it] Epoch: 10, train loss: 3.53711, f_loss_w: 0.07220, f_loss_uw: 3.53711, data loss: 0.15587:  44% 11/25 [45:34<58:12, 249.43s/it]Epoch: 11, train loss: 3.02102, f_loss_w: 0.03603, f_loss_uw: 3.02102, data loss: 0.11572:  44% 11/25 [52:00<58:12, 249.43s/it]Epoch: 11, train loss: 3.02102, f_loss_w: 0.03603, f_loss_uw: 3.02102, data loss: 0.11572:  48%  [31:40<2:41:48, 462.33s/it]Epoch: 4, train loss: 2.45252, f_loss_w: 99.32977, f_loss_uw: 2.45252, data loss: 0.08899:  16% 4/25 [36:24<2:41:48, 462.33s/it] Epoch: 4, train loss: 2.45252, f_loss_w: 99.32977, f_loss_uw: 2.45252, data loss: 0.08899:  20% 5/25 [36:24<2:19:34, 418.71s/it]Epoch: 5, train loss: 2.14350, f_loss_w: 66.08539, f_loss_uw: 2.14350, data loss: 0.07801:  20% 5/25 [42:03<2:19:34, 418.71s/it]Epoch: 5, train loss: 2.14350, f_loss_w: 66.08539, f_loss_uw: 2.14350, data loss: 0.07801:  24% 6/25 [42:03<2:07:13, 401.74s/it]Epoch: 6, train loss: 1.88729, f_loss_w: 56.43133, f_loss_uw: 1.88729, data loss: 0.07424:  24% 6/25 [48:01<2:07:13, 401.74s/it]Epoch: 6, train loss: 1.88729, f_loss_w: 56.43133, f_loss_uw: 1.88729, data loss: 0.07424:  28% 7/25 [48:01<1:58:01, 393.42s/it]Epoch: 7, train loss: 1.76337, f_loss_w: 46.34170, f_loss_uw: 1.76337, data loss: 0.07186:  28% 7/25 [53:33<1:58:01, 393.42s/it]Epoch: 7, train loss: 1.76337, f_loss_w: 46.34170, f_loss_uw: 1.76337, data loss: 0.07186:  0.07622:  32% 8/25 [37:39<1:18:39, 277.64s/it]Epoch: 8, train loss: 2.29631, f_loss_w: 65.88292, f_loss_uw: 2.29631, data loss: 0.08445:  32% 8/25 [41:12<1:18:39, 277.64s/it]Epoch: 8, train loss: 2.29631, f_loss_w: 65.88292, f_loss_uw: 2.29631, data loss: 0.08445:  36% 9/25 [41:12<1:11:14, 267.16s/it]Epoch: 9, train loss: 2.10922, f_loss_w: 59.92490, f_loss_uw: 2.10922, data loss: 0.08049:  36% 9/25 [45:33<1:11:14, 267.16s/it]Epoch: 9, train loss: 2.10922, f_loss_w: 59.92490, f_loss_uw: 2.10922, data loss: 0.08049:  40% 10/25 [45:33<1:06:33, 266.21s/it]Epoch: 10, train loss: 1.94837, f_loss_w: 59.09374, f_loss_uw: 1.94837, data loss: 0.07243:  40% 10/25 [49:56<1:06:33, 266.21s/it]Epoch: 10, train loss: 1.94837, f_loss_w: 59.09374, f_loss_uw: 1.94837, data loss: 0.07243:  44% 11/25 [49:56<1:01:59, 265.67s/it]Epoch: 11, train loss: 1.81431, f_loss_w: 67.27109, f_loss_uw: 1.81431, data loss: 0.06366:  44% 11/25 [54:08<1:01:59, 265.67s/it]Epoch: 11, train loss: 1.81431, f_loss_w: 67.27109, f_loss_uw: 1.8Epoch: 16, train loss: 2.00995, f_loss_w: 0.00023, f_loss_uw: 2.00995, data loss: 0.17580:  64% 16/25 [47:45<24:31, 163.47s/it]Epoch: 16, train loss: 2.00995, f_loss_w: 0.00023, f_loss_uw: 2.00995, data loss: 0.17580:  68% 17/25 [47:45<20:43, 155.50s/it]Epoch: 17, train loss: 2.81777, f_loss_w: -0.00005, f_loss_uw: 2.81777, data loss: 0.26435:  68% 17/25 [49:11<20:43, 155.50s/it]Epoch: 17, train loss: 2.81777, f_loss_w: -0.00005, f_loss_uw: 2.81777, data loss: 0.26435:  72% 18/25 [49:11<17:11, 147.31s/it]Epoch: 18, train loss: 5.22447, f_loss_w: 0.00290, f_loss_uw: 5.22447, data loss: 0.37791:  72% 18/25 [51:45<17:11, 147.31s/it] Epoch: 18, train loss: 5.22447, f_loss_w: 0.00290, f_loss_uw: 5.22447, data loss: 0.37791:  76% 19/25 [51:45<14:48, 148.04s/it]Epoch: 19, train loss: 2.42063, f_loss_w: 0.00019, f_loss_uw: 2.42063, data loss: 0.16615:  76% 19/25 [54:33<14:48, 148.04s/it]Epoch: 19, train loss: 2.42063, f_loss_w: 0.00019, f_loss_uw: 2.42063, data loss: 0.16615:  80% 20/25 [54:33<12:31, 150.32s/38:37<37:47, 174.40s/it]Epoch: 12, train loss: 2.08826, f_loss_w: 0.00284, f_loss_uw: 2.08826, data loss: 0.12459:  48% 12/25 [42:25<37:47, 174.40s/it] Epoch: 12, train loss: 2.08826, f_loss_w: 0.00284, f_loss_uw: 2.08826, data loss: 0.12459:  52% 13/25 [42:25<36:18, 181.55s/it]Epoch: 13, train loss: 2.20135, f_loss_w: 0.00299, f_loss_uw: 2.20135, data loss: 0.10515:  52% 13/25 [47:22<36:18, 181.55s/it]Epoch: 13, train loss: 2.20135, f_loss_w: 0.00299, f_loss_uw: 2.20135, data loss: 0.10515:  56% 14/25 [47:22<36:01, 196.47s/it]Epoch: 14, train loss: 2.27531, f_loss_w: 0.00344, f_loss_uw: 2.27531, data loss: 0.10383:  56% 14/25 [51:21<36:01, 196.47s/it]Epoch: 14, train loss: 2.27531, f_loss_w: 0.00344, f_loss_uw: 2.27531, data loss: 0.10383:  60% 15/25 [51:21<33:39, 201.95s/it]Epoch: 15, train loss: 2.42681, f_loss_w: 0.00321, f_loss_uw: 2.42681, data loss: 0.10458:  60% 15/25 [54:56<33:39, 201.95s/it]Epoch: 15, train loss: 2.42681, f_loss_w: 0.00321, f_loss_uw: 2.42681, data loss: 0.10458:  64% 16/25 ss: 2.89727, f_loss_w: 0.00009, f_loss_uw: 2.89727, data loss: 0.12658:  64% 16/25 [45:23<26:24, 176.05s/it]Epoch: 16, train loss: 2.89727, f_loss_w: 0.00009, f_loss_uw: 2.89727, data loss: 0.12658:  68% 17/25 [45:23<23:04, 173.03s/it]Epoch: 17, train loss: 3.02300, f_loss_w: 0.00006, f_loss_uw: 3.02300, data loss: 0.11858:  68% 17/25 [48:09<23:04, 173.03s/it]Epoch: 17, train loss: 3.02300, f_loss_w: 0.00006, f_loss_uw: 3.02300, data loss: 0.11858:  72% 18/25 [48:09<20:05, 172.21s/it]Epoch: 18, train loss: 3.08798, f_loss_w: 0.00004, f_loss_uw: 3.08798, data loss: 0.11993:  72% 18/25 [50:37<20:05, 172.21s/it]Epoch: 18, train loss: 3.08798, f_loss_w: 0.00004, f_loss_uw: 3.08798, data loss: 0.11993:  76% 19/25 [50:37<16:56, 169.43s/it]Epoch: 19, train loss: 3.18162, f_loss_w: 0.00003, f_loss_uw: 3.18162, data loss: 0.11400:  76% 19/25 [53:07<16:56, 169.43s/it]Epoch: 19, train loss: 3.18162, f_loss_w: 0.00003, f_loss_uw: 3.18162, data loss: 0.11400:  80% 20/25 [53:07<13:56, 167.24s/it]Epoch: 20, train lof_loss_uw: 150.98212, data loss: 2.07338:  80% 20/25 [47:23<12:56, 155.37s/it]Epoch: 20, train loss: 133.69939, f_loss_w: -0.00129, f_loss_uw: 133.69939, data loss: 1.81357:  80% 20/25 [49:40<12:56, 155.37s/it]Epoch: 20, train loss: 133.69939, f_loss_w: -0.00129, f_loss_uw: 133.69939, data loss: 1.81357:  84% 21/25 [49:40<10:13, 153.36s/it]Epoch: 21, train loss: 124.74782, f_loss_w: -0.00115, f_loss_uw: 124.74782, data loss: 1.62967:  84% 21/25 [51:55<10:13, 153.36s/it]Epoch: 21, train loss: 124.74782, f_loss_w: -0.00115, f_loss_uw: 124.74782, data loss: 1.62967:  88% 22/25 [51:55<07:33, 151.32s/it]Epoch: 22, train loss: 117.76646, f_loss_w: -0.00151, f_loss_uw: 117.76646, data loss: 1.53717:  88% 22/25 [53:48<07:33, 151.32s/it]Epoch: 22, train loss: 117.76646, f_loss_w: -0.00151, f_loss_uw: 117.76646, data loss: 1.53717:  92% 23/25 [53:48<04:54, 147.10s/it]Epoch: 23, train loss: 113.42693, f_loss_w: -0.00113, f_loss_uw: 113.42693, data loss: 1.43249:  92% 23/25 [55:56<04:54, 147.10s/it]Epoch: 23, tra00, f_loss_uw: 7.47524, data loss: 0.17431:  48% 12/25 [45:15<38:31, 177.81s/it]Epoch: 12, train loss: 7.47524, f_loss_w: 45603722.56000, f_loss_uw: 7.47524, data loss: 0.17431:  52% 13/25 [45:15<36:07, 180.62s/it]Epoch: 13, train loss: 6.62696, f_loss_w: 52401861.44000, f_loss_uw: 6.62696, data loss: 0.16187:  52% 13/25 [48:41<36:07, 180.62s/it]Epoch: 13, train loss: 6.62696, f_loss_w: 52401861.44000, f_loss_uw: 6.62696, data loss: 0.16187:  56% 14/25 [48:41<33:42, 183.83s/it]Epoch: 14, train loss: 6.07382, f_loss_w: 58075302.24000, f_loss_uw: 6.07382, data loss: 0.15467:  56% 14/25 [52:11<33:42, 183.83s/it]Epoch: 14, train loss: 6.07382, f_loss_w: 58075302.24000, f_loss_uw: 6.07382, data loss: 0.15467:  60% 15/25 [52:11<31:11, 187.15s/it]Epoch: 15, train loss: 5.51449, f_loss_w: 72942377.04000, f_loss_uw: 5.51449, data loss: 0.14602:  60% 15/25 [56:08<31:11, 187.15s/it]Epoch: 15, train loss: 5.51449, f_loss_w: 72942377.04000, f_loss_uw: 5.51449, data loss: 0.14602:  64% 16/25 [56:08<28:59, 193.30s/it0.08826:  48% 12/25 [47:16<51:04, 235.71s/it]Epoch: 12, train loss: 2.19599, f_loss_w: 4.29535, f_loss_uw: 2.19599, data loss: 0.07682:  48% 12/25 [49:57<51:04, 235.71s/it] Epoch: 12, train loss: 2.19599, f_loss_w: 4.29535, f_loss_uw: 2.19599, data loss: 0.07682:  52% 13/25 [49:57<45:08, 225.68s/it]Epoch: 13, train loss: 2.24309, f_loss_w: 1.67074, f_loss_uw: 2.24309, data loss: 0.08074:  52% 13/25 [52:23<45:08, 225.68s/it]Epoch: 13, train loss: 2.24309, f_loss_w: 1.67074, f_loss_uw: 2.24309, data loss: 0.08074:  56% 14/25 [52:23<39:28, 215.34s/it]Epoch: 14, train loss: 2.21919, f_loss_w: 1.61182, f_loss_uw: 2.21919, data loss: 0.08267:  56% 14/25 [55:01<39:28, 215.34s/it]Epoch: 14, train loss: 2.21919, f_loss_w: 1.61182, f_loss_uw: 2.21919, data loss: 0.08267:  60% 15/25 [55:01<34:40, 208.10s/it]Epoch: 15, train loss: 2.09549, f_loss_w: 1.55667, f_loss_uw: 2.09549, data loss: 0.08064:  60% 15/25 [57:32<34:40, 208.10s/it]Epoch: 15, train loss: 2.09549, f_loss_w: 1.55667, f_loss_uw: 2.09549, data loss:Checkpoint is saved at checkpoints//darcy-cpino-3.pt
Checkpoint is saved at checkpoints//darcy-cpino-3-weights.pt
in loss: 113.42693, f_loss_w: -0.00113, f_loss_uw: 113.42693, data loss: 1.43249:  96% 24/25 [55:56<02:25, 145.06s/it]Epoch: 24, train loss: 107.03135, f_loss_w: -0.00088, f_loss_uw: 107.03135, data loss: 1.33479:  96% 24/25 [57:49<02:25, 145.06s/it]Epoch: 24, train loss: 107.03135, f_loss_w: -0.00088, f_loss_uw: 107.03135, data loss: 1.33479: 100% 25/25 [57:49<00:00, 141.56s/it]Epoch: 24, train loss: 107.03135, f_loss_w: -0.00088, f_loss_uw: 107.03135, data loss: 1.33479: 100% 25/25 [57:49<00:00, 138.77s/it]
wandb: Waiting for W&B process to finish, PID 15391... (success).
it]Epoch: 20, train loss: 2.78298, f_loss_w: 0.00056, f_loss_uw: 2.78298, data loss: 0.11868:  80% 20/25 [51:38<13:10, 158.00s/it]Epoch: 20, train loss: 2.78298, f_loss_w: 0.00056, f_loss_uw: 2.78298, data loss: 0.11868:  84% 21/25 [51:38<10:45, 161.40s/it]Epoch: 21, train loss: 2.92690, f_loss_w: 0.00018, f_loss_uw: 2.92690, data loss: 0.10261:  84% 21/25 [53:49<10:45, 161.40s/it]Epoch: 21, train loss: 2.92690, f_loss_w: 0.00018, f_loss_uw: 2.92690, data loss: 0.10261:  88% 22/25 [53:49<07:53, 157.99s/it]Epoch: 22, train loss: 2.80787, f_loss_w: 0.00033, f_loss_uw: 2.80787, data loss: 0.11218:  88% 22/25 [55:54<07:53, 157.99s/it]Epoch: 22, train loss: 2.80787, f_loss_w: 0.00033, f_loss_uw: 2.80787, data loss: 0.11218:  92% 23/25 [55:54<05:08, 154.43s/it]Epoch: 23, train loss: 2.98751, f_loss_w: 0.00023, f_loss_uw: 2.98751, data loss: 0.13956:  92% 23/25 [57:51<05:08, 154.43s/it]Epoch: 23, train loss: 2.98751, f_loss_w: 0.00023, f_loss_uw: 2.98751, data loss: 0.13956:  96% 24/25 [57:51<02:30, 150.33s/wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss ▁▁▁▁▁▁▁▁▁▁▁█▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:            f loss ▁▁▁▁▁▁▁▁▁▁▁█▂▂▃▃▃▃▃▃▃▂▂▂▂
wandb:   f loss weighted ▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▁▁▁▁▁▁▁▁▁▁▁█▂▂▃▃▃▃▃▃▃▂▂▂▂
wandb: 
wandb: Run summary:
wandb:         data loss 1.33479
wandb:            f loss 107.03135
wandb:   f loss weighted -0.00088
wandb:        train loss 107.03135
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced lilac-surf-189: https://wandb.ai/rishigundakaram/CPINO/runs/35iohf7h
wandb: Find logs at: ./wandb/run-20220615_110423-35iohf7h/logs/debug.log
wandb: 

Done!
t]Epoch: 8, train loss: 2.51723, f_loss_w: 0.11683, f_loss_uw: 2.51723, data loss: 0.11130:  32% 8/25 [43:39<1:29:43, 316.68s/it]Epoch: 8, train loss: 2.51723, f_loss_w: 0.11683, f_loss_uw: 2.51723, data loss: 0.11130:  36% 9/25 [43:39<1:24:12, 315.75s/it]Epoch: 9, train loss: 2.54995, f_loss_w: 0.10245, f_loss_uw: 2.54995, data loss: 0.09457:  36% 9/25 [48:41<1:24:12, 315.75s/it]Epoch: 9, train loss: 2.54995, f_loss_w: 0.10245, f_loss_uw: 2.54995, data loss: 0.09457:  40% 10/25 [48:41<1:18:22, 313.52s/it]Epoch: 10, train loss: 2.68938, f_loss_w: 0.06243, f_loss_uw: 2.68938, data loss: 0.08313:  40% 10/25 [54:16<1:18:22, 313.52s/it]Epoch: 10, train loss: 2.68938, f_loss_w: 0.06243, f_loss_uw: 2.68938, data loss: 0.08313:  44% 11/25 [54:16<1:13:53, 316.66s/it]Epoch: 11, train loss: 2.73246, f_loss_w: 0.04621, f_loss_uw: 2.73246, data loss: 0.07671:  44% 11/25 [58:32<1:13:53, 316.66s/it]Epoch: 11, train loss: 2.73246, f_loss_w: 0.04621, f_loss_uw: 2.73246, data loss: 0.07671:  48% 12/25 [58:32<1:06:47, , 168.48s/it]Epoch: 16, train loss: 2.13473, f_loss_w: 0.00094, f_loss_uw: 2.13473, data loss: 0.08251:  64% 16/25 [52:54<25:16, 168.48s/it]Epoch: 16, train loss: 2.13473, f_loss_w: 0.00094, f_loss_uw: 2.13473, data loss: 0.08251:  68% 17/25 [52:54<21:12, 159.02s/it]Epoch: 17, train loss: 2.27426, f_loss_w: 0.00175, f_loss_uw: 2.27426, data loss: 0.07423:  68% 17/25 [54:37<21:12, 159.02s/it]Epoch: 17, train loss: 2.27426, f_loss_w: 0.00175, f_loss_uw: 2.27426, data loss: 0.07423:  72% 18/25 [54:37<17:47, 152.52s/it]Epoch: 18, train loss: 3.02920, f_loss_w: -0.00048, f_loss_uw: 3.02920, data loss: 0.16782:  72% 18/25 [56:42<17:47, 152.52s/it]Epoch: 18, train loss: 3.02920, f_loss_w: -0.00048, f_loss_uw: 3.02920, data loss: 0.16782:  76% 19/25 [56:42<14:55, 149.31s/it]Epoch: 19, train loss: 2.33414, f_loss_w: 0.00250, f_loss_uw: 2.33414, data loss: 0.07433:  76% 19/25 [59:01<14:55, 149.31s/it] Epoch: 19, train loss: 2.33414, f_loss_w: 0.00250, f_loss_uw: 2.33414, data loss: 0.07433:  80% 20/25 [59:01<12<26:19, 175.49s/it]Epoch: 16, train loss: 48.63152, f_loss_w: -0.00904, f_loss_uw: 48.63152, data loss: 1.20888:  64% 16/25 [51:57<26:19, 175.49s/it]Epoch: 16, train loss: 48.63152, f_loss_w: -0.00904, f_loss_uw: 48.63152, data loss: 1.20888:  68% 17/25 [51:57<24:01, 180.14s/it]Epoch: 17, train loss: 10.26536, f_loss_w: 0.00032, f_loss_uw: 10.26536, data loss: 0.20463:  68% 17/25 [54:08<24:01, 180.14s/it] Epoch: 17, train loss: 10.26536, f_loss_w: 0.00032, f_loss_uw: 10.26536, data loss: 0.20463:  72% 18/25 [54:08<20:20, 174.30s/it]Epoch: 18, train loss: 7.29038, f_loss_w: 0.00009, f_loss_uw: 7.29038, data loss: 0.17174:  72% 18/25 [56:09<20:20, 174.30s/it]  Epoch: 18, train loss: 7.29038, f_loss_w: 0.00009, f_loss_uw: 7.29038, data loss: 0.17174:  76% 19/25 [56:09<16:49, 168.19s/it]Epoch: 19, train loss: 5.29181, f_loss_w: 0.00032, f_loss_uw: 5.29181, data loss: 0.16023:  76% 19/25 [59:03<16:49, 168.19s/it]Epoch: 19, train loss: 5.29181, f_loss_w: 0.00032, f_loss_uw: 5.29181, data loss: 0.16023:  80%:18, 283.46s/it]Epoch: 8, train loss: 1.75870, f_loss_w: 0.05457, f_loss_uw: 1.75870, data loss: 0.05374:  32% 8/25 [44:20<1:20:18, 283.46s/it]Epoch: 8, train loss: 1.75870, f_loss_w: 0.05457, f_loss_uw: 1.75870, data loss: 0.05374:  36% 9/25 [44:20<1:15:39, 283.71s/it]Epoch: 9, train loss: 1.70717, f_loss_w: 0.04594, f_loss_uw: 1.70717, data loss: 0.05130:  36% 9/25 [49:25<1:15:39, 283.71s/it]Epoch: 9, train loss: 1.70717, f_loss_w: 0.04594, f_loss_uw: 1.70717, data loss: 0.05130:  40% 10/25 [49:25<1:11:46, 287.08s/it]Epoch: 10, train loss: 1.67566, f_loss_w: 0.03910, f_loss_uw: 1.67566, data loss: 0.04952:  40% 10/25 [54:17<1:11:46, 287.08s/it]Epoch: 10, train loss: 1.67566, f_loss_w: 0.03910, f_loss_uw: 1.67566, data loss: 0.04952:  44% 11/25 [54:17<1:07:09, 287.79s/it]Epoch: 11, train loss: 1.63703, f_loss_w: 0.03747, f_loss_uw: 1.63703, data loss: 0.04803:  44% 11/25 [59:19<1:07:09, 287.79s/it]Epoch: 11, train loss: 1.63703, f_loss_w: 0.03747, f_loss_uw: 1.63703, data loss: 0.04803:  48% 12/25 [5Checkpoint is saved at checkpoints//darcy-cpino-7.pt
Checkpoint is saved at checkpoints//darcy-cpino-7-weights.pt
it]Epoch: 24, train loss: 3.00462, f_loss_w: 0.00015, f_loss_uw: 3.00462, data loss: 0.16344:  96% 24/25 [59:37<02:30, 150.33s/it]Epoch: 24, train loss: 3.00462, f_loss_w: 0.00015, f_loss_uw: 3.00462, data loss: 0.16344: 100% 25/25 [59:37<00:00, 145.52s/it]Epoch: 24, train loss: 3.00462, f_loss_w: 0.00015, f_loss_uw: 3.00462, data loss: 0.16344: 100% 25/25 [59:37<00:00, 143.09s/it]
wandb: Waiting for W&B process to finish, PID 30145... (success).
 [50:05<55:46, 257.44s/it]  Epoch: 12, train loss: 2.51691, f_loss_w: 0.00212, f_loss_uw: 2.51691, data loss: 0.10230:  48% 12/25 [52:26<55:46, 257.44s/it]Epoch: 12, train loss: 2.51691, f_loss_w: 0.00212, f_loss_uw: 2.51691, data loss: 0.10230:  52% 13/25 [52:26<48:23, 241.92s/it]Epoch: 13, train loss: 2.33268, f_loss_w: 0.00197, f_loss_uw: 2.33268, data loss: 0.07912:  52% 13/25 [55:01<48:23, 241.92s/it]Epoch: 13, train loss: 2.33268, f_loss_w: 0.00197, f_loss_uw: 2.33268, data loss: 0.07912:  56% 14/25 [55:01<42:17, 230.64s/it]Epoch: 14, train loss: 2.43149, f_loss_w: 0.00206, f_loss_uw: 2.43149, data loss: 0.09610:  56% 14/25 [57:15<42:17, 230.64s/it]Epoch: 14, train loss: 2.43149, f_loss_w: 0.00206, f_loss_uw: 2.43149, data loss: 0.09610:  60% 15/25 [57:15<36:24, 218.41s/it]Epoch: 15, train loss: 2.33115, f_loss_w: 0.00197, f_loss_uw: 2.33115, data loss: 0.08204:  60% 15/25 [59:45<36:24, 218.41s/it]Epoch: 15, train loss: 2.33115, f_loss_w: 0.00197, f_loss_uw: 2.33115, data loss: 0.08204:  64% 16/wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▂▂▂▂▂▂▁▂▂▃▂▁▁▁▂▄▅▂▁▁▁▁▂▂
wandb:            f loss ▃▁▁▂▃▃▃▂▃▂▄▂▂▂▂▃▃█▃▃▂▃▃▃▃
wandb:   f loss weighted ▁▆▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▆▆▆▆▆▆
wandb:        train loss ▃▁▁▂▃▃▃▂▃▂▄▂▂▂▂▃▃█▃▃▂▃▃▃▃
wandb: 
wandb: Run summary:
wandb:         data loss 0.16344
wandb:            f loss 3.00462
wandb:   f loss weighted 0.00015
wandb:        train loss 3.00462
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced worldly-tree-207: https://wandb.ai/rishigundakaram/CPINO/runs/uxjhlxiq
wandb: Find logs at: ./wandb/run-20220615_110425-uxjhlxiq/logs/debug.log
wandb: 

Done!
7.71s/it]Epoch: 16, train loss: 2.41838, f_loss_w: 0.00222, f_loss_uw: 2.41838, data loss: 0.20774:  64% 16/25 [50:16<25:09, 167.71s/it]Epoch: 16, train loss: 2.41838, f_loss_w: 0.00222, f_loss_uw: 2.41838, data loss: 0.20774:  68% 17/25 [50:16<21:30, 161.27s/it]Epoch: 17, train loss: 3.14545, f_loss_w: 0.01262, f_loss_uw: 3.14545, data loss: 0.40390:  68% 17/25 [52:35<21:30, 161.27s/it]Epoch: 17, train loss: 3.14545, f_loss_w: 0.01262, f_loss_uw: 3.14545, data loss: 0.40390:  72% 18/25 [52:35<18:30, 158.61s/it]Epoch: 18, train loss: 2.00973, f_loss_w: 0.00557, f_loss_uw: 2.00973, data loss: 0.17014:  72% 18/25 [56:21<18:30, 158.61s/it]Epoch: 18, train loss: 2.00973, f_loss_w: 0.00557, f_loss_uw: 2.00973, data loss: 0.17014:  76% 19/25 [56:21<16:38, 166.44s/it]Epoch: 19, train loss: 2.34631, f_loss_w: 0.01526, f_loss_uw: 2.34631, data loss: 0.15723:  76% 19/25 [1:00:11<16:38, 166.44s/it]Epoch: 19, train loss: 2.34631, f_loss_w: 0.01526, f_loss_uw: 2.34631, data loss: 0.15723:  80% 20/25 [1:00:11<14:2848% 12/25 [46:49<49:44, 229.60s/it]Epoch: 12, train loss: 3.77363, f_loss_w: 0.00233, f_loss_uw: 3.77363, data loss: 0.13696:  48% 12/25 [50:26<49:44, 229.60s/it]Epoch: 12, train loss: 3.77363, f_loss_w: 0.00233, f_loss_uw: 3.77363, data loss: 0.13696:  52% 13/25 [50:26<45:33, 227.82s/it]Epoch: 13, train loss: 3.48080, f_loss_w: 0.00215, f_loss_uw: 3.48080, data loss: 0.12893:  52% 13/25 [54:08<45:33, 227.82s/it]Epoch: 13, train loss: 3.48080, f_loss_w: 0.00215, f_loss_uw: 3.48080, data loss: 0.12893:  56% 14/25 [54:08<41:37, 227.08s/it]Epoch: 14, train loss: 4.02132, f_loss_w: 0.00333, f_loss_uw: 4.02132, data loss: 0.16236:  56% 14/25 [57:36<41:37, 227.08s/it]Epoch: 14, train loss: 4.02132, f_loss_w: 0.00333, f_loss_uw: 4.02132, data loss: 0.16236:  60% 15/25 [57:36<37:26, 224.63s/it]Epoch: 15, train loss: 3.56883, f_loss_w: 0.00111, f_loss_uw: 3.56883, data loss: 0.13817:  60% 15/25 [1:00:32<37:26, 224.63s/it]Epoch: 15, train loss: 3.56883, f_loss_w: 0.00111, f_loss_uw: 3.56883, data loss: 0.13817::28, 329.94s/it]Epoch: 8, train loss: 2.07813, f_loss_w: 0.01080, f_loss_uw: 2.07813, data loss: 0.06171:  32% 8/25 [49:01<1:33:28, 329.94s/it]Epoch: 8, train loss: 2.07813, f_loss_w: 0.01080, f_loss_uw: 2.07813, data loss: 0.06171:  36% 9/25 [49:01<1:24:55, 318.49s/it]Epoch: 9, train loss: 1.93473, f_loss_w: 0.00779, f_loss_uw: 1.93473, data loss: 0.05253:  36% 9/25 [53:33<1:24:55, 318.49s/it]Epoch: 9, train loss: 1.93473, f_loss_w: 0.00779, f_loss_uw: 1.93473, data loss: 0.05253:  40% 10/25 [53:33<1:17:50, 311.34s/it]Epoch: 10, train loss: 1.85244, f_loss_w: 0.00672, f_loss_uw: 1.85244, data loss: 0.05420:  40% 10/25 [58:27<1:17:50, 311.34s/it]Epoch: 10, train loss: 1.85244, f_loss_w: 0.00672, f_loss_uw: 1.85244, data loss: 0.05420:  44% 11/25 [58:27<1:12:02, 308.74s/it]Epoch: 11, train loss: 1.85140, f_loss_w: 0.00706, f_loss_uw: 1.85140, data loss: 0.05796:  44% 11/25 [1:02:18<1:12:02, 308.74s/it]Epoch: 11, train loss: 1.85140, f_loss_w: 0.00706, f_loss_uw: 1.85140, data loss: 0.05796:  48% 12/25 it]Epoch: 20, train loss: 2.49636, f_loss_w: 0.00018, f_loss_uw: 2.49636, data loss: 0.16850:  80% 20/25 [57:02<12:31, 150.32s/it]Epoch: 20, train loss: 2.49636, f_loss_w: 0.00018, f_loss_uw: 2.49636, data loss: 0.16850:  84% 21/25 [57:02<10:00, 150.20s/it]Epoch: 21, train loss: 2.51645, f_loss_w: 0.00006, f_loss_uw: 2.51645, data loss: 0.17604:  84% 21/25 [59:05<10:00, 150.20s/it]Epoch: 21, train loss: 2.51645, f_loss_w: 0.00006, f_loss_uw: 2.51645, data loss: 0.17604:  88% 22/25 [59:05<07:21, 147.15s/it]Epoch: 22, train loss: 2.29774, f_loss_w: 0.00009, f_loss_uw: 2.29774, data loss: 0.15089:  88% 22/25 [1:01:04<07:21, 147.15s/it]Epoch: 22, train loss: 2.29774, f_loss_w: 0.00009, f_loss_uw: 2.29774, data loss: 0.15089:  92% 23/25 [1:01:04<04:48, 144.10s/it]Epoch: 23, train loss: 2.41295, f_loss_w: 0.00006, f_loss_uw: 2.41295, data loss: 0.14369:  92% 23/25 [1:03:11<04:48, 144.10s/it]Epoch: 23, train loss: 2.41295, f_loss_w: 0.00006, f_loss_uw: 2.41295, data loss: 0.14369:  96% 24/25 [1:03:11<02:22, ss: 2.94745, f_loss_w: 0.00003, f_loss_uw: 2.94745, data loss: 0.11113:  80% 20/25 [55:42<13:56, 167.24s/it]Epoch: 20, train loss: 2.94745, f_loss_w: 0.00003, f_loss_uw: 2.94745, data loss: 0.11113:  84% 21/25 [55:42<11:03, 165.91s/it]Epoch: 21, train loss: 2.81449, f_loss_w: 0.00005, f_loss_uw: 2.81449, data loss: 0.11284:  84% 21/25 [57:45<11:03, 165.91s/it]Epoch: 21, train loss: 2.81449, f_loss_w: 0.00005, f_loss_uw: 2.81449, data loss: 0.11284:  88% 22/25 [57:45<08:03, 161.07s/it]Epoch: 22, train loss: 2.79622, f_loss_w: 0.00007, f_loss_uw: 2.79622, data loss: 0.11769:  88% 22/25 [59:38<08:03, 161.07s/it]Epoch: 22, train loss: 2.79622, f_loss_w: 0.00007, f_loss_uw: 2.79622, data loss: 0.11769:  92% 23/25 [59:38<05:11, 155.83s/it]Epoch: 23, train loss: 2.63592, f_loss_w: 0.00005, f_loss_uw: 2.63592, data loss: 0.11247:  92% 23/25 [1:01:29<05:11, 155.83s/it]Epoch: 23, train loss: 2.63592, f_loss_w: 0.00005, f_loss_uw: 2.63592, data loss: 0.11247:  96% 24/25 [1:01:29<02:31, 151.00s/it]Epoch: 24, traiCheckpoint is saved at checkpoints//darcy-cpino-19.pt
Checkpoint is saved at checkpoints//darcy-cpino-19-weights.pt
n loss: 2.62987, f_loss_w: 0.00003, f_loss_uw: 2.62987, data loss: 0.10494:  96% 24/25 [1:03:26<02:31, 151.00s/it]Epoch: 24, train loss: 2.62987, f_loss_w: 0.00003, f_loss_uw: 2.62987, data loss: 0.10494: 100% 25/25 [1:03:26<00:00, 147.27s/it]Epoch: 24, train loss: 2.62987, f_loss_w: 0.00003, f_loss_uw: 2.62987, data loss: 0.10494: 100% 25/25 [1:03:26<00:00, 152.25s/it]
wandb: Waiting for W&B process to finish, PID 18011... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▅▄▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:            f loss ▅▂▂▂▁▁▁▂▂▂▁▂▄█▇▄▃▃▃▃▃▃▃▂▂
wandb:   f loss weighted █▃▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▅▂▂▂▁▁▁▂▂▂▁▂▄█▇▄▃▃▃▃▃▃▃▂▂
wandb: 
wandb: Run summary:
wandb:         data loss 0.10494
wandb:            f loss 2.62987
wandb:   f loss weighted 3e-05
wandb:        train loss 2.62987
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced efficient-smoke-204: https://wandb.ai/rishigundakaram/CPINO/runs/345grtly
wandb: Find logs at: ./wandb/run-20220615_110425-345grtly/logs/debug.log
wandb: 

Done!
Checkpoint is saved at checkpoints//darcy-cpino-8.pt
Checkpoint is saved at checkpoints//darcy-cpino-8-weights.pt
142.21s/it]Epoch: 24, train loss: 2.32087, f_loss_w: 0.00007, f_loss_uw: 2.32087, data loss: 0.13846:  96% 24/25 [1:04:57<02:22, 142.21s/it]Epoch: 24, train loss: 2.32087, f_loss_w: 0.00007, f_loss_uw: 2.32087, data loss: 0.13846: 100% 25/25 [1:04:57<00:00, 138.35s/it]Epoch: 24, train loss: 2.32087, f_loss_w: 0.00007, f_loss_uw: 2.32087, data loss: 0.13846: 100% 25/25 [1:04:57<00:00, 155.92s/it]
wandb: Waiting for W&B process to finish, PID 11711... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▂▂▂▁▁▂▂▁▁▁▁▂▂▃▁▂▃▄▂▂▂▁▁▁
wandb:            f loss ▅▂▂▂▁▁▃▄▃▄▃▃▃▂▄▁▁▃█▂▂▂▂▂▂
wandb:   f loss weighted ▁████████████████████████
wandb:        train loss ▅▂▂▂▁▁▃▄▃▄▃▃▃▂▄▁▁▃█▂▂▂▂▂▂
wandb: 
wandb: Run summary:
wandb:         data loss 0.13846
wandb:            f loss 2.32087
wandb:   f loss weighted 7e-05
wandb:        train loss 2.32087
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced legendary-donkey-188: https://wandb.ai/rishigundakaram/CPINO/runs/1nx69q86
wandb: Find logs at: ./wandb/run-20220615_110423-1nx69q86/logs/debug.log
wandb: 

Done!
 f_loss_uw: 2.07835, data loss: 0.08242:  32% 8/25 [45:42<1:30:47, 320.44s/it]Epoch: 8, train loss: 1.91659, f_loss_w: 18938.15457, f_loss_uw: 1.91659, data loss: 0.07959:  32% 8/25 [50:21<1:30:47, 320.44s/it]Epoch: 8, train loss: 1.91659, f_loss_w: 18938.15457, f_loss_uw: 1.91659, data loss: 0.07959:  36% 9/25 [50:21<1:23:39, 313.71s/it]Epoch: 9, train loss: 1.77754, f_loss_w: 21179.18250, f_loss_uw: 1.77754, data loss: 0.07243:  36% 9/25 [55:24<1:23:39, 313.71s/it]Epoch: 9, train loss: 1.77754, f_loss_w: 21179.18250, f_loss_uw: 1.77754, data loss: 0.07243:  40% 10/25 [55:24<1:18:00, 312.05s/it]Epoch: 10, train loss: 1.68948, f_loss_w: 19774.96012, f_loss_uw: 1.68948, data loss: 0.06896:  40% 10/25 [1:00:31<1:18:00, 312.05s/it]Epoch: 10, train loss: 1.68948, f_loss_w: 19774.96012, f_loss_uw: 1.68948, data loss: 0.06896:  44% 11/25 [1:00:31<1:12:38, 311.30s/it]Epoch: 11, train loss: 1.64413, f_loss_w: 16822.50334, f_loss_uw: 1.64413, data loss: 0.06605:  44% 11/25 [1:06:01<1:12:38, 311.30s/it]Epoch: 1:20, 148.12s/it]Epoch: 20, train loss: 2.18488, f_loss_w: 0.00209, f_loss_uw: 2.18488, data loss: 0.06575:  80% 20/25 [1:01:19<12:20, 148.12s/it]Epoch: 20, train loss: 2.18488, f_loss_w: 0.00209, f_loss_uw: 2.18488, data loss: 0.06575:  84% 21/25 [1:01:19<09:48, 147.00s/it]Epoch: 21, train loss: 2.24462, f_loss_w: 0.00192, f_loss_uw: 2.24462, data loss: 0.06675:  84% 21/25 [1:03:15<09:48, 147.00s/it]Epoch: 21, train loss: 2.24462, f_loss_w: 0.00192, f_loss_uw: 2.24462, data loss: 0.06675:  88% 22/25 [1:03:15<07:10, 143.52s/it]Epoch: 22, train loss: 2.23284, f_loss_w: 0.00156, f_loss_uw: 2.23284, data loss: 0.06516:  88% 22/25 [1:05:12<07:10, 143.52s/it]Epoch: 22, train loss: 2.23284, f_loss_w: 0.00156, f_loss_uw: 2.23284, data loss: 0.06516:  92% 23/25 [1:05:12<04:41, 140.69s/it]Epoch: 23, train loss: 2.23641, f_loss_w: 0.00109, f_loss_uw: 2.23641, data loss: 0.06231:  92% 23/25 [1:07:13<04:41, 140.69s/it]Epoch: 23, train loss: 2.23641, f_loss_w: 0.00109, f_loss_uw: 2.23641, data loss: 0.06231:  96% 2:45, 330.90s/it]Epoch: 8, train loss: 1.78300, f_loss_w: 0.01869, f_loss_uw: 1.78300, data loss: 0.05401:  32% 8/25 [50:28<1:33:45, 330.90s/it]Epoch: 8, train loss: 1.78300, f_loss_w: 0.01869, f_loss_uw: 1.78300, data loss: 0.05401:  36% 9/25 [50:28<1:28:27, 331.69s/it]Epoch: 9, train loss: 1.70254, f_loss_w: 0.01647, f_loss_uw: 1.70254, data loss: 0.05051:  36% 9/25 [56:03<1:28:27, 331.69s/it]Epoch: 9, train loss: 1.70254, f_loss_w: 0.01647, f_loss_uw: 1.70254, data loss: 0.05051:  40% 10/25 [56:03<1:23:03, 332.24s/it]Epoch: 10, train loss: 1.61677, f_loss_w: 0.01604, f_loss_uw: 1.61677, data loss: 0.04732:  40% 10/25 [1:02:21<1:23:03, 332.24s/it]Epoch: 10, train loss: 1.61677, f_loss_w: 0.01604, f_loss_uw: 1.61677, data loss: 0.04732:  44% 11/25 [1:02:21<1:19:03, 338.84s/it]Epoch: 11, train loss: 1.55764, f_loss_w: 0.01613, f_loss_uw: 1.55764, data loss: 0.04372:  44% 11/25 [1:08:05<1:19:03, 338.84s/it]Epoch: 11, train loss: 1.55764, f_loss_w: 0.01613, f_loss_uw: 1.55764, data loss: 0.04372:  48% 12 0.08064:  64% 16/25 [57:32<30:10, 201.13s/it]Epoch: 16, train loss: 2.00693, f_loss_w: 1.55162, f_loss_uw: 2.00693, data loss: 0.07815:  64% 16/25 [59:57<30:10, 201.13s/it]Epoch: 16, train loss: 2.00693, f_loss_w: 1.55162, f_loss_uw: 2.00693, data loss: 0.07815:  68% 17/25 [59:57<25:55, 194.41s/it]Epoch: 17, train loss: 1.92419, f_loss_w: 1.62614, f_loss_uw: 1.92419, data loss: 0.07711:  68% 17/25 [1:02:43<25:55, 194.41s/it]Epoch: 17, train loss: 1.92419, f_loss_w: 1.62614, f_loss_uw: 1.92419, data loss: 0.07711:  72% 18/25 [1:02:43<22:17, 191.02s/it]Epoch: 18, train loss: 1.85061, f_loss_w: 1.59403, f_loss_uw: 1.85061, data loss: 0.07696:  72% 18/25 [1:05:30<22:17, 191.02s/it]Epoch: 18, train loss: 1.85061, f_loss_w: 1.59403, f_loss_uw: 1.85061, data loss: 0.07696:  76% 19/25 [1:05:30<18:49, 188.25s/it]Epoch: 19, train loss: 1.79782, f_loss_w: 1.57662, f_loss_uw: 1.79782, data loss: 0.07414:  76% 19/25 [1:08:09<18:49, 188.25s/it]Epoch: 19, train loss: 1.79782, f_loss_w: 1.57662, f_loss_uw: 1.79782, Checkpoint is saved at checkpoints//darcy-cpino-18.pt
Checkpoint is saved at checkpoints//darcy-cpino-18-weights.pt
4/25 [1:07:13<02:18, 138.54s/it]Epoch: 24, train loss: 2.25266, f_loss_w: 0.00127, f_loss_uw: 2.25266, data loss: 0.06059:  96% 24/25 [1:09:11<02:18, 138.54s/it]Epoch: 24, train loss: 2.25266, f_loss_w: 0.00127, f_loss_uw: 2.25266, data loss: 0.06059: 100% 25/25 [1:09:11<00:00, 136.33s/it]Epoch: 24, train loss: 2.25266, f_loss_w: 0.00127, f_loss_uw: 2.25266, data loss: 0.06059: 100% 25/25 [1:09:11<00:00, 166.08s/it]
wandb: Waiting for W&B process to finish, PID 22367... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▃▃▂▂▂▂▁▁▁▁▁▂▁▁▂▁▁▃▁▁▁▁▁▁
wandb:            f loss ▆▁▄▃▁▃▃▃▂▃▂▃▃▂▂▃▂▃█▃▂▂▂▂▃
wandb:   f loss weighted █▄▄▃▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▆▁▄▃▁▃▃▃▂▃▂▃▃▂▂▃▂▃█▃▂▂▂▂▃
wandb: 
wandb: Run summary:
wandb:         data loss 0.06059
wandb:            f loss 2.25266
wandb:   f loss weighted 0.00127
wandb:        train loss 2.25266
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced devout-sponge-205: https://wandb.ai/rishigundakaram/CPINO/runs/28256sve
wandb: Find logs at: ./wandb/run-20220615_110425-28256sve/logs/debug.log
wandb: 

Done!
:55, 324.44s/it]Epoch: 8, train loss: 1.96872, f_loss_w: 0.62015, f_loss_uw: 1.96872, data loss: 0.07345:  32% 8/25 [50:02<1:31:55, 324.44s/it]Epoch: 8, train loss: 1.96872, f_loss_w: 0.62015, f_loss_uw: 1.96872, data loss: 0.07345:  36% 9/25 [50:02<1:27:48, 329.31s/it]Epoch: 9, train loss: 1.80360, f_loss_w: 0.59764, f_loss_uw: 1.80360, data loss: 0.06335:  36% 9/25 [56:38<1:27:48, 329.31s/it]Epoch: 9, train loss: 1.80360, f_loss_w: 0.59764, f_loss_uw: 1.80360, data loss: 0.06335:  40% 10/25 [56:38<1:24:52, 339.50s/it]Epoch: 10, train loss: 1.67539, f_loss_w: 0.62135, f_loss_uw: 1.67539, data loss: 0.05630:  40% 10/25 [1:03:03<1:24:52, 339.50s/it]Epoch: 10, train loss: 1.67539, f_loss_w: 0.62135, f_loss_uw: 1.67539, data loss: 0.05630:  44% 11/25 [1:03:03<1:20:46, 346.18s/it]Epoch: 11, train loss: 1.55318, f_loss_w: 0.62453, f_loss_uw: 1.55318, data loss: 0.05059:  44% 11/25 [1:09:47<1:20:46, 346.18s/it]Epoch: 11, train loss: 1.55318, f_loss_w: 0.62453, f_loss_uw: 1.55318, data loss: 0.05059:  48% 12  64% 16/25 [1:00:32<32:48, 218.77s/it]Epoch: 16, train loss: 3.66549, f_loss_w: 0.00115, f_loss_uw: 3.66549, data loss: 0.14082:  64% 16/25 [1:02:59<32:48, 218.77s/it]Epoch: 16, train loss: 3.66549, f_loss_w: 0.00115, f_loss_uw: 3.66549, data loss: 0.14082:  68% 17/25 [1:02:59<28:00, 210.09s/it]Epoch: 17, train loss: 3.57713, f_loss_w: 0.00111, f_loss_uw: 3.57713, data loss: 0.13394:  68% 17/25 [1:05:15<28:00, 210.09s/it]Epoch: 17, train loss: 3.57713, f_loss_w: 0.00111, f_loss_uw: 3.57713, data loss: 0.13394:  72% 18/25 [1:05:15<23:29, 201.42s/it]Epoch: 18, train loss: 3.53675, f_loss_w: 0.00098, f_loss_uw: 3.53675, data loss: 0.12402:  72% 18/25 [1:07:52<23:29, 201.42s/it]Epoch: 18, train loss: 3.53675, f_loss_w: 0.00098, f_loss_uw: 3.53675, data loss: 0.12402:  76% 19/25 [1:07:52<19:37, 196.23s/it]Epoch: 19, train loss: 3.83285, f_loss_w: 0.00157, f_loss_uw: 3.83285, data loss: 0.13769:  76% 19/25 [1:10:12<19:37, 196.23s/it]Epoch: 19, train loss: 3.83285, f_loss_w: 0.00157, f_loss_uw: 3.83285, dat1431, data loss: 0.06366:  48% 12/25 [54:08<57:10, 263.86s/it]  Epoch: 12, train loss: 1.76099, f_loss_w: 66.72012, f_loss_uw: 1.76099, data loss: 0.05605:  48% 12/25 [58:25<57:10, 263.86s/it]Epoch: 12, train loss: 1.76099, f_loss_w: 66.72012, f_loss_uw: 1.76099, data loss: 0.05605:  52% 13/25 [58:25<52:34, 262.86s/it]Epoch: 13, train loss: 1.68911, f_loss_w: 52.67107, f_loss_uw: 1.68911, data loss: 0.05346:  52% 13/25 [1:03:01<52:34, 262.86s/it]Epoch: 13, train loss: 1.68911, f_loss_w: 52.67107, f_loss_uw: 1.68911, data loss: 0.05346:  56% 14/25 [1:03:01<48:31, 264.65s/it]Epoch: 14, train loss: 1.70483, f_loss_w: 37.51831, f_loss_uw: 1.70483, data loss: 0.05288:  56% 14/25 [1:06:58<48:31, 264.65s/it]Epoch: 14, train loss: 1.70483, f_loss_w: 37.51831, f_loss_uw: 1.70483, data loss: 0.05288:  60% 15/25 [1:06:58<43:31, 261.12s/it]Epoch: 15, train loss: 1.66999, f_loss_w: 29.15057, f_loss_uw: 1.66999, data loss: 0.04995:  60% 15/25 [1:11:03<43:31, 261.12s/it]Epoch: 15, train loss: 1.66999, f_loss_w: 29.1[54:56<30:31, 203.52s/it]Epoch: 16, train loss: 2.34893, f_loss_w: 0.00329, f_loss_uw: 2.34893, data loss: 0.08219:  64% 16/25 [59:08<30:31, 203.52s/it]Epoch: 16, train loss: 2.34893, f_loss_w: 0.00329, f_loss_uw: 2.34893, data loss: 0.08219:  68% 17/25 [59:08<27:54, 209.34s/it]Epoch: 17, train loss: 2.32580, f_loss_w: 0.00264, f_loss_uw: 2.32580, data loss: 0.07146:  68% 17/25 [1:03:49<27:54, 209.34s/it]Epoch: 17, train loss: 2.32580, f_loss_w: 0.00264, f_loss_uw: 2.32580, data loss: 0.07146:  72% 18/25 [1:03:49<25:23, 217.71s/it]Epoch: 18, train loss: 2.32153, f_loss_w: 0.00254, f_loss_uw: 2.32153, data loss: 0.07803:  72% 18/25 [1:08:03<25:23, 217.71s/it]Epoch: 18, train loss: 2.32153, f_loss_w: 0.00254, f_loss_uw: 2.32153, data loss: 0.07803:  76% 19/25 [1:08:03<22:11, 221.93s/it]Epoch: 19, train loss: 2.27004, f_loss_w: 0.00097, f_loss_uw: 2.27004, data loss: 0.07227:  76% 19/25 [1:11:22<22:11, 221.93s/it]Epoch: 19, train loss: 2.27004, f_loss_w: 0.00097, f_loss_uw: 2.27004, data loss: 0.07227:  25 [59:45<31:30, 210.06s/it]Epoch: 16, train loss: 2.76589, f_loss_w: 0.00487, f_loss_uw: 2.76589, data loss: 0.13752:  64% 16/25 [1:02:10<31:30, 210.06s/it]Epoch: 16, train loss: 2.76589, f_loss_w: 0.00487, f_loss_uw: 2.76589, data loss: 0.13752:  68% 17/25 [1:02:10<26:57, 202.18s/it]Epoch: 17, train loss: 2.20659, f_loss_w: 0.00349, f_loss_uw: 2.20659, data loss: 0.07341:  68% 17/25 [1:05:58<26:57, 202.18s/it]Epoch: 17, train loss: 2.20659, f_loss_w: 0.00349, f_loss_uw: 2.20659, data loss: 0.07341:  72% 18/25 [1:05:58<23:57, 205.30s/it]Epoch: 18, train loss: 2.27714, f_loss_w: 0.00212, f_loss_uw: 2.27714, data loss: 0.07046:  72% 18/25 [1:09:23<23:57, 205.30s/it]Epoch: 18, train loss: 2.27714, f_loss_w: 0.00212, f_loss_uw: 2.27714, data loss: 0.07046:  76% 19/25 [1:09:23<20:31, 205.24s/it]Epoch: 19, train loss: 2.24389, f_loss_w: 0.00153, f_loss_uw: 2.24389, data loss: 0.07625:  76% 19/25 [1:11:57<20:31, 205.24s/it]Epoch: 19, train loss: 2.24389, f_loss_w: 0.00153, f_loss_uw: 2.24389, data loss: 0.0 20/25 [59:03<14:03, 168.79s/it]Epoch: 20, train loss: 3.82584, f_loss_w: 0.00060, f_loss_uw: 3.82584, data loss: 0.14369:  80% 20/25 [1:03:16<14:03, 168.79s/it]Epoch: 20, train loss: 3.82584, f_loss_w: 0.00060, f_loss_uw: 3.82584, data loss: 0.14369:  84% 21/25 [1:03:16<11:52, 178.25s/it]Epoch: 21, train loss: 3.58629, f_loss_w: 0.00063, f_loss_uw: 3.58629, data loss: 0.12881:  84% 21/25 [1:06:43<11:52, 178.25s/it]Epoch: 21, train loss: 3.58629, f_loss_w: 0.00063, f_loss_uw: 3.58629, data loss: 0.12881:  88% 22/25 [1:06:43<09:04, 181.52s/it]Epoch: 22, train loss: 3.67868, f_loss_w: 0.00019, f_loss_uw: 3.67868, data loss: 0.11328:  88% 22/25 [1:10:08<09:04, 181.52s/it]Epoch: 22, train loss: 3.67868, f_loss_w: 0.00019, f_loss_uw: 3.67868, data loss: 0.11328:  92% 23/25 [1:10:08<06:08, 184.02s/it]Epoch: 23, train loss: 3.74508, f_loss_w: 0.00011, f_loss_uw: 3.74508, data loss: 0.11397:  92% 23/25 [1:13:21<06:08, 184.02s/it]Epoch: 23, train loss: 3.74508, f_loss_w: 0.00011, f_loss_uw: 3.74508, data loss:308.25s/it]Epoch: 12, train loss: 2.81805, f_loss_w: 0.02667, f_loss_uw: 2.81805, data loss: 0.07836:  48% 12/25 [1:03:20<1:06:47, 308.25s/it]Epoch: 12, train loss: 2.81805, f_loss_w: 0.02667, f_loss_uw: 2.81805, data loss: 0.07836:  52% 13/25 [1:03:20<1:01:05, 305.49s/it]Epoch: 13, train loss: 2.82832, f_loss_w: 0.01720, f_loss_uw: 2.82832, data loss: 0.08268:  52% 13/25 [1:07:46<1:01:05, 305.49s/it]Epoch: 13, train loss: 2.82832, f_loss_w: 0.01720, f_loss_uw: 2.82832, data loss: 0.08268:  56% 14/25 [1:07:46<55:03, 300.36s/it]  Epoch: 14, train loss: 2.86687, f_loss_w: 0.01544, f_loss_uw: 2.86687, data loss: 0.08199:  56% 14/25 [1:11:31<55:03, 300.36s/it]Epoch: 14, train loss: 2.86687, f_loss_w: 0.01544, f_loss_uw: 2.86687, data loss: 0.08199:  60% 15/25 [1:11:31<48:29, 290.92s/it]Epoch: 15, train loss: 2.79617, f_loss_w: 0.01127, f_loss_uw: 2.79617, data loss: 0.07591:  60% 15/25 [1:15:20<48:29, 290.92s/it]Epoch: 15, train loss: 2.79617, f_loss_w: 0.01127, f_loss_uw: 2.79617, data loss: 0.07591:  64]Epoch: 16, train loss: 5.01561, f_loss_w: 91493362.88000, f_loss_uw: 5.01561, data loss: 0.13762:  64% 16/25 [1:00:28<28:59, 193.30s/it]Epoch: 16, train loss: 5.01561, f_loss_w: 91493362.88000, f_loss_uw: 5.01561, data loss: 0.13762:  68% 17/25 [1:00:28<26:50, 201.35s/it]Epoch: 17, train loss: 4.63850, f_loss_w: 98986295.20000, f_loss_uw: 4.63850, data loss: 0.13135:  68% 17/25 [1:05:22<26:50, 201.35s/it]Epoch: 17, train loss: 4.63850, f_loss_w: 98986295.20000, f_loss_uw: 4.63850, data loss: 0.13135:  72% 18/25 [1:05:22<24:45, 212.23s/it]Epoch: 18, train loss: 4.33758, f_loss_w: 102104675.20000, f_loss_uw: 4.33758, data loss: 0.12561:  72% 18/25 [1:10:33<24:45, 212.23s/it]Epoch: 18, train loss: 4.33758, f_loss_w: 102104675.20000, f_loss_uw: 4.33758, data loss: 0.12561:  76% 19/25 [1:10:33<22:21, 223.58s/it]Epoch: 19, train loss: 4.04500, f_loss_w: 103198131.04000, f_loss_uw: 4.04500, data loss: 0.12017:  76% 19/25 [1:15:58<22:21, 223.58s/it]Epoch: 19, train loss: 4.04500, f_loss_w: 103198131.04000, f[1:02:18<1:04:32, 297.91s/it]Epoch: 12, train loss: 1.90278, f_loss_w: 0.00685, f_loss_uw: 1.90278, data loss: 0.06082:  48% 12/25 [1:05:34<1:04:32, 297.91s/it]Epoch: 12, train loss: 1.90278, f_loss_w: 0.00685, f_loss_uw: 1.90278, data loss: 0.06082:  52% 13/25 [1:05:34<56:51, 284.27s/it]  Epoch: 13, train loss: 1.77942, f_loss_w: 0.00729, f_loss_uw: 1.77942, data loss: 0.05468:  52% 13/25 [1:09:06<56:51, 284.27s/it]Epoch: 13, train loss: 1.77942, f_loss_w: 0.00729, f_loss_uw: 1.77942, data loss: 0.05468:  56% 14/25 [1:09:06<50:24, 274.96s/it]Epoch: 14, train loss: 2.21773, f_loss_w: 0.01738, f_loss_uw: 2.21773, data loss: 0.10903:  56% 14/25 [1:12:22<50:24, 274.96s/it]Epoch: 14, train loss: 2.21773, f_loss_w: 0.01738, f_loss_uw: 2.21773, data loss: 0.10903:  60% 15/25 [1:12:22<44:09, 264.97s/it]Epoch: 15, train loss: 1.72026, f_loss_w: 0.01014, f_loss_uw: 1.72026, data loss: 0.05422:  60% 15/25 [1:16:42<44:09, 264.97s/it]Epoch: 15, train loss: 1.72026, f_loss_w: 0.01014, f_loss_uw: 1.72026, data lossCheckpoint is saved at checkpoints//darcy-cpino-1.pt
Checkpoint is saved at checkpoints//darcy-cpino-1-weights.pt
 0.11397:  96% 24/25 [1:13:21<03:04, 184.99s/it]Epoch: 24, train loss: 3.49186, f_loss_w: 0.00011, f_loss_uw: 3.49186, data loss: 0.11170:  96% 24/25 [1:16:48<03:04, 184.99s/it]Epoch: 24, train loss: 3.49186, f_loss_w: 0.00011, f_loss_uw: 3.49186, data loss: 0.11170: 100% 25/25 [1:16:48<00:00, 187.46s/it]Epoch: 24, train loss: 3.49186, f_loss_w: 0.00011, f_loss_uw: 3.49186, data loss: 0.11170: 100% 25/25 [1:16:48<00:00, 184.36s/it]
wandb: Waiting for W&B process to finish, PID 7284... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss ▄▁▂▁▁▁▁▁▂▁▅▂▁▁▁▂█▂▁▁▁▁▁▁▁
wandb:            f loss ▂▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁█▂▂▁▁▁▁▁▁
wandb:   f loss weighted █▂▂▂▂▂▂▁▂▂▃▂▁▁▁▁▁▁▁▁▂▂▁▁▁
wandb:        train loss ▂▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁█▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.1117
wandb:            f loss 3.49186
wandb:   f loss weighted 0.00011
wandb:        train loss 3.49186
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced smooth-frost-195: https://wandb.ai/rishigundakaram/CPINO/runs/35a5mqrl
wandb: Find logs at: ./wandb/run-20220615_110424-35a5mqrl/logs/debug.log
wandb: 

Done!
 32% 8/25 [53:33<1:48:23, 382.55s/it]Epoch: 8, train loss: 1.64914, f_loss_w: 41.86779, f_loss_uw: 1.64914, data loss: 0.06846:  32% 8/25 [59:23<1:48:23, 382.55s/it]Epoch: 8, train loss: 1.64914, f_loss_w: 41.86779, f_loss_uw: 1.64914, data loss: 0.06846:  36% 9/25 [59:23<1:40:38, 377.38s/it]Epoch: 9, train loss: 1.49082, f_loss_w: 43.19522, f_loss_uw: 1.49082, data loss: 0.05932:  36% 9/25 [1:05:45<1:40:38, 377.38s/it]Epoch: 9, train loss: 1.49082, f_loss_w: 43.19522, f_loss_uw: 1.49082, data loss: 0.05932:  40% 10/25 [1:05:45<1:34:31, 378.08s/it]Epoch: 10, train loss: 1.37036, f_loss_w: 42.39061, f_loss_uw: 1.37036, data loss: 0.04987:  40% 10/25 [1:12:06<1:34:31, 378.08s/it]Epoch: 10, train loss: 1.37036, f_loss_w: 42.39061, f_loss_uw: 1.37036, data loss: 0.04987:  44% 11/25 [1:12:06<1:28:18, 378.43s/it]Epoch: 11, train loss: 1.29752, f_loss_w: 37.87233, f_loss_uw: 1.29752, data loss: 0.04539:  44% 11/25 [1:18:53<1:28:18, 378.43s/it]Epoch: 11, train loss: 1.29752, f_loss_w: 37.87233, f_loss_uw: 1.2, 173.62s/it]Epoch: 20, train loss: 2.58844, f_loss_w: 0.00482, f_loss_uw: 2.58844, data loss: 0.12798:  80% 20/25 [1:04:02<14:28, 173.62s/it]Epoch: 20, train loss: 2.58844, f_loss_w: 0.00482, f_loss_uw: 2.58844, data loss: 0.12798:  84% 21/25 [1:04:02<12:00, 180.14s/it]Epoch: 21, train loss: 2.65587, f_loss_w: 0.00204, f_loss_uw: 2.65587, data loss: 0.10471:  84% 21/25 [1:08:16<12:00, 180.14s/it]Epoch: 21, train loss: 2.65587, f_loss_w: 0.00204, f_loss_uw: 2.65587, data loss: 0.10471:  88% 22/25 [1:08:16<09:24, 188.27s/it]Epoch: 22, train loss: 2.32185, f_loss_w: 0.00208, f_loss_uw: 2.32185, data loss: 0.09198:  88% 22/25 [1:13:13<09:24, 188.27s/it]Epoch: 22, train loss: 2.32185, f_loss_w: 0.00208, f_loss_uw: 2.32185, data loss: 0.09198:  92% 23/25 [1:13:13<06:40, 200.26s/it]Epoch: 23, train loss: 2.17095, f_loss_w: 0.00208, f_loss_uw: 2.17095, data loss: 0.08182:  92% 23/25 [1:20:00<06:40, 200.26s/it]Epoch: 23, train loss: 2.17095, f_loss_w: 0.00208, f_loss_uw: 2.17095, data loss: 0.08182:  96% 24/2data loss: 0.07414:  80% 20/25 [1:08:09<15:24, 184.93s/it]Epoch: 20, train loss: 1.75104, f_loss_w: 1.55824, f_loss_uw: 1.75104, data loss: 0.07305:  80% 20/25 [1:11:04<15:24, 184.93s/it]Epoch: 20, train loss: 1.75104, f_loss_w: 1.55824, f_loss_uw: 1.75104, data loss: 0.07305:  84% 21/25 [1:11:04<12:15, 183.76s/it]Epoch: 21, train loss: 1.73481, f_loss_w: 1.61769, f_loss_uw: 1.73481, data loss: 0.07139:  84% 21/25 [1:13:59<12:15, 183.76s/it]Epoch: 21, train loss: 1.73481, f_loss_w: 1.61769, f_loss_uw: 1.73481, data loss: 0.07139:  88% 22/25 [1:13:59<09:08, 182.84s/it]Epoch: 22, train loss: 1.69358, f_loss_w: 1.55700, f_loss_uw: 1.69358, data loss: 0.06716:  88% 22/25 [1:17:29<09:08, 182.84s/it]Epoch: 22, train loss: 1.69358, f_loss_w: 1.55700, f_loss_uw: 1.69358, data loss: 0.06716:  92% 23/25 [1:17:29<06:11, 185.85s/it]Epoch: 23, train loss: 1.64744, f_loss_w: 1.45106, f_loss_uw: 1.64744, data loss: 0.06355:  92% 23/25 [1:20:51<06:11, 185.85s/it]Epoch: 23, train loss: 1.64744, f_loss_w: 1.45106, f_lo9:19<1:02:45, 289.69s/it]Epoch: 12, train loss: 1.60184, f_loss_w: 0.03641, f_loss_uw: 1.60184, data loss: 0.04708:  48% 12/25 [1:04:05<1:02:45, 289.69s/it]Epoch: 12, train loss: 1.60184, f_loss_w: 0.03641, f_loss_uw: 1.60184, data loss: 0.04708:  52% 13/25 [1:04:05<57:50, 289.23s/it]  Epoch: 13, train loss: 1.54901, f_loss_w: 0.03646, f_loss_uw: 1.54901, data loss: 0.04613:  52% 13/25 [1:09:30<57:50, 289.23s/it]Epoch: 13, train loss: 1.54901, f_loss_w: 0.03646, f_loss_uw: 1.54901, data loss: 0.04613:  56% 14/25 [1:09:30<53:53, 293.94s/it]Epoch: 14, train loss: 1.53057, f_loss_w: 0.03694, f_loss_uw: 1.53057, data loss: 0.04576:  56% 14/25 [1:15:12<53:53, 293.94s/it]Epoch: 14, train loss: 1.53057, f_loss_w: 0.03694, f_loss_uw: 1.53057, data loss: 0.04576:  60% 15/25 [1:15:12<49:58, 299.88s/it]Epoch: 15, train loss: 1.48409, f_loss_w: 0.03946, f_loss_uw: 1.48409, data loss: 0.04579:  60% 15/25 [1:21:03<49:58, 299.88s/it]Epoch: 15, train loss: 1.48409, f_loss_w: 0.03946, f_loss_uw: 1.48409, data loss: 0.Checkpoint is saved at checkpoints//darcy-cpino-23.pt
Checkpoint is saved at checkpoints//darcy-cpino-23-weights.pt
ss_uw: 1.64744, data loss: 0.06355:  96% 24/25 [1:20:51<03:07, 187.56s/it]Epoch: 24, train loss: 1.62563, f_loss_w: 1.39348, f_loss_uw: 1.62563, data loss: 0.06096:  96% 24/25 [1:24:36<03:07, 187.56s/it]Epoch: 24, train loss: 1.62563, f_loss_w: 1.39348, f_loss_uw: 1.62563, data loss: 0.06096: 100% 25/25 [1:24:36<00:00, 191.62s/it]Epoch: 24, train loss: 1.62563, f_loss_w: 1.39348, f_loss_uw: 1.62563, data loss: 0.06096: 100% 25/25 [1:24:36<00:00, 203.07s/it]
wandb: Waiting for W&B process to finish, PID 21692... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss █▇▄▄▄▃▃▃▂▂▂▂▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb:   f loss weighted ██▂▂▃▃▂▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss █▇▄▄▄▃▃▃▂▂▂▂▃▃▃▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.06096
wandb:            f loss 1.62563
wandb:   f loss weighted 1.39348
wandb:        train loss 1.62563
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced glad-pine-200: https://wandb.ai/rishigundakaram/CPINO/runs/2qvvc0xm
wandb: Find logs at: ./wandb/run-20220615_110424-2qvvc0xm/logs/debug.log
wandb: 

Done!
7625:  80% 20/25 [1:11:57<16:36, 199.37s/it]Epoch: 20, train loss: 2.17088, f_loss_w: 0.00136, f_loss_uw: 2.17088, data loss: 0.07670:  80% 20/25 [1:14:52<16:36, 199.37s/it]Epoch: 20, train loss: 2.17088, f_loss_w: 0.00136, f_loss_uw: 2.17088, data loss: 0.07670:  84% 21/25 [1:14:52<13:06, 196.63s/it]Epoch: 21, train loss: 2.06338, f_loss_w: 0.00187, f_loss_uw: 2.06338, data loss: 0.06783:  84% 21/25 [1:18:07<13:06, 196.63s/it]Epoch: 21, train loss: 2.06338, f_loss_w: 0.00187, f_loss_uw: 2.06338, data loss: 0.06783:  88% 22/25 [1:18:07<09:49, 196.46s/it]Epoch: 22, train loss: 2.03569, f_loss_w: 0.00213, f_loss_uw: 2.03569, data loss: 0.06977:  88% 22/25 [1:21:31<09:49, 196.46s/it]Epoch: 22, train loss: 2.03569, f_loss_w: 0.00213, f_loss_uw: 2.03569, data loss: 0.06977:  92% 23/25 [1:21:31<06:34, 197.29s/it]Epoch: 23, train loss: 1.95443, f_loss_w: 0.00181, f_loss_uw: 1.95443, data loss: 0.06015:  92% 23/25 [1:24:45<06:34, 197.29s/it]Epoch: 23, train loss: 1.95443, f_loss_w: 0.00181, f_loss_uw: 1.9544312/25 [52:00<58:10, 268.50s/it]Epoch: 12, train loss: 3.14940, f_loss_w: 0.01346, f_loss_uw: 3.14940, data loss: 0.10282:  48% 12/25 [58:08<58:10, 268.50s/it]Epoch: 12, train loss: 3.14940, f_loss_w: 0.01346, f_loss_uw: 3.14940, data loss: 0.10282:  52% 13/25 [58:08<56:21, 281.81s/it]Epoch: 13, train loss: 3.26380, f_loss_w: 0.00868, f_loss_uw: 3.26380, data loss: 0.09712:  52% 13/25 [1:04:05<56:21, 281.81s/it]Epoch: 13, train loss: 3.26380, f_loss_w: 0.00868, f_loss_uw: 3.26380, data loss: 0.09712:  56% 14/25 [1:04:05<53:27, 291.60s/it]/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/CGDs/cgd_utils.py:201: UserWarning: CG iter num: 397
  warnings.warn('CG iter num: %d' % (i + 1))
/home/rgundaka/miniconda3/envs/rishig/lib/python3.6/site-packages/CGDs/cgd_utils.py:201: UserWarning: CG iter num: 1641
  warnings.warn('CG iter num: %d' % (i + 1))
Checkpoint is saved at checkpoints//darcy-cpino-13.pt
Checkpoint is saved at checkpoints//darcy-cpino-13-weights.pt
5 [1:20:00<03:42, 222.65s/it]Epoch: 24, train loss: 2.27228, f_loss_w: 0.00174, f_loss_uw: 2.27228, data loss: 0.08568:  96% 24/25 [1:25:56<03:42, 222.65s/it]Epoch: 24, train loss: 2.27228, f_loss_w: 0.00174, f_loss_uw: 2.27228, data loss: 0.08568: 100% 25/25 [1:25:56<00:00, 237.09s/it]Epoch: 24, train loss: 2.27228, f_loss_w: 0.00174, f_loss_uw: 2.27228, data loss: 0.08568: 100% 25/25 [1:25:56<00:00, 206.27s/it]
wandb: Waiting for W&B process to finish, PID 23648... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss ▇▃▂▃▂▁▁▄▂▁▁▁▁▁▁█▄█▃▃▂▂▁▁▁
wandb:            f loss ▃▁▃▃▃▂▁▃▃▃▂▁▁▁▁█▄█▁▃▅▅▃▂▃
wandb:   f loss weighted █▅▄▂▂▁▁▁▂▁▁▁▁▁▁▂▁▃▂▃▂▁▁▁▁
wandb:        train loss ▃▁▃▃▃▂▁▃▃▃▂▁▁▁▁█▄█▁▃▅▅▃▂▃
wandb: 
wandb: Run summary:
wandb:         data loss 0.08568
wandb:            f loss 2.27228
wandb:   f loss weighted 0.00174
wandb:        train loss 2.27228
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced usual-wind-193: https://wandb.ai/rishigundakaram/CPINO/runs/3f2m2kz2
wandb: Find logs at: ./wandb/run-20220615_110423-3f2m2kz2/logs/debug.log
wandb: 

Done!
Checkpoint is saved at checkpoints//darcy-cpino-12.pt
Checkpoint is saved at checkpoints//darcy-cpino-12-weights.pt
, data loss: 0.06015:  96% 24/25 [1:24:45<03:16, 196.92s/it]Epoch: 24, train loss: 2.10806, f_loss_w: 0.00100, f_loss_uw: 2.10806, data loss: 0.09743:  96% 24/25 [1:26:39<03:16, 196.92s/it]Epoch: 24, train loss: 2.10806, f_loss_w: 0.00100, f_loss_uw: 2.10806, data loss: 0.09743: 100% 25/25 [1:26:39<00:00, 188.02s/it]Epoch: 24, train loss: 2.10806, f_loss_w: 0.00100, f_loss_uw: 2.10806, data loss: 0.09743: 100% 25/25 [1:26:39<00:00, 207.98s/it]
wandb: Waiting for W&B process to finish, PID 18529... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▄▄▄▄▃▃▂▂▂▂▁▂▁▂▁▃▁▁▁▁▁▁▁▂
wandb:            f loss ▇▃▃▄▇▅█▅▆▅▅▄▅▄▄▄▇▃▃▃▃▂▂▁▂
wandb:   f loss weighted ▁▆▅▆▅▆█▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:        train loss ▇▃▃▄▇▅█▅▆▅▅▄▅▄▄▄▇▃▃▃▃▂▂▁▂
wandb: 
wandb: Run summary:
wandb:         data loss 0.09743
wandb:            f loss 2.10806
wandb:   f loss weighted 0.001
wandb:        train loss 2.10806
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced tough-star-197: https://wandb.ai/rishigundakaram/CPINO/runs/34dscilq
wandb: Find logs at: ./wandb/run-20220615_110424-34dscilq/logs/debug.log
wandb: 

Done!
1, train loss: 1.64413, f_loss_w: 16822.50334, f_loss_uw: 1.64413, data loss: 0.06605:  48% 12/25 [1:06:01<1:08:01, 313.99s/it]Epoch: 12, train loss: 1.59111, f_loss_w: 15234.37221, f_loss_uw: 1.59111, data loss: 0.06199:  48% 12/25 [1:11:34<1:08:01, 313.99s/it]Epoch: 12, train loss: 1.59111, f_loss_w: 15234.37221, f_loss_uw: 1.59111, data loss: 0.06199:  52% 13/25 [1:11:34<1:03:18, 316.55s/it]Epoch: 13, train loss: 1.53836, f_loss_w: 14802.18762, f_loss_uw: 1.53836, data loss: 0.05929:  52% 13/25 [1:17:08<1:03:18, 316.55s/it]Epoch: 13, train loss: 1.53836, f_loss_w: 14802.18762, f_loss_uw: 1.53836, data loss: 0.05929:  56% 14/25 [1:17:08<58:26, 318.75s/it]  Epoch: 14, train loss: 1.48260, f_loss_w: 14603.93910, f_loss_uw: 1.48260, data loss: 0.05661:  56% 14/25 [1:22:25<58:26, 318.75s/it]Epoch: 14, train loss: 1.48260, f_loss_w: 14603.93910, f_loss_uw: 1.48260, data loss: 0.05661:  60% 15/25 [1:22:25<53:05, 318.59s/it]Epoch: 15, train loss: 1.46669, f_loss_w: 12724.27316, f_loss_uw: 1.46669, data loss80% 20/25 [1:11:22<18:16, 219.32s/it]Epoch: 20, train loss: 2.10248, f_loss_w: 0.00166, f_loss_uw: 2.10248, data loss: 0.06234:  80% 20/25 [1:16:34<18:16, 219.32s/it]Epoch: 20, train loss: 2.10248, f_loss_w: 0.00166, f_loss_uw: 2.10248, data loss: 0.06234:  84% 21/25 [1:16:34<15:19, 229.75s/it]Epoch: 21, train loss: 2.15526, f_loss_w: 0.00181, f_loss_uw: 2.15526, data loss: 0.07874:  84% 21/25 [1:20:31<15:19, 229.75s/it]Epoch: 21, train loss: 2.15526, f_loss_w: 0.00181, f_loss_uw: 2.15526, data loss: 0.07874:  88% 22/25 [1:20:31<11:31, 230.54s/it]Epoch: 22, train loss: 2.21583, f_loss_w: 0.00075, f_loss_uw: 2.21583, data loss: 0.06540:  88% 22/25 [1:23:27<11:31, 230.54s/it]Epoch: 22, train loss: 2.21583, f_loss_w: 0.00075, f_loss_uw: 2.21583, data loss: 0.06540:  92% 23/25 [1:23:27<07:29, 224.55s/it]Epoch: 23, train loss: 2.08053, f_loss_w: 0.00121, f_loss_uw: 2.08053, data loss: 0.05614:  92% 23/25 [1:27:48<07:29, 224.55s/it]Epoch: 23, train loss: 2.08053, f_loss_w: 0.00121, f_loss_uw: 2.08053, data 5057, f_loss_uw: 1.66999, data loss: 0.04995:  64% 16/25 [1:11:03<38:52, 259.13s/it]Epoch: 16, train loss: 1.60668, f_loss_w: 28.66020, f_loss_uw: 1.60668, data loss: 0.04766:  64% 16/25 [1:14:51<38:52, 259.13s/it]Epoch: 16, train loss: 1.60668, f_loss_w: 28.66020, f_loss_uw: 1.60668, data loss: 0.04766:  68% 17/25 [1:14:51<34:03, 255.47s/it]Epoch: 17, train loss: 1.52593, f_loss_w: 27.83322, f_loss_uw: 1.52593, data loss: 0.04534:  68% 17/25 [1:19:20<34:03, 255.47s/it]Epoch: 17, train loss: 1.52593, f_loss_w: 27.83322, f_loss_uw: 1.52593, data loss: 0.04534:  72% 18/25 [1:19:20<29:59, 257.01s/it]Epoch: 18, train loss: 1.47962, f_loss_w: 27.30774, f_loss_uw: 1.47962, data loss: 0.04529:  72% 18/25 [1:23:39<29:59, 257.01s/it]Epoch: 18, train loss: 1.47962, f_loss_w: 27.30774, f_loss_uw: 1.47962, data loss: 0.04529:  76% 19/25 [1:23:39<25:43, 257.28s/it]Epoch: 19, train loss: 1.42158, f_loss_w: 27.88571, f_loss_uw: 1.42158, data loss: 0.04298:  76% 19/25 [1:28:14<25:43, 257.28s/it]Epoch: 19, train loss:% 16/25 [1:15:20<42:29, 283.33s/it]Epoch: 16, train loss: 2.68719, f_loss_w: 0.01264, f_loss_uw: 2.68719, data loss: 0.06982:  64% 16/25 [1:19:13<42:29, 283.33s/it]Epoch: 16, train loss: 2.68719, f_loss_w: 0.01264, f_loss_uw: 2.68719, data loss: 0.06982:  68% 17/25 [1:19:13<36:58, 277.32s/it]Epoch: 17, train loss: 2.64773, f_loss_w: 0.01265, f_loss_uw: 2.64773, data loss: 0.06801:  68% 17/25 [1:22:51<36:58, 277.32s/it]Epoch: 17, train loss: 2.64773, f_loss_w: 0.01265, f_loss_uw: 2.64773, data loss: 0.06801:  72% 18/25 [1:22:51<31:31, 270.26s/it]Epoch: 18, train loss: 2.59131, f_loss_w: 0.01281, f_loss_uw: 2.59131, data loss: 0.06607:  72% 18/25 [1:26:45<31:31, 270.26s/it]Epoch: 18, train loss: 2.59131, f_loss_w: 0.01281, f_loss_uw: 2.59131, data loss: 0.06607:  76% 19/25 [1:26:45<26:36, 266.16s/it]Epoch: 19, train loss: 2.57625, f_loss_w: 0.01041, f_loss_uw: 2.57625, data loss: 0.06445:  76% 19/25 [1:30:33<26:36, 266.16s/it]Epoch: 19, train loss: 2.57625, f_loss_w: 0.01041, f_loss_uw: 2.57625, data loCheckpoint is saved at checkpoints//darcy-cpino-6.pt
Checkpoint is saved at checkpoints//darcy-cpino-6-weights.pt
loss: 0.05614:  96% 24/25 [1:27:48<03:48, 228.52s/it]Epoch: 24, train loss: 2.12130, f_loss_w: 0.00128, f_loss_uw: 2.12130, data loss: 0.06456:  96% 24/25 [1:31:51<03:48, 228.52s/it]Epoch: 24, train loss: 2.12130, f_loss_w: 0.00128, f_loss_uw: 2.12130, data loss: 0.06456: 100% 25/25 [1:31:51<00:00, 230.10s/it]Epoch: 24, train loss: 2.12130, f_loss_w: 0.00128, f_loss_uw: 2.12130, data loss: 0.06456: 100% 25/25 [1:31:51<00:00, 220.47s/it]
wandb: Waiting for W&B process to finish, PID 11145... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss ▅▄▃█▄▃▃▂▂▃▂▃▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:            f loss ▁▃▁█▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   f loss weighted █▆▄▁▃▃▃▃▃▃▂▂▃▃▃▃▃▃▃▂▂▂▂▂▂
wandb:        train loss ▁▃▁█▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.06456
wandb:            f loss 2.1213
wandb:   f loss weighted 0.00128
wandb:        train loss 2.1213
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced daily-music-203: https://wandb.ai/rishigundakaram/CPINO/runs/2n88fw1a
wandb: Find logs at: ./wandb/run-20220615_110424-2n88fw1a/logs/debug.log
wandb: 

Done!
/25 [1:08:05<1:13:34, 339.54s/it]Epoch: 12, train loss: 1.49048, f_loss_w: 0.01656, f_loss_uw: 1.49048, data loss: 0.04123:  48% 12/25 [1:14:46<1:13:34, 339.54s/it]Epoch: 12, train loss: 1.49048, f_loss_w: 0.01656, f_loss_uw: 1.49048, data loss: 0.04123:  52% 13/25 [1:14:46<1:09:34, 347.83s/it]Epoch: 13, train loss: 1.45644, f_loss_w: 0.01721, f_loss_uw: 1.45644, data loss: 0.04055:  52% 13/25 [1:21:05<1:09:34, 347.83s/it]Epoch: 13, train loss: 1.45644, f_loss_w: 0.01721, f_loss_uw: 1.45644, data loss: 0.04055:  56% 14/25 [1:21:05<1:04:29, 351.79s/it]Epoch: 14, train loss: 1.43528, f_loss_w: 0.01634, f_loss_uw: 1.43528, data loss: 0.04053:  56% 14/25 [1:26:29<1:04:29, 351.79s/it]Epoch: 14, train loss: 1.43528, f_loss_w: 0.01634, f_loss_uw: 1.43528, data loss: 0.04053:  60% 15/25 [1:26:29<58:03, 348.39s/it]  Epoch: 15, train loss: 1.40016, f_loss_w: 0.01577, f_loss_uw: 1.40016, data loss: 0.03934:  60% 15/25 [1:32:56<58:03, 348.39s/it]Epoch: 15, train loss: 1.40016, f_loss_w: 0.01577, f_loss_uw: 1.4001: 0.05422:  64% 16/25 [1:16:42<39:39, 264.35s/it]Epoch: 16, train loss: 1.63220, f_loss_w: 0.00989, f_loss_uw: 1.63220, data loss: 0.04770:  64% 16/25 [1:20:50<39:39, 264.35s/it]Epoch: 16, train loss: 1.63220, f_loss_w: 0.00989, f_loss_uw: 1.63220, data loss: 0.04770:  68% 17/25 [1:20:50<34:59, 262.39s/it]Epoch: 17, train loss: 1.54622, f_loss_w: 0.01119, f_loss_uw: 1.54622, data loss: 0.04624:  68% 17/25 [1:25:26<34:59, 262.39s/it]Epoch: 17, train loss: 1.54622, f_loss_w: 0.01119, f_loss_uw: 1.54622, data loss: 0.04624:  72% 18/25 [1:25:26<30:48, 264.00s/it]Epoch: 18, train loss: 1.55487, f_loss_w: 0.01170, f_loss_uw: 1.55487, data loss: 0.04857:  72% 18/25 [1:29:52<30:48, 264.00s/it]Epoch: 18, train loss: 1.55487, f_loss_w: 0.01170, f_loss_uw: 1.55487, data loss: 0.04857:  76% 19/25 [1:29:52<26:25, 264.21s/it]Epoch: 19, train loss: 1.49987, f_loss_w: 0.01286, f_loss_uw: 1.49987, data loss: 0.05201:  76% 19/25 [1:34:40<26:25, 264.21s/it]Epoch: 19, train loss: 1.49987, f_loss_w: 0.01286, f_loss_uw: 1./25 [1:09:47<1:16:45, 354.24s/it]Epoch: 12, train loss: 1.48764, f_loss_w: 0.60144, f_loss_uw: 1.48764, data loss: 0.04482:  48% 12/25 [1:16:04<1:16:45, 354.24s/it]Epoch: 12, train loss: 1.48764, f_loss_w: 0.60144, f_loss_uw: 1.48764, data loss: 0.04482:  52% 13/25 [1:16:04<1:11:26, 357.22s/it]Epoch: 13, train loss: 1.45235, f_loss_w: 0.59397, f_loss_uw: 1.45235, data loss: 0.04330:  52% 13/25 [1:22:24<1:11:26, 357.22s/it]Epoch: 13, train loss: 1.45235, f_loss_w: 0.59397, f_loss_uw: 1.45235, data loss: 0.04330:  56% 14/25 [1:22:24<1:06:02, 360.25s/it]Epoch: 14, train loss: 1.42230, f_loss_w: 0.59867, f_loss_uw: 1.42230, data loss: 0.04148:  56% 14/25 [1:28:22<1:06:02, 360.25s/it]Epoch: 14, train loss: 1.42230, f_loss_w: 0.59867, f_loss_uw: 1.42230, data loss: 0.04148:  60% 15/25 [1:28:22<59:58, 359.88s/it]  Epoch: 15, train loss: 1.37858, f_loss_w: 0.62079, f_loss_uw: 1.37858, data loss: 0.03917:  60% 15/25 [1:35:07<59:58, 359.88s/it]Epoch: 15, train loss: 1.37858, f_loss_w: 0.62079, f_loss_uw: 1.3785_loss_uw: 4.04500, data loss: 0.12017:  80% 20/25 [1:15:58<19:35, 235.18s/it]Epoch: 20, train loss: 3.73297, f_loss_w: 105727798.88000, f_loss_uw: 3.73297, data loss: 0.11526:  80% 20/25 [1:21:29<19:35, 235.18s/it]Epoch: 20, train loss: 3.73297, f_loss_w: 105727798.88000, f_loss_uw: 3.73297, data loss: 0.11526:  84% 21/25 [1:21:29<16:23, 245.97s/it]Epoch: 21, train loss: 3.43630, f_loss_w: 105872092.80000, f_loss_uw: 3.43630, data loss: 0.11218:  84% 21/25 [1:27:22<16:23, 245.97s/it]Epoch: 21, train loss: 3.43630, f_loss_w: 105872092.80000, f_loss_uw: 3.43630, data loss: 0.11218:  88% 22/25 [1:27:22<12:53, 257.84s/it]Epoch: 22, train loss: 3.17931, f_loss_w: 103238237.92000, f_loss_uw: 3.17931, data loss: 0.10717:  88% 22/25 [1:33:23<12:53, 257.84s/it]Epoch: 22, train loss: 3.17931, f_loss_w: 103238237.92000, f_loss_uw: 3.17931, data loss: 0.10717:  92% 23/25 [1:33:23<08:58, 269.12s/it]Epoch: 23, train loss: 2.94152, f_loss_w: 100741544.48000, f_loss_uw: 2.94152, data loss: 0.10433:  92% 23/25 [1:39:48ss: 0.06445:  80% 20/25 [1:30:33<21:48, 261.76s/it]Epoch: 20, train loss: 2.57346, f_loss_w: 0.00990, f_loss_uw: 2.57346, data loss: 0.06452:  80% 20/25 [1:33:58<21:48, 261.76s/it]Epoch: 20, train loss: 2.57346, f_loss_w: 0.00990, f_loss_uw: 2.57346, data loss: 0.06452:  84% 21/25 [1:33:58<17:01, 255.40s/it]Epoch: 21, train loss: 2.49782, f_loss_w: 0.00908, f_loss_uw: 2.49782, data loss: 0.06241:  84% 21/25 [1:37:43<17:01, 255.40s/it]Epoch: 21, train loss: 2.49782, f_loss_w: 0.00908, f_loss_uw: 2.49782, data loss: 0.06241:  88% 22/25 [1:37:43<12:35, 251.97s/it]Epoch: 22, train loss: 2.39851, f_loss_w: 0.00937, f_loss_uw: 2.39851, data loss: 0.05960:  88% 22/25 [1:41:47<12:35, 251.97s/it]Epoch: 22, train loss: 2.39851, f_loss_w: 0.00937, f_loss_uw: 2.39851, data loss: 0.05960:  92% 23/25 [1:41:47<08:22, 251.20s/it]Epoch: 23, train loss: 2.35044, f_loss_w: 0.00895, f_loss_uw: 2.35044, data loss: 0.06003:  92% 23/25 [1:45:25<08:22, 251.20s/it]Epoch: 23, train loss: 2.35044, f_loss_w: 0.00895, f_loss_uw: 04579:  64% 16/25 [1:21:03<45:55, 306.15s/it]Epoch: 16, train loss: 1.45126, f_loss_w: 0.04336, f_loss_uw: 1.45126, data loss: 0.04556:  64% 16/25 [1:27:03<45:55, 306.15s/it]Epoch: 16, train loss: 1.45126, f_loss_w: 0.04336, f_loss_uw: 1.45126, data loss: 0.04556:  68% 17/25 [1:27:03<41:41, 312.65s/it]Epoch: 17, train loss: 1.42380, f_loss_w: 0.04588, f_loss_uw: 1.42380, data loss: 0.04536:  68% 17/25 [1:33:46<41:41, 312.65s/it]Epoch: 17, train loss: 1.42380, f_loss_w: 0.04588, f_loss_uw: 1.42380, data loss: 0.04536:  72% 18/25 [1:33:46<37:42, 323.24s/it]Epoch: 18, train loss: 1.41400, f_loss_w: 0.04820, f_loss_uw: 1.41400, data loss: 0.04665:  72% 18/25 [1:39:20<37:42, 323.24s/it]Epoch: 18, train loss: 1.41400, f_loss_w: 0.04820, f_loss_uw: 1.41400, data loss: 0.04665:  76% 19/25 [1:39:20<32:27, 324.50s/it]Epoch: 19, train loss: 1.37723, f_loss_w: 0.04949, f_loss_uw: 1.37723, data loss: 0.04581:  76% 19/25 [1:45:49<32:27, 324.50s/it]Epoch: 19, train loss: 1.37723, f_loss_w: 0.04949, f_loss_uw: 1.3772Checkpoint is saved at checkpoints//darcy-cpino-20.pt
Checkpoint is saved at checkpoints//darcy-cpino-20-weights.pt
<08:58, 269.12s/it]Epoch: 23, train loss: 2.94152, f_loss_w: 100741544.48000, f_loss_uw: 2.94152, data loss: 0.10433:  96% 24/25 [1:39:48<04:41, 281.76s/it]Epoch: 24, train loss: 2.73022, f_loss_w: 101710188.16000, f_loss_uw: 2.73022, data loss: 0.10099:  96% 24/25 [1:46:17<04:41, 281.76s/it]Epoch: 24, train loss: 2.73022, f_loss_w: 101710188.16000, f_loss_uw: 2.73022, data loss: 0.10099: 100% 25/25 [1:46:17<00:00, 293.28s/it]Epoch: 24, train loss: 2.73022, f_loss_w: 101710188.16000, f_loss_uw: 2.73022, data loss: 0.10099: 100% 25/25 [1:46:17<00:00, 255.11s/it]
wandb: Waiting for W&B process to finish, PID 25905... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss ▄█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss ▁█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   f loss weighted ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▁█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.10099
wandb:            f loss 2.73022
wandb:   f loss weighted 101710188.16
wandb:        train loss 2.73022
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced blooming-microwave-190: https://wandb.ai/rishigundakaram/CPINO/runs/709ifv8o
wandb: Find logs at: ./wandb/run-20220615_110423-709ifv8o/logs/debug.log
wandb: 

Done!
 1.42158, f_loss_w: 27.88571, f_loss_uw: 1.42158, data loss: 0.04298:  80% 20/25 [1:28:14<21:36, 259.25s/it]Epoch: 20, train loss: 1.37982, f_loss_w: 28.53896, f_loss_uw: 1.37982, data loss: 0.04261:  80% 20/25 [1:32:39<21:36, 259.25s/it]Epoch: 20, train loss: 1.37982, f_loss_w: 28.53896, f_loss_uw: 1.37982, data loss: 0.04261:  84% 21/25 [1:32:39<17:19, 259.94s/it]Epoch: 21, train loss: 1.32795, f_loss_w: 27.93104, f_loss_uw: 1.32795, data loss: 0.04170:  84% 21/25 [1:37:31<17:19, 259.94s/it]Epoch: 21, train loss: 1.32795, f_loss_w: 27.93104, f_loss_uw: 1.32795, data loss: 0.04170:  88% 22/25 [1:37:31<13:10, 263.47s/it]Epoch: 22, train loss: 1.28571, f_loss_w: 29.33297, f_loss_uw: 1.28571, data loss: 0.04017:  88% 22/25 [1:42:28<13:10, 263.47s/it]Epoch: 22, train loss: 1.28571, f_loss_w: 29.33297, f_loss_uw: 1.28571, data loss: 0.04017:  92% 23/25 [1:42:28<08:54, 267.09s/it]Epoch: 23, train loss: 1.28306, f_loss_w: 28.94232, f_loss_uw: 1.28306, data loss: 0.04180:  92% 23/25 [1:47:21<08:54, 267.09s/itCheckpoint is saved at checkpoints//darcy-cpino-24.pt
Checkpoint is saved at checkpoints//darcy-cpino-24-weights.pt
2.35044, data loss: 0.06003:  96% 24/25 [1:45:25<04:07, 247.49s/it]Epoch: 24, train loss: 2.33082, f_loss_w: 0.00839, f_loss_uw: 2.33082, data loss: 0.06041:  96% 24/25 [1:48:53<04:07, 247.49s/it]Epoch: 24, train loss: 2.33082, f_loss_w: 0.00839, f_loss_uw: 2.33082, data loss: 0.06041: 100% 25/25 [1:48:53<00:00, 243.33s/it]Epoch: 24, train loss: 2.33082, f_loss_w: 0.00839, f_loss_uw: 2.33082, data loss: 0.06041: 100% 25/25 [1:48:53<00:00, 261.36s/it]
wandb: Waiting for W&B process to finish, PID 22900... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss █▄▇▂▁▂▃▃▃▃▃▃▄▄▄▄▃▃▃▃▃▂▂▂▂
wandb:   f loss weighted ▇█▄▂▄▄▄▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss █▄▇▂▁▂▃▃▃▃▃▃▄▄▄▄▃▃▃▃▃▂▂▂▂
wandb: 
wandb: Run summary:
wandb:         data loss 0.06041
wandb:            f loss 2.33082
wandb:   f loss weighted 0.00839
wandb:        train loss 2.33082
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced ethereal-feather-210: https://wandb.ai/rishigundakaram/CPINO/runs/chg5pnpo
wandb: Find logs at: ./wandb/run-20220615_110441-chg5pnpo/logs/debug.log
wandb: 

Done!
9752, data loss: 0.04539:  48% 12/25 [1:18:53<1:22:51, 382.42s/it]Epoch: 12, train loss: 1.24946, f_loss_w: 39.77449, f_loss_uw: 1.24946, data loss: 0.04234:  48% 12/25 [1:25:40<1:22:51, 382.42s/it]Epoch: 12, train loss: 1.24946, f_loss_w: 39.77449, f_loss_uw: 1.24946, data loss: 0.04234:  52% 13/25 [1:25:40<1:17:08, 385.67s/it]Epoch: 13, train loss: 1.21103, f_loss_w: 42.67922, f_loss_uw: 1.21103, data loss: 0.04096:  52% 13/25 [1:32:56<1:17:08, 385.67s/it]Epoch: 13, train loss: 1.21103, f_loss_w: 42.67922, f_loss_uw: 1.21103, data loss: 0.04096:  56% 14/25 [1:32:56<1:11:54, 392.26s/it]Epoch: 14, train loss: 1.18013, f_loss_w: 44.20295, f_loss_uw: 1.18013, data loss: 0.03911:  56% 14/25 [1:41:05<1:11:54, 392.26s/it]Epoch: 14, train loss: 1.18013, f_loss_w: 44.20295, f_loss_uw: 1.18013, data loss: 0.03911:  60% 15/25 [1:41:05<1:07:23, 404.39s/it]Epoch: 15, train loss: 1.14392, f_loss_w: 43.59578, f_loss_uw: 1.14392, data loss: 0.03771:  60% 15/25 [1:50:10<1:07:23, 404.39s/it]Epoch: 15, train loss: 1.1: 0.05390:  60% 15/25 [1:27:35<53:05, 318.59s/it]Epoch: 15, train loss: 1.46669, f_loss_w: 12724.27316, f_loss_uw: 1.46669, data loss: 0.05390:  64% 16/25 [1:27:35<47:36, 317.43s/it]Epoch: 16, train loss: 1.40107, f_loss_w: 12559.47326, f_loss_uw: 1.40107, data loss: 0.04921:  64% 16/25 [1:33:08<47:36, 317.43s/it]Epoch: 16, train loss: 1.40107, f_loss_w: 12559.47326, f_loss_uw: 1.40107, data loss: 0.04921:  68% 17/25 [1:33:08<42:35, 319.40s/it]Epoch: 17, train loss: 1.36774, f_loss_w: 12213.75428, f_loss_uw: 1.36774, data loss: 0.04733:  68% 17/25 [1:38:27<42:35, 319.40s/it]Epoch: 17, train loss: 1.36774, f_loss_w: 12213.75428, f_loss_uw: 1.36774, data loss: 0.04733:  72% 18/25 [1:38:27<37:14, 319.25s/it]Epoch: 18, train loss: 1.33195, f_loss_w: 11742.59170, f_loss_uw: 1.33195, data loss: 0.04359:  72% 18/25 [1:44:22<37:14, 319.25s/it]Epoch: 18, train loss: 1.33195, f_loss_w: 11742.59170, f_loss_uw: 1.33195, data loss: 0.04359:  76% 19/25 [1:44:22<32:20, 323.44s/it]Epoch: 19, train loss: 1.29822, f_lo49987, data loss: 0.05201:  80% 20/25 [1:34:40<22:14, 266.90s/it]Epoch: 20, train loss: 1.50848, f_loss_w: 0.01438, f_loss_uw: 1.50848, data loss: 0.05340:  80% 20/25 [1:39:12<22:14, 266.90s/it]Epoch: 20, train loss: 1.50848, f_loss_w: 0.01438, f_loss_uw: 1.50848, data loss: 0.05340:  84% 21/25 [1:39:12<17:49, 267.45s/it]Epoch: 21, train loss: 1.93657, f_loss_w: 0.01575, f_loss_uw: 1.93657, data loss: 0.07824:  84% 21/25 [1:42:47<17:49, 267.45s/it]Epoch: 21, train loss: 1.93657, f_loss_w: 0.01575, f_loss_uw: 1.93657, data loss: 0.07824:  88% 22/25 [1:42:47<13:05, 261.70s/it]Epoch: 22, train loss: 1.77375, f_loss_w: 0.01417, f_loss_uw: 1.77375, data loss: 0.06339:  88% 22/25 [1:46:18<13:05, 261.70s/it]Epoch: 22, train loss: 1.77375, f_loss_w: 0.01417, f_loss_uw: 1.77375, data loss: 0.06339:  92% 23/25 [1:46:18<08:32, 256.10s/it]Epoch: 23, train loss: 1.40470, f_loss_w: 0.01505, f_loss_uw: 1.40470, data loss: 0.04462:  92% 23/25 [1:50:47<08:32, 256.10s/it]Epoch: 23, train loss: 1.40470, f_loss_w: 0.0150Checkpoint is saved at checkpoints//darcy-cpino-22.pt
Checkpoint is saved at checkpoints//darcy-cpino-22-weights.pt
]Epoch: 23, train loss: 1.28306, f_loss_w: 28.94232, f_loss_uw: 1.28306, data loss: 0.04180:  96% 24/25 [1:47:21<04:29, 269.92s/it]Epoch: 24, train loss: 1.24768, f_loss_w: 32.70139, f_loss_uw: 1.24768, data loss: 0.04013:  96% 24/25 [1:51:46<04:29, 269.92s/it]Epoch: 24, train loss: 1.24768, f_loss_w: 32.70139, f_loss_uw: 1.24768, data loss: 0.04013: 100% 25/25 [1:51:46<00:00, 269.46s/it]Epoch: 24, train loss: 1.24768, f_loss_w: 32.70139, f_loss_uw: 1.24768, data loss: 0.04013: 100% 25/25 [1:51:46<00:00, 268.27s/it]
wandb: Waiting for W&B process to finish, PID 18090... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss █▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb:   f loss weighted ▇▅█▇▅▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss █▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.04013
wandb:            f loss 1.24768
wandb:   f loss weighted 32.70139
wandb:        train loss 1.24768
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced balmy-hill-194: https://wandb.ai/rishigundakaram/CPINO/runs/3k1b39hb
wandb: Find logs at: ./wandb/run-20220615_110424-3k1b39hb/logs/debug.log
wandb: 

Done!
Checkpoint is saved at checkpoints//darcy-cpino-11.pt
Checkpoint is saved at checkpoints//darcy-cpino-11-weights.pt
5, f_loss_uw: 1.40470, data loss: 0.04462:  96% 24/25 [1:50:47<04:17, 257.56s/it]Epoch: 24, train loss: 1.49714, f_loss_w: 0.01426, f_loss_uw: 1.49714, data loss: 0.05511:  96% 24/25 [1:54:55<04:17, 257.56s/it]Epoch: 24, train loss: 1.49714, f_loss_w: 0.01426, f_loss_uw: 1.49714, data loss: 0.05511: 100% 25/25 [1:54:55<00:00, 256.53s/it]Epoch: 24, train loss: 1.49714, f_loss_w: 0.01426, f_loss_uw: 1.49714, data loss: 0.05511: 100% 25/25 [1:54:55<00:00, 275.84s/it]
wandb: Waiting for W&B process to finish, PID 16185... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▃▃▄▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁
wandb:            f loss ▄▂▂█▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▂▁▁▁
wandb:   f loss weighted ▇█▃▅▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▄▂▂█▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.05511
wandb:            f loss 1.49714
wandb:   f loss weighted 0.01426
wandb:        train loss 1.49714
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced bumbling-morning-196: https://wandb.ai/rishigundakaram/CPINO/runs/22googc6
wandb: Find logs at: ./wandb/run-20220615_110424-22googc6/logs/debug.log
wandb: 

Done!
6, data loss: 0.03934:  64% 16/25 [1:32:56<52:57, 353.03s/it]Epoch: 16, train loss: 1.35650, f_loss_w: 0.01672, f_loss_uw: 1.35650, data loss: 0.03657:  64% 16/25 [1:39:49<52:57, 353.03s/it]Epoch: 16, train loss: 1.35650, f_loss_w: 0.01672, f_loss_uw: 1.35650, data loss: 0.03657:  68% 17/25 [1:39:49<48:01, 360.24s/it]Epoch: 17, train loss: 1.34041, f_loss_w: 0.01737, f_loss_uw: 1.34041, data loss: 0.03620:  68% 17/25 [1:46:31<48:01, 360.24s/it]Epoch: 17, train loss: 1.34041, f_loss_w: 0.01737, f_loss_uw: 1.34041, data loss: 0.03620:  72% 18/25 [1:46:31<42:36, 365.21s/it]Epoch: 18, train loss: 1.32580, f_loss_w: 0.01827, f_loss_uw: 1.32580, data loss: 0.03631:  72% 18/25 [1:53:29<42:36, 365.21s/it]Epoch: 18, train loss: 1.32580, f_loss_w: 0.01827, f_loss_uw: 1.32580, data loss: 0.03631:  76% 19/25 [1:53:29<37:07, 371.30s/it]Epoch: 19, train loss: 1.30216, f_loss_w: 0.01919, f_loss_uw: 1.30216, data loss: 0.03629:  76% 19/25 [2:00:42<37:07, 371.30s/it]Epoch: 19, train loss: 1.30216, f_loss_w: 0.01919, f_loss_uw: 1.30216, data loss: 0.03629:  80% 20/25 [2:00:42<31:31, 378.29s/it]wandb: Network error (ReadTimeout), entering retry loop.
a loss: 0.13769:  80% 20/25 [1:10:12<15:49, 189.82s/it]Epoch: 20, train loss: 3.40260, f_loss_w: 0.00069, f_loss_uw: 3.40260, data loss: 0.12483:  80% 20/25 [1:12:42<15:49, 189.82s/it]Epoch: 20, train loss: 3.40260, f_loss_w: 0.00069, f_loss_uw: 3.40260, data loss: 0.12483:  84% 21/25 [1:12:42<12:21, 185.36s/it]Epoch: 21, train loss: 3.24973, f_loss_w: 0.00136, f_loss_uw: 3.24973, data loss: 0.11458:  84% 21/25 [1:15:36<12:21, 185.36s/it]Epoch: 21, train loss: 3.24973, f_loss_w: 0.00136, f_loss_uw: 3.24973, data loss: 0.11458:  88% 22/25 [1:15:36<09:12, 184.11s/it]Epoch: 22, train loss: 3.49215, f_loss_w: 0.00103, f_loss_uw: 3.49215, data loss: 0.11465:  88% 22/25 [1:17:58<09:12, 184.11s/it]Epoch: 22, train loss: 3.49215, f_loss_w: 0.00103, f_loss_uw: 3.49215, data loss: 0.11465:  92% 23/25 [1:17:58<05:58, 179.47s/it]wandb: Network error (ReadTimeout), entering retry loop.
ss_w: 11681.81023, f_loss_uw: 1.29822, data loss: 0.04217:  76% 19/25 [1:50:31<32:20, 323.44s/it]Epoch: 19, train loss: 1.29822, f_loss_w: 11681.81023, f_loss_uw: 1.29822, data loss: 0.04217:  80% 20/25 [1:50:31<27:23, 328.66s/it]Epoch: 20, train loss: 1.27404, f_loss_w: 11805.79660, f_loss_uw: 1.27404, data loss: 0.04059:  80% 20/25 [1:56:48<27:23, 328.66s/it]Epoch: 20, train loss: 1.27404, f_loss_w: 11805.79660, f_loss_uw: 1.27404, data loss: 0.04059:  84% 21/25 [1:56:48<22:16, 334.03s/it]wandb: Network error (ReadTimeout), entering retry loop.
8, data loss: 0.03917:  64% 16/25 [1:35:07<54:48, 365.41s/it]Epoch: 16, train loss: 1.33305, f_loss_w: 0.66244, f_loss_uw: 1.33305, data loss: 0.03761:  64% 16/25 [1:42:12<54:48, 365.41s/it]Epoch: 16, train loss: 1.33305, f_loss_w: 0.66244, f_loss_uw: 1.33305, data loss: 0.03761:  68% 17/25 [1:42:12<49:41, 372.66s/it]Epoch: 17, train loss: 1.31822, f_loss_w: 0.66966, f_loss_uw: 1.31822, data loss: 0.03643:  68% 17/25 [1:49:05<49:41, 372.66s/it]Epoch: 17, train loss: 1.31822, f_loss_w: 0.66966, f_loss_uw: 1.31822, data loss: 0.03643:  72% 18/25 [1:49:05<44:01, 377.34s/it]Epoch: 18, train loss: 1.25429, f_loss_w: 0.66456, f_loss_uw: 1.25429, data loss: 0.03533:  72% 18/25 [1:56:48<44:01, 377.34s/it]Epoch: 18, train loss: 1.25429, f_loss_w: 0.66456, f_loss_uw: 1.25429, data loss: 0.03533:  76% 19/25 [1:56:48<38:43, 387.26s/it]wandb: Network error (ReadTimeout), entering retry loop.
Epoch: 14, train loss: 162.90299, f_loss_w: 1268.06626, f_loss_uw: 162.90299, data loss: 1.62921:  56% 14/25 [1:25:57<53:27, 291.60s/it]Epoch: 14, train loss: 162.90299, f_loss_w: 1268.06626, f_loss_uw: 162.90299, data loss: 1.62921:  60% 15/25 [1:25:57<1:10:01, 420.15s/it]wandb: Network error (ReadTimeout), entering retry loop.
3, data loss: 0.04581:  80% 20/25 [1:45:49<27:39, 331.90s/it]Epoch: 20, train loss: 1.36468, f_loss_w: 0.05014, f_loss_uw: 1.36468, data loss: 0.04570:  80% 20/25 [1:51:27<27:39, 331.90s/it]Epoch: 20, train loss: 1.36468, f_loss_w: 0.05014, f_loss_uw: 1.36468, data loss: 0.04570:  84% 21/25 [1:51:27<22:10, 332.57s/it]Epoch: 21, train loss: 1.49857, f_loss_w: 0.03729, f_loss_uw: 1.49857, data loss: 0.05227:  84% 21/25 [1:56:47<22:10, 332.57s/it]Epoch: 21, train loss: 1.49857, f_loss_w: 0.03729, f_loss_uw: 1.49857, data loss: 0.05227:  88% 22/25 [1:56:47<16:33, 331.20s/it]Epoch: 22, train loss: 1.30985, f_loss_w: 0.03216, f_loss_uw: 1.30985, data loss: 0.04225:  88% 22/25 [2:01:55<16:33, 331.20s/it]Epoch: 22, train loss: 1.30985, f_loss_w: 0.03216, f_loss_uw: 1.30985, data loss: 0.04225:  92% 23/25 [2:01:55<10:57, 328.67s/it]wandb: Network error (ReadTimeout), entering retry loop.
4392, f_loss_w: 43.59578, f_loss_uw: 1.14392, data loss: 0.03771:  64% 16/25 [1:50:10<1:03:15, 421.70s/it]Epoch: 16, train loss: 1.10467, f_loss_w: 41.05294, f_loss_uw: 1.10467, data loss: 0.03631:  64% 16/25 [1:59:11<1:03:15, 421.70s/it]Epoch: 16, train loss: 1.10467, f_loss_w: 41.05294, f_loss_uw: 1.10467, data loss: 0.03631:  68% 17/25 [1:59:11<58:08, 436.05s/it]  wandb: Network error (ReadTimeout), entering retry loop.
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
Epoch: 21, train loss: 1.24911, f_loss_w: 11642.68756, f_loss_uw: 1.24911, data loss: 0.03918:  84% 21/25 [2:03:41<22:16, 334.03s/it]Epoch: 21, train loss: 1.24911, f_loss_w: 11642.68756, f_loss_uw: 1.24911, data loss: 0.03918:  88% 22/25 [2:03:41<17:08, 342.81s/it]wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
Epoch: 19, train loss: 1.20732, f_loss_w: 0.64740, f_loss_uw: 1.20732, data loss: 0.03284:  76% 19/25 [2:05:09<38:43, 387.26s/it]Epoch: 19, train loss: 1.20732, f_loss_w: 0.64740, f_loss_uw: 1.20732, data loss: 0.03284:  80% 20/25 [2:05:09<33:21, 400.23s/it]wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
wandb: ERROR Error while calling W&B API: internal database error (<Response [500]>)
Checkpoint is saved at checkpoints//darcy-cpino-10.pt
Checkpoint is saved at checkpoints//darcy-cpino-10-weights.pt
Epoch: 23, train loss: 1.24796, f_loss_w: 0.03347, f_loss_uw: 1.24796, data loss: 0.04380:  92% 23/25 [2:06:39<10:57, 328.67s/it]Epoch: 23, train loss: 1.24796, f_loss_w: 0.03347, f_loss_uw: 1.24796, data loss: 0.04380:  96% 24/25 [2:06:39<05:23, 323.81s/it]Epoch: 24, train loss: 1.24533, f_loss_w: 0.03167, f_loss_uw: 1.24533, data loss: 0.04468:  96% 24/25 [2:10:53<05:23, 323.81s/it]Epoch: 24, train loss: 1.24533, f_loss_w: 0.03167, f_loss_uw: 1.24533, data loss: 0.04468: 100% 25/25 [2:10:53<00:00, 316.26s/it]Epoch: 24, train loss: 1.24533, f_loss_w: 0.03167, f_loss_uw: 1.24533, data loss: 0.04468: 100% 25/25 [2:10:53<00:00, 314.14s/it]
wandb: Waiting for W&B process to finish, PID 14121... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss ▇▅█▃▃▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁
wandb:   f loss weighted █▄▇▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▇▅█▃▃▄▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.04468
wandb:            f loss 1.24533
wandb:   f loss weighted 0.03167
wandb:        train loss 1.24533
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced polished-music-208: https://wandb.ai/rishigundakaram/CPINO/runs/w8sbpf65
wandb: Find logs at: ./wandb/run-20220615_110428-w8sbpf65/logs/debug.log
wandb: 

Done!
Checkpoint is saved at checkpoints//darcy-cpino-21.pt
Checkpoint is saved at checkpoints//darcy-cpino-21-weights.pt
Epoch: 22, train loss: 1.22338, f_loss_w: 11866.92855, f_loss_uw: 1.22338, data loss: 0.03812:  88% 22/25 [2:10:44<17:08, 342.81s/it]Epoch: 22, train loss: 1.22338, f_loss_w: 11866.92855, f_loss_uw: 1.22338, data loss: 0.03812:  92% 23/25 [2:10:44<11:43, 351.57s/it]Epoch: 23, train loss: 1.20109, f_loss_w: 12357.22314, f_loss_uw: 1.20109, data loss: 0.03686:  92% 23/25 [2:18:17<11:43, 351.57s/it]Epoch: 23, train loss: 1.20109, f_loss_w: 12357.22314, f_loss_uw: 1.20109, data loss: 0.03686:  96% 24/25 [2:18:17<06:02, 362.64s/it]Epoch: 24, train loss: 1.18358, f_loss_w: 12704.95439, f_loss_uw: 1.18358, data loss: 0.03676:  96% 24/25 [2:25:50<06:02, 362.64s/it]Epoch: 24, train loss: 1.18358, f_loss_w: 12704.95439, f_loss_uw: 1.18358, data loss: 0.03676: 100% 25/25 [2:25:50<00:00, 372.35s/it]Epoch: 24, train loss: 1.18358, f_loss_w: 12704.95439, f_loss_uw: 1.18358, data loss: 0.03676: 100% 25/25 [2:25:50<00:00, 350.01s/it]
wandb: Waiting for W&B process to finish, PID 11872... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss █▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb:   f loss weighted ▁▂▃▃█▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂
wandb:        train loss █▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.03676
wandb:            f loss 1.18358
wandb:   f loss weighted 12704.95439
wandb:        train loss 1.18358
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced serene-blaze-198: https://wandb.ai/rishigundakaram/CPINO/runs/kvniafs9
wandb: Find logs at: ./wandb/run-20220615_110424-kvniafs9/logs/debug.log
wandb: 

Done!
Epoch: 20, train loss: 1.26479, f_loss_w: 0.02093, f_loss_uw: 1.26479, data loss: 0.03491:  80% 20/25 [2:08:32<31:31, 378.29s/it]Epoch: 20, train loss: 1.26479, f_loss_w: 0.02093, f_loss_uw: 1.26479, data loss: 0.03491:  84% 21/25 [2:08:32<25:54, 388.65s/it]Epoch: 21, train loss: 1.26321, f_loss_w: 0.02173, f_loss_uw: 1.26321, data loss: 0.03529:  84% 21/25 [2:16:15<25:54, 388.65s/it]Epoch: 21, train loss: 1.26321, f_loss_w: 0.02173, f_loss_uw: 1.26321, data loss: 0.03529:  88% 22/25 [2:16:15<19:50, 396.85s/it]Epoch: 22, train loss: 1.42595, f_loss_w: 0.01947, f_loss_uw: 1.42595, data loss: 0.04410:  88% 22/25 [2:20:56<19:50, 396.85s/it]Epoch: 22, train loss: 1.42595, f_loss_w: 0.01947, f_loss_uw: 1.42595, data loss: 0.04410:  92% 23/25 [2:20:56<12:48, 384.19s/it]Epoch: 23, train loss: 1.31362, f_loss_w: 0.01438, f_loss_uw: 1.31362, data loss: 0.03528:  92% 23/25 [2:26:30<12:48, 384.19s/it]Epoch: 23, train loss: 1.31362, f_loss_w: 0.01438, f_loss_uw: 1.31362, data loss: 0.03528:  96% 24/25 [2:26:30<06Checkpoint is saved at checkpoints//darcy-cpino-17.pt
Checkpoint is saved at checkpoints//darcy-cpino-17-weights.pt
:18, 378.69s/it]Epoch: 24, train loss: 1.30849, f_loss_w: 0.01641, f_loss_uw: 1.30849, data loss: 0.03689:  96% 24/25 [2:32:14<06:18, 378.69s/it]Epoch: 24, train loss: 1.30849, f_loss_w: 0.01641, f_loss_uw: 1.30849, data loss: 0.03689: 100% 25/25 [2:32:14<00:00, 374.96s/it]Epoch: 24, train loss: 1.30849, f_loss_w: 0.01641, f_loss_uw: 1.30849, data loss: 0.03689: 100% 25/25 [2:32:14<00:00, 365.38s/it]
wandb: Waiting for W&B process to finish, PID 25761... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss ▆▆█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁
wandb:   f loss weighted ▂█▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▆▆█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.03689
wandb:            f loss 1.30849
wandb:   f loss weighted 0.01641
wandb:        train loss 1.30849
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced faithful-field-201: https://wandb.ai/rishigundakaram/CPINO/runs/2uzmycsg
wandb: Find logs at: ./wandb/run-20220615_110424-2uzmycsg/logs/debug.log
wandb: 

Done!
Epoch: 17, train loss: 1.06182, f_loss_w: 36.09189, f_loss_uw: 1.06182, data loss: 0.03613:  68% 17/25 [2:08:27<58:08, 436.05s/it]Epoch: 17, train loss: 1.06182, f_loss_w: 36.09189, f_loss_uw: 1.06182, data loss: 0.03613:  72% 18/25 [2:08:27<52:30, 450.11s/it]Epoch: 18, train loss: 1.00619, f_loss_w: 35.29102, f_loss_uw: 1.00619, data loss: 0.03444:  72% 18/25 [2:18:23<52:30, 450.11s/it]Epoch: 18, train loss: 1.00619, f_loss_w: 35.29102, f_loss_uw: 1.00619, data loss: 0.03444:  76% 19/25 [2:18:23<46:42, 467.03s/it]Epoch: 19, train loss: 0.97377, f_loss_w: 33.45753, f_loss_uw: 0.97377, data loss: 0.03337:  76% 19/25 [2:28:09<46:42, 467.03s/it]Epoch: 19, train loss: 0.97377, f_loss_w: 33.45753, f_loss_uw: 0.97377, data loss: 0.03337:  80% 20/25 [2:28:09<40:02, 480.54s/it]Epoch: 20, train loss: 0.92125, f_loss_w: 31.97876, f_loss_uw: 0.92125, data loss: 0.03269:  80% 20/25 [2:38:28<40:02, 480.54s/it]Epoch: 20, train loss: 0.92125, f_loss_w: 31.97876, f_loss_uw: 0.92125, data loss: 0.03269:  84% 21/25 [2:Epoch: 20, train loss: 1.15325, f_loss_w: 0.63296, f_loss_uw: 1.15325, data loss: 0.03212:  80% 20/25 [2:14:21<33:21, 400.23s/it]Epoch: 20, train loss: 1.15325, f_loss_w: 0.63296, f_loss_uw: 1.15325, data loss: 0.03212:  84% 21/25 [2:14:21<27:48, 417.25s/it]Epoch: 21, train loss: 1.11973, f_loss_w: 0.61506, f_loss_uw: 1.11973, data loss: 0.03137:  84% 21/25 [2:23:44<27:48, 417.25s/it]Epoch: 21, train loss: 1.11973, f_loss_w: 0.61506, f_loss_uw: 1.11973, data loss: 0.03137:  88% 22/25 [2:23:44<21:40, 433.42s/it]Epoch: 22, train loss: 1.09456, f_loss_w: 0.58869, f_loss_uw: 1.09456, data loss: 0.03177:  88% 22/25 [2:31:47<21:40, 433.42s/it]Epoch: 22, train loss: 1.09456, f_loss_w: 0.58869, f_loss_uw: 1.09456, data loss: 0.03177:  92% 23/25 [2:31:47<14:37, 438.81s/it]Epoch: 23, train loss: 1.05103, f_loss_w: 0.53815, f_loss_uw: 1.05103, data loss: 0.03042:  92% 23/25 [2:40:37<14:37, 438.81s/it]Epoch: 23, train loss: 1.05103, f_loss_w: 0.53815, f_loss_uw: 1.05103, data loss: 0.03042:  96% 24/25 [2:40:37<07Checkpoint is saved at checkpoints//darcy-cpino-16.pt
Checkpoint is saved at checkpoints//darcy-cpino-16-weights.pt
:28, 448.80s/it]Epoch: 24, train loss: 1.02406, f_loss_w: 0.51330, f_loss_uw: 1.02406, data loss: 0.02963:  96% 24/25 [2:49:23<07:28, 448.80s/it]Epoch: 24, train loss: 1.02406, f_loss_w: 0.51330, f_loss_uw: 1.02406, data loss: 0.02963: 100% 25/25 [2:49:23<00:00, 457.06s/it]Epoch: 24, train loss: 1.02406, f_loss_w: 0.51330, f_loss_uw: 1.02406, data loss: 0.02963: 100% 25/25 [2:49:23<00:00, 406.53s/it]
wandb: Waiting for W&B process to finish, PID 13839... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▃▃▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss ▅▄▄█▆▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   f loss weighted ▁▃▂▃█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss ▅▄▄█▆▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.02963
wandb:            f loss 1.02406
wandb:   f loss weighted 0.5133
wandb:        train loss 1.02406
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced fancy-fog-186: https://wandb.ai/rishigundakaram/CPINO/runs/gq6jdt6k
wandb: Find logs at: ./wandb/run-20220615_110422-gq6jdt6k/logs/debug.log
wandb: 

Done!
38:28<33:04, 496.12s/it]Epoch: 21, train loss: 0.89056, f_loss_w: 31.35055, f_loss_uw: 0.89056, data loss: 0.03196:  84% 21/25 [2:48:58<33:04, 496.12s/it]Epoch: 21, train loss: 0.89056, f_loss_w: 31.35055, f_loss_uw: 0.89056, data loss: 0.03196:  88% 22/25 [2:48:58<25:32, 510.96s/it]Epoch: 22, train loss: 0.86107, f_loss_w: 31.98402, f_loss_uw: 0.86107, data loss: 0.03055:  88% 22/25 [2:59:55<25:32, 510.96s/it]Epoch: 22, train loss: 0.86107, f_loss_w: 31.98402, f_loss_uw: 0.86107, data loss: 0.03055:  92% 23/25 [2:59:55<17:33, 526.90s/it]Epoch: 23, train loss: 0.83147, f_loss_w: 27.56245, f_loss_uw: 0.83147, data loss: 0.02982:  92% 23/25 [3:10:50<17:33, 526.90s/it]Epoch: 23, train loss: 0.83147, f_loss_w: 27.56245, f_loss_uw: 0.83147, data loss: 0.02982:  96% 24/25 [3:10:50<09:00, 540.83s/it]Epoch: 24, train loss: 0.81607, f_loss_w: 26.82274, f_loss_uw: 0.81607, data loss: 0.02898:  96% 24/25 [3:21:27<09:00, 540.83s/it]Epoch: 24, train loss: 0.81607, f_loss_w: 26.82274, f_loss_uw: 0.81607, data loss:Checkpoint is saved at checkpoints//darcy-cpino-15.pt
Checkpoint is saved at checkpoints//darcy-cpino-15-weights.pt
 0.02898: 100% 25/25 [3:21:27<00:00, 551.26s/it]Epoch: 24, train loss: 0.81607, f_loss_w: 26.82274, f_loss_uw: 0.81607, data loss: 0.02898: 100% 25/25 [3:21:27<00:00, 483.51s/it]
wandb: Waiting for W&B process to finish, PID 29552... (success).
wandb: - 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: \ 376.46MB of 376.46MB uploaded (0.00MB deduped)wandb: | 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.46MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: / 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: - 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: \ 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb: | 376.47MB of 376.47MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Run history:
wandb:         data loss █▃▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:            f loss █▃▇▆▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb:   f loss weighted ▁▁█▆▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:        train loss █▃▇▆▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:         data loss 0.02898
wandb:            f loss 0.81607
wandb:   f loss weighted 26.82274
wandb:        train loss 0.81607
wandb: 
wandb: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Synced comfy-snowflake-209: https://wandb.ai/rishigundakaram/CPINO/runs/1p45i0xb
wandb: Find logs at: ./wandb/run-20220615_110428-1p45i0xb/logs/debug.log
wandb: 

Done!
